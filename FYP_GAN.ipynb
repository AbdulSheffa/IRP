{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1iyXb4n-lH6Pjnc_ua_xJVobZGcVftJhl",
      "authorship_tag": "ABX9TyOC2+bge1Z7WA4yCiHYaC+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdulSheffa/IRP/blob/main/FYP_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB52lxgkTjB7",
        "outputId": "e4a80e73-b108-4ca8-d018-eb1ac99c3041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo2OYl_B4LvW",
        "outputId": "9774160d-a48f-43a5-bae9-c488ab93f38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2516, done.\u001b[K\n",
            "remote: Total 2516 (delta 0), reused 0 (delta 0), pack-reused 2516 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2516/2516), 8.20 MiB | 7.89 MiB/s, done.\n",
            "Resolving deltas: 100% (1575/1575), done.\n",
            "/content/pytorch-CycleGAN-and-pix2pix\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git\n",
        "%cd pytorch-CycleGAN-and-pix2pix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkTHg53q4cgW",
        "outputId": "f8b3efd3-3286-472d-b451-f7e4c48bc89c",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu124)\n",
            "Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.33)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (75.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408196 sha256=cec7f41ba5f1f83d105523f7d24a51d8695d7c782a78fede4ef49ef5281852b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/a4/bb/2be445c295d88a74f9c0a4232f04860ca489a5c7c57eb959d9\n",
            "Successfully built visdom\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dominate, visdom, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dominate-2.9.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 visdom-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "from models.networks import ResnetGenerator, NLayerDiscriminator\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Dataset with Self-Supervised Learning Masking\n",
        "# ------------------------------\n",
        "class RainDatasetSSL(Dataset):\n",
        "    def __init__(self, dataset_name, input_dir, target_dir, transform=None, sample_size=None, output_dir=None, save_masked=False, epoch=0):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.input_dir = input_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.transform = transform\n",
        "        self.output_dir = output_dir\n",
        "        self.save_masked = save_masked  # Flag to control saving masked images\n",
        "        self.epoch = epoch  # Current epoch for saving masked images with correct names\n",
        "\n",
        "        self.input_images = sorted(os.listdir(input_dir))\n",
        "        self.target_images = sorted(os.listdir(target_dir))\n",
        "\n",
        "        if sample_size:\n",
        "            indices = random.sample(range(len(self.input_images)), sample_size)\n",
        "            self.input_images = [self.input_images[i] for i in indices]\n",
        "            self.target_images = [self.target_images[i] for i in indices]\n",
        "\n",
        "        if save_masked and output_dir:\n",
        "            os.makedirs(output_dir, exist_ok=True)  # Ensure the directory exists\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_images)  # ✅ Fix for DataLoader issue\n",
        "\n",
        "    def mask_image(self, img_tensor, img_name):\n",
        "        \"\"\"Apply dynamic masking for self-supervised learning & save masked image if required.\"\"\"\n",
        "        _, h, w = img_tensor.shape\n",
        "        mask_size = (random.randint(h // 4, h // 2), random.randint(w // 4, w // 2))  # Dynamic mask size\n",
        "        x, y = random.randint(0, h - mask_size[0]), random.randint(0, w - mask_size[1])\n",
        "\n",
        "        # Apply masking (set pixels to zero in the selected region)\n",
        "        img_tensor[:, x:x + mask_size[0], y:y + mask_size[1]] = 0\n",
        "\n",
        "        # Save masked image if enabled\n",
        "        if self.save_masked and self.output_dir:\n",
        "            save_path = os.path.join(self.output_dir, f\"masked_{self.dataset_name}_epoch_{self.epoch}_de_rained_{img_name}\")\n",
        "            save_image(img_tensor, save_path)\n",
        "            print(f\"Saved masked image: {save_path}\")\n",
        "\n",
        "        return img_tensor\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_img_path = os.path.join(self.input_dir, self.input_images[idx])\n",
        "        target_img_path = os.path.join(self.target_dir, self.target_images[idx])\n",
        "\n",
        "        input_image = Image.open(input_img_path).convert(\"RGB\")\n",
        "        target_image = Image.open(target_img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            input_image = self.transform(input_image)\n",
        "            target_image = self.transform(target_image)\n",
        "\n",
        "        # Apply masking to input image for SSL\n",
        "        masked_image = self.mask_image(input_image.clone(), self.input_images[idx])\n",
        "\n",
        "        return masked_image, input_image, target_image, self.input_images[idx]\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Improved Self-Supervised DeRain CycleGAN Model\n",
        "# ------------------------------\n",
        "class DeRainCycleGANSSL:\n",
        "    def __init__(self, input_nc, output_nc, ngf, ndf, device):\n",
        "        self.device = device\n",
        "        self.netG_A = ResnetGenerator(input_nc, output_nc, ngf).to(device)  # Rainy -> Clean\n",
        "        self.netG_B = ResnetGenerator(output_nc, input_nc, ngf).to(device)  # Clean -> Rainy\n",
        "        self.netD_A = NLayerDiscriminator(output_nc, ndf).to(device)  # Discriminator for Clean Images\n",
        "        self.netD_B = NLayerDiscriminator(input_nc, ndf).to(device)  # Discriminator for Rainy Images\n",
        "\n",
        "        self.criterionGAN = nn.MSELoss()\n",
        "        self.criterionCycle = nn.L1Loss()\n",
        "\n",
        "        # Add perceptual loss using VGG19\n",
        "        self.vgg = models.vgg19(pretrained=True).features[:16].eval().to(device)\n",
        "        for param in self.vgg.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.criterionPerceptual = nn.MSELoss()\n",
        "\n",
        "        # Optimizers\n",
        "        self.optimizer_G = torch.optim.Adam(\n",
        "            list(self.netG_A.parameters()) + list(self.netG_B.parameters()), lr=0.0001, betas=(0.5, 0.999)\n",
        "        )\n",
        "        self.optimizer_D = torch.optim.Adam(\n",
        "            list(self.netD_A.parameters()) + list(self.netD_B.parameters()), lr=0.0001, betas=(0.5, 0.999)\n",
        "        )\n",
        "\n",
        "    def perceptual_loss(self, x, y):\n",
        "        return self.criterionPerceptual(self.vgg(x), self.vgg(y))\n",
        "\n",
        "    def forward(self, real_A, real_B):\n",
        "        fake_B = self.netG_A(real_A)  # Rainy -> Clean\n",
        "        rec_A = self.netG_B(fake_B)  # Clean -> Rainy\n",
        "        fake_A = self.netG_B(real_B)  # Clean -> Rainy\n",
        "        rec_B = self.netG_A(fake_A)  # Rainy -> Clean\n",
        "        return fake_B, rec_A, fake_A, rec_B\n",
        "\n",
        "    def backward_G(self, real_A, real_B, fake_B, rec_A, fake_A, rec_B):\n",
        "        loss_G_A = self.criterionGAN(self.netD_A(fake_B), torch.ones_like(self.netD_A(fake_B)))\n",
        "        loss_G_B = self.criterionGAN(self.netD_B(fake_A), torch.ones_like(self.netD_B(fake_A)))\n",
        "        loss_cycle_A = self.criterionCycle(rec_A, real_A) * 10.0\n",
        "        loss_cycle_B = self.criterionCycle(rec_B, real_B) * 10.0\n",
        "        loss_perceptual = self.perceptual_loss(fake_B, real_B) * 0.1  # Small weight for perceptual loss\n",
        "\n",
        "        loss_G = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B + loss_perceptual\n",
        "        loss_G.backward()\n",
        "        return loss_G\n",
        "\n",
        "    def backward_D(self, netD, real, fake):\n",
        "        \"\"\" Compute discriminator loss and backpropagate \"\"\"\n",
        "        pred_real = netD(real)\n",
        "        loss_D_real = self.criterionGAN(pred_real, torch.ones_like(pred_real))\n",
        "\n",
        "        pred_fake = netD(fake.detach())  # Detach to avoid affecting generator\n",
        "        loss_D_fake = self.criterionGAN(pred_fake, torch.zeros_like(pred_fake))\n",
        "\n",
        "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
        "        loss_D.backward()\n",
        "        return loss_D\n",
        "\n",
        "    def optimize_parameters(self, real_A, real_B):\n",
        "        fake_B, rec_A, fake_A, rec_B = self.forward(real_A, real_B)\n",
        "        self.optimizer_G.zero_grad()\n",
        "        loss_G = self.backward_G(real_A, real_B, fake_B, rec_A, fake_A, rec_B)\n",
        "        self.optimizer_G.step()\n",
        "\n",
        "        self.optimizer_D.zero_grad()\n",
        "        loss_D_A = self.backward_D(self.netD_A, real_B, fake_B)\n",
        "        loss_D_B = self.backward_D(self.netD_B, real_A, fake_A)\n",
        "        self.optimizer_D.step()\n",
        "\n",
        "        return loss_G, loss_D_A, loss_D_B\n"
      ],
      "metadata": {
        "id": "t4aaBymOOZ5P"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from models.networks import ResnetGenerator, NLayerDiscriminator\n",
        "\n",
        "# Define multiple dataset paths with respective batch sizes and sample sizes\n",
        "datasets = {\n",
        "    \"Rain100L\": {\n",
        "        \"input\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain100L/input\",\n",
        "        \"target\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain100L/target\",\n",
        "        \"output\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain100L/results_2/\",\n",
        "        \"batch_size\": 8,  # Custom batch size per dataset\n",
        "        \"sample_size\": 100  # Take only 100 samples\n",
        "    },\n",
        "    \"DID-MDN-Heavy\": {\n",
        "        \"input\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Heavy/rainy\",\n",
        "        \"target\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Heavy/non_rainy\",\n",
        "        \"output\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_1/\",\n",
        "        \"batch_size\": 6,\n",
        "        \"sample_size\": 200  # Take 200 samples\n",
        "    }\n",
        "    # \"DID-MDN-Medium\": {\n",
        "    # \"input\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Medium/rainy\",\n",
        "    # \"target\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Medium/non_rainy\",\n",
        "    # \"output\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Medium-rain/results_1/\",\n",
        "    # \"batch_size\": 6,\n",
        "    # \"sample_size\": 200  # Take 200 samples\n",
        "    # },\n",
        "    # \"DID-MDN-Medium\": {\n",
        "    # \"input\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Light/rainy\",\n",
        "    # \"target\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Light/non_rainy\",\n",
        "    # \"output\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Light-rain/results_1/\",\n",
        "    # \"batch_size\": 6,\n",
        "    # \"sample_size\": 200  # Take 200 samples\n",
        "    # }\n",
        "}\n",
        "\n",
        "# Define transformation with normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "# Define a function to denormalize images before saving\n",
        "def denormalize(tensor):\n",
        "    \"\"\"Reverse normalization applied earlier to get back to [0, 1]\"\"\"\n",
        "    return tensor * 0.5 + 0.5\n",
        "\n",
        "# Initialize Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize Model\n",
        "model = DeRainCycleGANSSL(input_nc=3, output_nc=3, ngf=128, ndf=128, device=device)\n",
        "\n",
        "# Add Learning Rate Schedulers\n",
        "scheduler_G = torch.optim.lr_scheduler.StepLR(model.optimizer_G, step_size=20, gamma=0.5)\n",
        "scheduler_D = torch.optim.lr_scheduler.StepLR(model.optimizer_D, step_size=20, gamma=0.5)\n",
        "\n",
        "# Training Configuration\n",
        "num_epochs = 70\n",
        "\n",
        "# Define a masked output directory\n",
        "masked_output_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/masked_images\"\n",
        "\n",
        "# Loop Through Each Dataset and Train\n",
        "for dataset_name, paths in datasets.items():\n",
        "    print(f\"\\n🔹 Training on {dataset_name} dataset...\")\n",
        "\n",
        "    input_dir = paths[\"input\"]\n",
        "    target_dir = paths[\"target\"]\n",
        "    output_dir = paths[\"output\"]\n",
        "    batch_size = paths[\"batch_size\"]\n",
        "    sample_size = paths[\"sample_size\"]\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load dataset with masked saving enabled\n",
        "    train_loader = DataLoader(\n",
        "        RainDatasetSSL(\n",
        "            dataset_name=dataset_name,\n",
        "            input_dir=input_dir,\n",
        "            target_dir=target_dir,\n",
        "            transform=transform,\n",
        "            sample_size=sample_size,\n",
        "            output_dir=masked_output_dir,  # Save masked images here\n",
        "            save_masked=True\n",
        "        ),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.netG_A.train()\n",
        "        model.netG_B.train()\n",
        "        epoch_loss_G, epoch_loss_D_A, epoch_loss_D_B = 0, 0, 0\n",
        "\n",
        "        for i, (masked_A, real_A, real_B, img_name) in enumerate(train_loader):\n",
        "          masked_A, real_A, real_B = masked_A.to(device), real_A.to(device), real_B.to(device)\n",
        "\n",
        "          # Forward pass and optimization\n",
        "          loss_G, loss_D_A, loss_D_B = model.optimize_parameters(masked_A, real_B)\n",
        "          epoch_loss_G += loss_G.item()\n",
        "          epoch_loss_D_A += loss_D_A.item()\n",
        "          epoch_loss_D_B += loss_D_B.item()\n",
        "\n",
        "          # Prevent runtime disconnection\n",
        "          print(f\"Epoch {epoch}/{num_epochs}, Batch {i}/{len(train_loader)}, Image: {img_name[0]}, \"\n",
        "                f\"Loss_G: {loss_G:.4f}, Loss_D_A: {loss_D_A:.4f}, Loss_D_B: {loss_D_B:.4f}\")\n",
        "\n",
        "        # Step the scheduler\n",
        "        scheduler_G.step()\n",
        "        scheduler_D.step()\n",
        "\n",
        "    # Save generated images at intervals\n",
        "    if epoch == num_epochs - 1:\n",
        "        model.netG_A.eval()  # Switch generator to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for i, (real_A, _, img_names) in enumerate(train_loader):\n",
        "                real_A = real_A.to(device)\n",
        "                fake_B = model.netG_A(real_A)  # Rainy -> Clean\n",
        "\n",
        "                # Denormalize before saving\n",
        "                fake_B = denormalize(fake_B)\n",
        "\n",
        "                # Save each image in the batch\n",
        "                for j in range(real_A.size(0)):\n",
        "                    img_name = img_names[j]\n",
        "                    save_path = os.path.join(output_dir, f\"{dataset_name}_epoch_{epoch}_de_rained_{img_name}\")\n",
        "                    save_image(fake_B[j], save_path)\n",
        "\n",
        "                    print(f\"Saved: {save_path}\")\n",
        "\n",
        "print(\"Training on all datasets completed ✅\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "qUX1yheK7O3l",
        "outputId": "0c96de15-1b54-4d7c-81bf-832782fea6a3",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Training on Rain100L dataset...\n",
            "Saved masked image: /content/drive/MyDrive/Khabeer - IRP/Dataset/masked_images/masked_Rain100L_epoch_0_de_rained_24.png\n",
            "Saved masked image: /content/drive/MyDrive/Khabeer - IRP/Dataset/masked_images/masked_Rain100L_epoch_0_de_rained_95.png\n",
            "Saved masked image: /content/drive/MyDrive/Khabeer - IRP/Dataset/masked_images/masked_Rain100L_epoch_0_de_rained_98.png\n",
            "Saved masked image: /content/drive/MyDrive/Khabeer - IRP/Dataset/masked_images/masked_Rain100L_epoch_0_de_rained_73.png\n",
            "Saved masked image: /content/drive/MyDrive/Khabeer - IRP/Dataset/masked_images/masked_Rain100L_epoch_0_de_rained_55.png\n",
            "Saved masked image: /content/drive/MyDrive/Khabeer - IRP/Dataset/masked_images/masked_Rain100L_epoch_0_de_rained_76.png\n",
            "Saved masked image: /content/drive/MyDrive/Khabeer - IRP/Dataset/masked_images/masked_Rain100L_epoch_0_de_rained_11.png\n",
            "Saved masked image: /content/drive/MyDrive/Khabeer - IRP/Dataset/masked_images/masked_Rain100L_epoch_0_de_rained_87.png\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 20.12 MiB is free. Process 2598 has 14.72 GiB memory in use. Of the allocated memory 12.99 GiB is allocated by PyTorch, and 1.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-bf225cdfe131>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m           \u001b[0;31m# Forward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m           \u001b[0mloss_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_D_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_D_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m           \u001b[0mepoch_loss_G\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m           \u001b[0mepoch_loss_D_A\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_D_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-c29f4e5b79ed>\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(self, real_A, real_B)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mfake_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mloss_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-c29f4e5b79ed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, real_A, real_B)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Rainy -> Clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mrec_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clean -> Rainy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mfake_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_B\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clean -> Rainy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch-CycleGAN-and-pix2pix/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;34m\"\"\"Standard forward\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 20.12 MiB is free. Process 2598 has 14.72 GiB memory in use. Of the allocated memory 12.99 GiB is allocated by PyTorch, and 1.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "# Define Autoencoder with Skip Connections\n",
        "class AutoencoderWithSkipConnections(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(AutoencoderWithSkipConnections, self).__init__()\n",
        "        self.encoder1 = nn.Sequential(nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.encoder2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.encoder3 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.bottleneck = nn.Sequential(nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder1 = nn.Sequential(nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder2 = nn.Sequential(nn.ConvTranspose2d(256 + 256, 128, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder3 = nn.Sequential(nn.ConvTranspose2d(128 + 128, 64, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder4 = nn.Sequential(nn.ConvTranspose2d(64 + 64, input_nc, kernel_size=4, stride=2, padding=1), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        b = self.bottleneck(e3)\n",
        "        d1 = self.decoder1(b)\n",
        "        d2 = self.decoder2(torch.cat([d1, e3], dim=1))\n",
        "        d3 = self.decoder3(torch.cat([d2, e2], dim=1))\n",
        "        d4 = self.decoder4(torch.cat([d3, e1], dim=1))\n",
        "        return d4\n",
        "\n",
        "# Perceptual Loss using VGG19\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        vgg19 = models.vgg19(pretrained=True).features[:16].eval()\n",
        "        for param in vgg19.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.vgg19 = vgg19\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x_features = self.vgg19(x)\n",
        "        y_features = self.vgg19(y)\n",
        "        return self.criterion(x_features, y_features)\n",
        "\n",
        "# Initialize Autoencoder and Loss Functions\n",
        "input_channels = 3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "autoencoder = AutoencoderWithSkipConnections(input_channels).to(device)\n",
        "\n",
        "mse_loss = nn.MSELoss()\n",
        "perceptual_loss = PerceptualLoss().to(device)\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0002)\n",
        "\n",
        "# Define the GAN-generated output directories\n",
        "gan_output_dirs = {\n",
        "    \"results_6\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/Split-DID-MDN/results_6\",\n",
        "    \"results_5\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/Split-DID-MDN/results_5\",\n",
        "    \"results_4\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/Split-DID-MDN/results_4\"\n",
        "}\n",
        "\n",
        "# Function to load images from a directory\n",
        "def load_images_from_dir(directory):\n",
        "    images, filenames = [], []\n",
        "    for img_name in sorted(os.listdir(directory)):\n",
        "        if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img_path = os.path.join(directory, img_name)\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "            img = transforms.ToTensor()(img)\n",
        "            images.append(img)\n",
        "            filenames.append(img_name)\n",
        "    return torch.stack(images), filenames\n",
        "\n",
        "# Process each directory separately\n",
        "for dir_name, gan_output_path in gan_output_dirs.items():\n",
        "    print(f\"\\n🔹 Processing GAN outputs from: {gan_output_path}\")\n",
        "\n",
        "    # Load images from current directory\n",
        "    train_data, train_filenames = load_images_from_dir(gan_output_path)\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "\n",
        "    # Train the Autoencoder\n",
        "    epochs = 60\n",
        "    final_epoch_reconstructions = {}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, images in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            reconstructed = autoencoder(images)\n",
        "            mse_loss_value = mse_loss(reconstructed, images)\n",
        "            perceptual_loss_value = perceptual_loss(reconstructed, images)\n",
        "            total_loss = mse_loss_value + 0.01 * perceptual_loss_value\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Save final epoch reconstructions\n",
        "            if epoch == epochs - 1:\n",
        "                batch_filenames = train_filenames[i * 16:(i + 1) * 16]\n",
        "                for j, filename in enumerate(batch_filenames):\n",
        "                    final_epoch_reconstructions[filename] = reconstructed[j].unsqueeze(0)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], MSE Loss: {mse_loss_value.item()}, Perceptual Loss: {perceptual_loss_value.item()}\")\n",
        "\n",
        "    # Create output directory for this specific dataset\n",
        "    output_dir = f\"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/reconstructed_autoencoder_{dir_name}\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save reconstructed images in their respective folders\n",
        "    for filename, reconstructed_image in final_epoch_reconstructions.items():\n",
        "        save_path = os.path.join(output_dir, f\"{filename.split('.')[0]}_refined.png\")\n",
        "        save_image(reconstructed_image, save_path)\n",
        "\n",
        "    print(f\"✅ Finished processing {dir_name} - Saved to: {output_dir}\")\n",
        "\n",
        "print(\"\\n🎯 Autoencoder Training and Refinement Completed for All GAN Output Directories!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1zt2fj3gM2Q",
        "outputId": "acaa4210-2fb2-42d2-c9d6-1816220afed8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/60], MSE Loss: 0.20659932494163513, Perceptual Loss: 4.693155765533447\n",
            "Epoch [2/60], MSE Loss: 0.13648764789104462, Perceptual Loss: 2.8803763389587402\n",
            "Epoch [3/60], MSE Loss: 0.055457036942243576, Perceptual Loss: 3.4117679595947266\n",
            "Epoch [4/60], MSE Loss: 0.03448586165904999, Perceptual Loss: 2.597916841506958\n",
            "Epoch [5/60], MSE Loss: 0.019618110731244087, Perceptual Loss: 2.0173041820526123\n",
            "Epoch [6/60], MSE Loss: 0.018136020749807358, Perceptual Loss: 1.9500073194503784\n",
            "Epoch [7/60], MSE Loss: 0.017502862960100174, Perceptual Loss: 2.065246343612671\n",
            "Epoch [8/60], MSE Loss: 0.012627768330276012, Perceptual Loss: 1.7568596601486206\n",
            "Epoch [9/60], MSE Loss: 0.015493995510041714, Perceptual Loss: 1.8104727268218994\n",
            "Epoch [10/60], MSE Loss: 0.009665400721132755, Perceptual Loss: 1.7112977504730225\n",
            "Epoch [11/60], MSE Loss: 0.01640314981341362, Perceptual Loss: 1.7680519819259644\n",
            "Epoch [12/60], MSE Loss: 0.009533348493278027, Perceptual Loss: 1.5512104034423828\n",
            "Epoch [13/60], MSE Loss: 0.005541055463254452, Perceptual Loss: 0.8820416331291199\n",
            "Epoch [14/60], MSE Loss: 0.0055077034048736095, Perceptual Loss: 0.7968869805335999\n",
            "Epoch [15/60], MSE Loss: 0.004622092470526695, Perceptual Loss: 0.759538471698761\n",
            "Epoch [16/60], MSE Loss: 0.0038308892399072647, Perceptual Loss: 0.6292638778686523\n",
            "Epoch [17/60], MSE Loss: 0.0037139817140996456, Perceptual Loss: 0.5902756452560425\n",
            "Epoch [18/60], MSE Loss: 0.0029342479538172483, Perceptual Loss: 0.45370107889175415\n",
            "Epoch [19/60], MSE Loss: 0.005013981834053993, Perceptual Loss: 0.5413772463798523\n",
            "Epoch [20/60], MSE Loss: 0.004439244046807289, Perceptual Loss: 0.5431703329086304\n",
            "Epoch [21/60], MSE Loss: 0.00273955799639225, Perceptual Loss: 0.3937968611717224\n",
            "Epoch [22/60], MSE Loss: 0.003814912401139736, Perceptual Loss: 0.47905880212783813\n",
            "Epoch [23/60], MSE Loss: 0.004132146015763283, Perceptual Loss: 0.4747270941734314\n",
            "Epoch [24/60], MSE Loss: 0.002236640080809593, Perceptual Loss: 0.25027143955230713\n",
            "Epoch [25/60], MSE Loss: 0.002851975616067648, Perceptual Loss: 0.454629123210907\n",
            "Epoch [26/60], MSE Loss: 0.003297109855338931, Perceptual Loss: 0.36281442642211914\n",
            "Epoch [27/60], MSE Loss: 0.002578472951427102, Perceptual Loss: 0.4391448497772217\n",
            "Epoch [28/60], MSE Loss: 0.002859153551980853, Perceptual Loss: 0.3869593143463135\n",
            "Epoch [29/60], MSE Loss: 0.00118316023144871, Perceptual Loss: 0.22110667824745178\n",
            "Epoch [30/60], MSE Loss: 0.0033460427075624466, Perceptual Loss: 0.4911496639251709\n",
            "Epoch [31/60], MSE Loss: 0.0018893703818321228, Perceptual Loss: 0.32124626636505127\n",
            "Epoch [32/60], MSE Loss: 0.0019247474847361445, Perceptual Loss: 0.3062567114830017\n",
            "Epoch [33/60], MSE Loss: 0.0015052406815811992, Perceptual Loss: 0.28698837757110596\n",
            "Epoch [34/60], MSE Loss: 0.0025431730318814516, Perceptual Loss: 0.3338863253593445\n",
            "Epoch [35/60], MSE Loss: 0.0016384597402065992, Perceptual Loss: 0.2832149565219879\n",
            "Epoch [36/60], MSE Loss: 0.0017536850646138191, Perceptual Loss: 0.24379503726959229\n",
            "Epoch [37/60], MSE Loss: 0.003454318270087242, Perceptual Loss: 0.41995108127593994\n",
            "Epoch [38/60], MSE Loss: 0.0018560810713097453, Perceptual Loss: 0.285010427236557\n",
            "Epoch [39/60], MSE Loss: 0.0017514058854430914, Perceptual Loss: 0.2832863926887512\n",
            "Epoch [40/60], MSE Loss: 0.0019001639448106289, Perceptual Loss: 0.28256672620773315\n",
            "Epoch [41/60], MSE Loss: 0.0014614638639613986, Perceptual Loss: 0.22794413566589355\n",
            "Epoch [42/60], MSE Loss: 0.0013234536163508892, Perceptual Loss: 0.23501545190811157\n",
            "Epoch [43/60], MSE Loss: 0.0013528948184102774, Perceptual Loss: 0.18943946063518524\n",
            "Epoch [44/60], MSE Loss: 0.0008074257057160139, Perceptual Loss: 0.19035369157791138\n",
            "Epoch [45/60], MSE Loss: 0.0008402959210798144, Perceptual Loss: 0.159245103597641\n",
            "Epoch [46/60], MSE Loss: 0.0010546629782766104, Perceptual Loss: 0.22574442625045776\n",
            "Epoch [47/60], MSE Loss: 0.0027680406346917152, Perceptual Loss: 0.3165283799171448\n",
            "Epoch [48/60], MSE Loss: 0.001119640888646245, Perceptual Loss: 0.2072097659111023\n",
            "Epoch [49/60], MSE Loss: 0.002034649020060897, Perceptual Loss: 0.26019391417503357\n",
            "Epoch [50/60], MSE Loss: 0.0007398693705908954, Perceptual Loss: 0.15640151500701904\n",
            "Epoch [51/60], MSE Loss: 0.0008769318228587508, Perceptual Loss: 0.16544824838638306\n",
            "Epoch [52/60], MSE Loss: 0.0014057498192414641, Perceptual Loss: 0.22651073336601257\n",
            "Epoch [53/60], MSE Loss: 0.0017097200034186244, Perceptual Loss: 0.24588200449943542\n",
            "Epoch [54/60], MSE Loss: 0.0012288469588384032, Perceptual Loss: 0.207509845495224\n",
            "Epoch [55/60], MSE Loss: 0.0010296443942934275, Perceptual Loss: 0.19393953680992126\n",
            "Epoch [56/60], MSE Loss: 0.0009782937122508883, Perceptual Loss: 0.19040121138095856\n",
            "Epoch [57/60], MSE Loss: 0.0007700698333792388, Perceptual Loss: 0.1506158709526062\n",
            "Epoch [58/60], MSE Loss: 0.0012606572126969695, Perceptual Loss: 0.18608978390693665\n",
            "Epoch [59/60], MSE Loss: 0.0010409040842205286, Perceptual Loss: 0.19235458970069885\n",
            "Epoch [60/60], MSE Loss: 0.0008364042732864618, Perceptual Loss: 0.1620998978614807\n",
            "Autoencoder training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# If a GPU is available, you can also check its details\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
        "    print(f\"GPU Memory Cached: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n"
      ],
      "metadata": {
        "id": "WnkEcQLrpxfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29dd6f59-6f60-49d3-fc29-e796b4b32f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory Allocated: 0.00 GB\n",
            "GPU Memory Cached: 0.00 GB\n"
          ]
        }
      ]
    }
  ]
}