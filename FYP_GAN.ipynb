{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1iyXb4n-lH6Pjnc_ua_xJVobZGcVftJhl",
      "authorship_tag": "ABX9TyNHKUOKrKLn9+ktGcx+A8+T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdulSheffa/IRP/blob/main/FYP_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB52lxgkTjB7",
        "outputId": "9ddbc94f-a1de-4f92-b6d1-fee21b60f464"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo2OYl_B4LvW",
        "outputId": "a6749acb-0dc4-4035-8456-f882c90099e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2516, done.\u001b[K\n",
            "remote: Total 2516 (delta 0), reused 0 (delta 0), pack-reused 2516 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2516/2516), 8.20 MiB | 27.35 MiB/s, done.\n",
            "Resolving deltas: 100% (1575/1575), done.\n",
            "/content/pytorch-CycleGAN-and-pix2pix\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git\n",
        "%cd pytorch-CycleGAN-and-pix2pix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkTHg53q4cgW",
        "outputId": "fdd8528e-878d-4c4e-cc35-0725c499f299"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu121)\n",
            "Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->-r requirements.txt (line 1)) (12.8.61)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.33)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (75.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.2)\n",
            "Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408196 sha256=5b0ab0d5a44139ee35d1f5304f9f3a21a1192a4ed0456823d42ee91ab4d9a61b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/a4/bb/2be445c295d88a74f9c0a4232f04860ca489a5c7c57eb959d9\n",
            "Successfully built visdom\n",
            "Installing collected packages: dominate, visdom\n",
            "Successfully installed dominate-2.9.1 visdom-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-test\"\n",
        "output_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/Split-DID-MDN\"\n",
        "\n",
        "# Create output directories for rainy and non-rainy\n",
        "rainy_path = os.path.join(output_path, \"rainy\")\n",
        "non_rainy_path = os.path.join(output_path, \"non_rainy\")\n",
        "\n",
        "os.makedirs(rainy_path, exist_ok=True)\n",
        "os.makedirs(non_rainy_path, exist_ok=True)\n",
        "\n",
        "# Split each image\n",
        "for filename in os.listdir(dataset_path):\n",
        "    file_path = os.path.join(dataset_path, filename)\n",
        "    if filename.endswith(('.png', '.jpg', '.jpeg')):  # Process only image files\n",
        "        try:\n",
        "            # Open the image\n",
        "            img = Image.open(file_path)\n",
        "            width, height = img.size\n",
        "\n",
        "            # Split the image into two halves\n",
        "            rainy_part = img.crop((0, 0, width // 2, height))  # Left half\n",
        "            non_rainy_part = img.crop((width // 2, 0, width, height))  # Right half\n",
        "\n",
        "            # Save the split images\n",
        "            rainy_output = os.path.join(rainy_path, f\"rainy_{filename}\")\n",
        "            non_rainy_output = os.path.join(non_rainy_path, f\"non_rainy_{filename}\")\n",
        "\n",
        "            rainy_part.save(rainy_output)\n",
        "            non_rainy_part.save(non_rainy_output)\n",
        "\n",
        "            print(f\"Processed: {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "print(f\"Splitting complete! Rainy images saved in {rainy_path}, Non-rainy images saved in {non_rainy_path}.\")\n"
      ],
      "metadata": {
        "id": "XX2btmo4i8RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from models.networks import ResnetGenerator, NLayerDiscriminator  # Use predefined architectures\n",
        "\n",
        "class DeRainCycleGAN:\n",
        "    def __init__(self, input_nc, output_nc, ngf, ndf, device):\n",
        "        self.device = device\n",
        "\n",
        "        # Initialize ResNet-based generators (Rainy -> Clean and Clean -> Rainy)\n",
        "        self.netG_A = ResnetGenerator(input_nc, output_nc, ngf).to(device)  # Rainy -> Clean\n",
        "        self.netG_B = ResnetGenerator(output_nc, input_nc, ngf).to(device)  # Clean -> Rainy\n",
        "\n",
        "        # Initialize PatchGAN-based discriminators\n",
        "        self.netD_A = NLayerDiscriminator(output_nc, ndf).to(device)  # For clean images\n",
        "        self.netD_B = NLayerDiscriminator(input_nc, ndf).to(device)  # For rainy images\n",
        "\n",
        "        # Define loss functions\n",
        "        self.criterionGAN = nn.MSELoss()  # For adversarial loss\n",
        "        self.criterionCycle = nn.L1Loss()  # For cycle consistency loss\n",
        "\n",
        "        # Define optimizers\n",
        "        self.optimizer_G = torch.optim.Adam(\n",
        "            list(self.netG_A.parameters()) + list(self.netG_B.parameters()), lr=0.0002, betas=(0.5, 0.999)\n",
        "        )\n",
        "        self.optimizer_D = torch.optim.Adam(\n",
        "            list(self.netD_A.parameters()) + list(self.netD_B.parameters()), lr=0.0002, betas=(0.5, 0.999)\n",
        "        )\n",
        "\n",
        "    def forward(self, real_A, real_B):\n",
        "        # Forward cycle (Rainy -> Clean -> Rainy)\n",
        "        fake_B = self.netG_A(real_A)  # Rainy -> Clean\n",
        "        rec_A = self.netG_B(fake_B)  # Clean -> Rainy -> Reconstruct Rainy\n",
        "\n",
        "        # Backward cycle (Clean -> Rainy -> Clean)\n",
        "        fake_A = self.netG_B(real_B)  # Clean -> Rainy\n",
        "        rec_B = self.netG_A(fake_A)  # Rainy -> Clean -> Reconstruct Clean\n",
        "\n",
        "        return fake_B, rec_A, fake_A, rec_B\n",
        "\n",
        "    def backward_G(self, real_A, real_B, fake_B, rec_A, fake_A, rec_B):\n",
        "        # GAN loss\n",
        "        loss_G_A = self.criterionGAN(self.netD_A(fake_B), torch.ones_like(fake_B))  # Rainy -> Clean\n",
        "        loss_G_B = self.criterionGAN(self.netD_B(fake_A), torch.ones_like(fake_A))  # Clean -> Rainy\n",
        "\n",
        "        # Cycle consistency loss\n",
        "        loss_cycle_A = self.criterionCycle(rec_A, real_A) * 10.0  # Rainy -> Clean -> Rainy\n",
        "        loss_cycle_B = self.criterionCycle(rec_B, real_B) * 10.0  # Clean -> Rainy -> Clean\n",
        "\n",
        "        # Total generator loss\n",
        "        loss_G = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B\n",
        "        loss_G.backward()\n",
        "        return loss_G\n",
        "\n",
        "    def backward_D(self, netD, real, fake):\n",
        "        # Real loss\n",
        "        pred_real = netD(real)\n",
        "        loss_D_real = self.criterionGAN(pred_real, torch.ones_like(pred_real))\n",
        "\n",
        "        # Fake loss\n",
        "        pred_fake = netD(fake.detach())\n",
        "        loss_D_fake = self.criterionGAN(pred_fake, torch.zeros_like(pred_fake))\n",
        "\n",
        "        # Total discriminator loss\n",
        "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
        "        loss_D.backward()\n",
        "        return loss_D\n",
        "\n",
        "    def optimize_parameters(self, real_A, real_B):\n",
        "        # Forward pass\n",
        "        fake_B, rec_A, fake_A, rec_B = self.forward(real_A, real_B)\n",
        "\n",
        "        # Update G (Generators)\n",
        "        self.optimizer_G.zero_grad()\n",
        "        loss_G = self.backward_G(real_A, real_B, fake_B, rec_A, fake_A, rec_B)\n",
        "        self.optimizer_G.step()\n",
        "\n",
        "        # Update D_A (Discriminator for Clean Images)\n",
        "        self.optimizer_D.zero_grad()\n",
        "        loss_D_A = self.backward_D(self.netD_A, real_B, fake_B)\n",
        "        self.optimizer_D.step()\n",
        "\n",
        "        # Update D_B (Discriminator for Rainy Images)\n",
        "        self.optimizer_D.zero_grad()\n",
        "        loss_D_B = self.backward_D(self.netD_B, real_A, fake_A)\n",
        "        self.optimizer_D.step()\n",
        "\n",
        "        return loss_G, loss_D_A, loss_D_B\n"
      ],
      "metadata": {
        "id": "pr3E3jia4nxY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "from models.networks import ResnetGenerator, NLayerDiscriminator  # Use predefined architectures\n",
        "\n",
        "class RainDataset(Dataset):\n",
        "    def __init__(self, input_dir, target_dir, transform=None, sample_size=None):\n",
        "        self.input_dir = input_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.transform = transform\n",
        "        self.input_images = sorted(os.listdir(input_dir))\n",
        "        self.target_images = sorted(os.listdir(target_dir))\n",
        "\n",
        "        # Randomly sample a subset if sample_size is provided\n",
        "        if sample_size is not None:\n",
        "            indices = random.sample(range(len(self.input_images)), sample_size)\n",
        "            self.input_images = [self.input_images[i] for i in indices]\n",
        "            self.target_images = [self.target_images[i] for i in indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_img_path = os.path.join(self.input_dir, self.input_images[idx])\n",
        "        target_img_path = os.path.join(self.target_dir, self.target_images[idx])\n",
        "\n",
        "        input_image = Image.open(input_img_path).convert(\"RGB\")\n",
        "        target_image = Image.open(target_img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            input_image = self.transform(input_image)\n",
        "            target_image = self.transform(target_image)\n",
        "\n",
        "        return input_image, target_image, self.input_images[idx]\n",
        "\n",
        "class DeRainCycleGAN:\n",
        "    def __init__(self, input_nc, output_nc, ngf, ndf, device):\n",
        "        self.device = device\n",
        "\n",
        "        # Initialize ResNet-based generators (Rainy -> Clean and Clean -> Rainy)\n",
        "        self.netG_A = ResnetGenerator(input_nc, output_nc, ngf).to(device)  # Rainy -> Clean\n",
        "        self.netG_B = ResnetGenerator(output_nc, input_nc, ngf).to(device)  # Clean -> Rainy\n",
        "\n",
        "        # Initialize PatchGAN-based discriminators\n",
        "        self.netD_A = NLayerDiscriminator(output_nc, ndf).to(device)  # For clean images\n",
        "        self.netD_B = NLayerDiscriminator(input_nc, ndf).to(device)  # For rainy images\n",
        "\n",
        "        # Define loss functions\n",
        "        self.criterionGAN = nn.MSELoss()  # For adversarial loss\n",
        "        self.criterionCycle = nn.L1Loss()  # For cycle consistency loss\n",
        "\n",
        "        # Define optimizers\n",
        "        self.optimizer_G = torch.optim.Adam(\n",
        "            list(self.netG_A.parameters()) + list(self.netG_B.parameters()), lr=0.0002, betas=(0.5, 0.999)\n",
        "        )\n",
        "        self.optimizer_D = torch.optim.Adam(\n",
        "            list(self.netD_A.parameters()) + list(self.netD_B.parameters()), lr=0.0002, betas=(0.5, 0.999)\n",
        "        )\n",
        "\n",
        "    def forward(self, real_A, real_B):\n",
        "        # Forward cycle (Rainy -> Clean -> Rainy)\n",
        "        fake_B = self.netG_A(real_A)  # Rainy -> Clean\n",
        "        rec_A = self.netG_B(fake_B)  # Clean -> Rainy -> Reconstruct Rainy\n",
        "\n",
        "        # Backward cycle (Clean -> Rainy -> Clean)\n",
        "        fake_A = self.netG_B(real_B)  # Clean -> Rainy\n",
        "        rec_B = self.netG_A(fake_A)  # Rainy -> Clean -> Reconstruct Clean\n",
        "\n",
        "        return fake_B, rec_A, fake_A, rec_B\n",
        "\n",
        "    def backward_G(self, real_A, real_B, fake_B, rec_A, fake_A, rec_B):\n",
        "        # GAN loss\n",
        "        loss_G_A = self.criterionGAN(self.netD_A(fake_B), torch.ones_like(self.netD_A(fake_B)))  # Rainy -> Clean\n",
        "        loss_G_B = self.criterionGAN(self.netD_B(fake_A), torch.ones_like(self.netD_B(fake_A)))  # Clean -> Rainy\n",
        "\n",
        "        # Cycle consistency loss\n",
        "        loss_cycle_A = self.criterionCycle(rec_A, real_A) * 10.0  # Rainy -> Clean -> Rainy\n",
        "        loss_cycle_B = self.criterionCycle(rec_B, real_B) * 10.0  # Clean -> Rainy -> Clean\n",
        "\n",
        "        # Total generator loss\n",
        "        loss_G = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B\n",
        "        loss_G.backward()\n",
        "        return loss_G\n",
        "\n",
        "    def backward_D(self, netD, real, fake):\n",
        "        # Real loss\n",
        "        pred_real = netD(real)\n",
        "        loss_D_real = self.criterionGAN(pred_real, torch.ones_like(pred_real))\n",
        "\n",
        "        # Fake loss\n",
        "        pred_fake = netD(fake.detach())\n",
        "        loss_D_fake = self.criterionGAN(pred_fake, torch.zeros_like(pred_fake))\n",
        "\n",
        "        # Total discriminator loss\n",
        "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
        "        loss_D.backward()\n",
        "        return loss_D\n",
        "\n",
        "    def optimize_parameters(self, real_A, real_B):\n",
        "        # Forward pass\n",
        "        fake_B, rec_A, fake_A, rec_B = self.forward(real_A, real_B)\n",
        "\n",
        "        # Update G (Generators)\n",
        "        self.optimizer_G.zero_grad()\n",
        "        loss_G = self.backward_G(real_A, real_B, fake_B, rec_A, fake_A, rec_B)\n",
        "        self.optimizer_G.step()\n",
        "\n",
        "        # Update D_A (Discriminator for Clean Images)\n",
        "        self.optimizer_D.zero_grad()\n",
        "        loss_D_A = self.backward_D(self.netD_A, real_B, fake_B)\n",
        "        self.optimizer_D.step()\n",
        "\n",
        "        # Update D_B (Discriminator for Rainy Images)\n",
        "        self.optimizer_D.zero_grad()\n",
        "        loss_D_B = self.backward_D(self.netD_B, real_A, fake_A)\n",
        "        self.optimizer_D.step()\n",
        "\n",
        "        return loss_G, loss_D_A, loss_D_B\n"
      ],
      "metadata": {
        "id": "t4aaBymOOZ5P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize dataset paths and DataLoader\n",
        "input_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain100L/input\"\n",
        "target_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain100L/target\"\n",
        "output_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain100L/results_3/\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Limit dataset to 10 samples for trial purposes\n",
        "train_loader = DataLoader(RainDataset(input_dir, target_dir, transform, sample_size=100), batch_size=8, shuffle=True)\n",
        "\n",
        "# Initialize and train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model = DeRainCycleGAN(input_nc=3, output_nc=3, ngf=64, ndf=64, device=device)\n",
        "\n",
        "# Add learning rate schedulers\n",
        "scheduler_G = torch.optim.lr_scheduler.StepLR(model.optimizer_G, step_size=20, gamma=0.5)\n",
        "scheduler_D = torch.optim.lr_scheduler.StepLR(model.optimizer_D, step_size=20, gamma=0.5)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(60):  # Number of epochs\n",
        "    model.netG_A.train()\n",
        "    model.netG_B.train()\n",
        "    epoch_loss_G, epoch_loss_D_A, epoch_loss_D_B = 0, 0, 0\n",
        "\n",
        "    for i, (real_A, real_B, img_name) in enumerate(train_loader):\n",
        "        real_A, real_B = real_A.to(device), real_B.to(device)\n",
        "\n",
        "        # Forward pass and optimization\n",
        "        loss_G, loss_D_A, loss_D_B = model.optimize_parameters(real_A, real_B)\n",
        "        epoch_loss_G += loss_G.item()\n",
        "        epoch_loss_D_A += loss_D_A.item()\n",
        "        epoch_loss_D_B += loss_D_B.item()\n",
        "\n",
        "        # Prevent runtime disconnection\n",
        "        print(f\"Epoch {epoch}/{60}, Batch {i}/{len(train_loader)}, Image: {img_name[0]}, Loss_G: {loss_G:.4f}, Loss_D_A: {loss_D_A:.4f}, Loss_D_B: {loss_D_B:.4f}\")\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler_G.step()\n",
        "    scheduler_D.step()\n",
        "\n",
        "    # Save generated images every 25 epochs and at the final epoch\n",
        "    if epoch % 30 == 0 or epoch == 59:  # Save images for epochs 0, 30, and the final epoch\n",
        "        model.netG_A.eval()  # Use the Rainy -> Clean generator\n",
        "        with torch.no_grad():\n",
        "            for i, (real_A, _, img_names) in enumerate(train_loader):  # Iterate over all batches\n",
        "                real_A = real_A.to(model.device)\n",
        "                fake_B = model.netG_A(real_A)  # Rainy -> Clean\n",
        "\n",
        "                # Save each image in the batch\n",
        "                for j in range(real_A.size(0)):  # Loop through images in the current batch\n",
        "                    img_name = img_names[j]  # Name of the image\n",
        "                    save_path = os.path.join(output_dir, f\"epoch_{epoch}_de_rained_{img_name}\")\n",
        "                    save_image(fake_B[j], save_path)  # Save individual images\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUX1yheK7O3l",
        "outputId": "e156c40a-bca1-4bea-a710-def07f637120"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch 0/60, Batch 0/13, Image: 96.png, Loss_G: 13.0750, Loss_D_A: 0.8836, Loss_D_B: 0.7776\n",
            "Epoch 0/60, Batch 1/13, Image: 72.png, Loss_G: 9.0179, Loss_D_A: 1.9938, Loss_D_B: 1.1945\n",
            "Epoch 0/60, Batch 2/13, Image: 17.png, Loss_G: 8.0362, Loss_D_A: 0.8726, Loss_D_B: 0.8749\n",
            "Epoch 0/60, Batch 3/13, Image: 42.png, Loss_G: 8.7849, Loss_D_A: 2.1532, Loss_D_B: 1.0016\n",
            "Epoch 0/60, Batch 4/13, Image: 28.png, Loss_G: 9.2781, Loss_D_A: 0.4794, Loss_D_B: 1.0131\n",
            "Epoch 0/60, Batch 5/13, Image: 30.png, Loss_G: 8.3922, Loss_D_A: 0.4736, Loss_D_B: 0.6537\n",
            "Epoch 0/60, Batch 6/13, Image: 53.png, Loss_G: 7.1460, Loss_D_A: 0.3698, Loss_D_B: 0.4094\n",
            "Epoch 0/60, Batch 7/13, Image: 82.png, Loss_G: 6.9584, Loss_D_A: 0.3112, Loss_D_B: 0.3227\n",
            "Epoch 0/60, Batch 8/13, Image: 93.png, Loss_G: 5.5604, Loss_D_A: 0.2816, Loss_D_B: 0.2725\n",
            "Epoch 0/60, Batch 9/13, Image: 92.png, Loss_G: 5.2531, Loss_D_A: 0.2592, Loss_D_B: 0.2660\n",
            "Epoch 0/60, Batch 10/13, Image: 94.png, Loss_G: 4.7053, Loss_D_A: 0.2564, Loss_D_B: 0.2468\n",
            "Epoch 0/60, Batch 11/13, Image: 5.png, Loss_G: 4.9265, Loss_D_A: 0.2359, Loss_D_B: 0.2208\n",
            "Epoch 0/60, Batch 12/13, Image: 88.png, Loss_G: 5.7213, Loss_D_A: 0.2573, Loss_D_B: 0.2586\n",
            "Epoch 1/60, Batch 0/13, Image: 90.png, Loss_G: 5.8003, Loss_D_A: 0.2485, Loss_D_B: 0.2576\n",
            "Epoch 1/60, Batch 1/13, Image: 13.png, Loss_G: 4.7494, Loss_D_A: 0.2271, Loss_D_B: 0.2220\n",
            "Epoch 1/60, Batch 2/13, Image: 23.png, Loss_G: 4.9386, Loss_D_A: 0.2278, Loss_D_B: 0.2185\n",
            "Epoch 1/60, Batch 3/13, Image: 73.png, Loss_G: 5.2780, Loss_D_A: 0.2395, Loss_D_B: 0.2172\n",
            "Epoch 1/60, Batch 4/13, Image: 56.png, Loss_G: 4.6522, Loss_D_A: 0.2161, Loss_D_B: 0.2468\n",
            "Epoch 1/60, Batch 5/13, Image: 31.png, Loss_G: 5.2003, Loss_D_A: 0.2284, Loss_D_B: 0.2852\n",
            "Epoch 1/60, Batch 6/13, Image: 52.png, Loss_G: 4.8051, Loss_D_A: 0.2154, Loss_D_B: 0.2651\n",
            "Epoch 1/60, Batch 7/13, Image: 77.png, Loss_G: 4.5432, Loss_D_A: 0.2212, Loss_D_B: 0.2371\n",
            "Epoch 1/60, Batch 8/13, Image: 37.png, Loss_G: 5.6104, Loss_D_A: 0.2647, Loss_D_B: 0.2312\n",
            "Epoch 1/60, Batch 9/13, Image: 10.png, Loss_G: 5.2399, Loss_D_A: 0.3043, Loss_D_B: 0.2171\n",
            "Epoch 1/60, Batch 10/13, Image: 19.png, Loss_G: 4.9875, Loss_D_A: 0.3452, Loss_D_B: 0.2091\n",
            "Epoch 1/60, Batch 11/13, Image: 24.png, Loss_G: 4.9595, Loss_D_A: 0.3117, Loss_D_B: 0.2331\n",
            "Epoch 1/60, Batch 12/13, Image: 15.png, Loss_G: 4.9579, Loss_D_A: 0.2323, Loss_D_B: 0.2401\n",
            "Epoch 2/60, Batch 0/13, Image: 40.png, Loss_G: 5.4191, Loss_D_A: 0.2453, Loss_D_B: 0.2955\n",
            "Epoch 2/60, Batch 1/13, Image: 1.png, Loss_G: 4.8195, Loss_D_A: 0.2037, Loss_D_B: 0.2262\n",
            "Epoch 2/60, Batch 2/13, Image: 12.png, Loss_G: 5.1718, Loss_D_A: 0.1868, Loss_D_B: 0.1874\n",
            "Epoch 2/60, Batch 3/13, Image: 80.png, Loss_G: 5.5123, Loss_D_A: 0.2095, Loss_D_B: 0.2105\n",
            "Epoch 2/60, Batch 4/13, Image: 20.png, Loss_G: 4.8011, Loss_D_A: 0.2252, Loss_D_B: 0.2138\n",
            "Epoch 2/60, Batch 5/13, Image: 59.png, Loss_G: 4.5668, Loss_D_A: 0.2015, Loss_D_B: 0.1861\n",
            "Epoch 2/60, Batch 6/13, Image: 23.png, Loss_G: 5.6293, Loss_D_A: 0.1979, Loss_D_B: 0.1852\n",
            "Epoch 2/60, Batch 7/13, Image: 30.png, Loss_G: 5.3783, Loss_D_A: 0.2069, Loss_D_B: 0.1926\n",
            "Epoch 2/60, Batch 8/13, Image: 44.png, Loss_G: 5.4831, Loss_D_A: 0.1964, Loss_D_B: 0.1791\n",
            "Epoch 2/60, Batch 9/13, Image: 78.png, Loss_G: 5.2242, Loss_D_A: 0.2238, Loss_D_B: 0.2021\n",
            "Epoch 2/60, Batch 10/13, Image: 51.png, Loss_G: 5.6318, Loss_D_A: 0.2288, Loss_D_B: 0.2276\n",
            "Epoch 2/60, Batch 11/13, Image: 21.png, Loss_G: 4.8195, Loss_D_A: 0.1819, Loss_D_B: 0.1721\n",
            "Epoch 2/60, Batch 12/13, Image: 99.png, Loss_G: 5.7190, Loss_D_A: 0.1879, Loss_D_B: 0.1854\n",
            "Epoch 3/60, Batch 0/13, Image: 40.png, Loss_G: 5.1212, Loss_D_A: 0.1731, Loss_D_B: 0.1539\n",
            "Epoch 3/60, Batch 1/13, Image: 4.png, Loss_G: 4.4346, Loss_D_A: 0.1654, Loss_D_B: 0.1485\n",
            "Epoch 3/60, Batch 2/13, Image: 72.png, Loss_G: 4.3855, Loss_D_A: 0.1715, Loss_D_B: 0.1445\n",
            "Epoch 3/60, Batch 3/13, Image: 45.png, Loss_G: 4.3912, Loss_D_A: 0.1741, Loss_D_B: 0.1465\n",
            "Epoch 3/60, Batch 4/13, Image: 19.png, Loss_G: 4.5003, Loss_D_A: 0.1817, Loss_D_B: 0.1591\n",
            "Epoch 3/60, Batch 5/13, Image: 5.png, Loss_G: 4.5583, Loss_D_A: 0.2205, Loss_D_B: 0.2035\n",
            "Epoch 3/60, Batch 6/13, Image: 51.png, Loss_G: 5.6747, Loss_D_A: 0.2304, Loss_D_B: 0.1775\n",
            "Epoch 3/60, Batch 7/13, Image: 91.png, Loss_G: 4.9684, Loss_D_A: 0.2740, Loss_D_B: 0.1994\n",
            "Epoch 3/60, Batch 8/13, Image: 84.png, Loss_G: 4.8471, Loss_D_A: 0.2727, Loss_D_B: 0.2228\n",
            "Epoch 3/60, Batch 9/13, Image: 80.png, Loss_G: 5.0574, Loss_D_A: 0.2725, Loss_D_B: 0.2465\n",
            "Epoch 3/60, Batch 10/13, Image: 70.png, Loss_G: 4.5606, Loss_D_A: 0.2083, Loss_D_B: 0.2522\n",
            "Epoch 3/60, Batch 11/13, Image: 59.png, Loss_G: 4.5045, Loss_D_A: 0.2235, Loss_D_B: 0.2335\n",
            "Epoch 3/60, Batch 12/13, Image: 64.png, Loss_G: 5.5260, Loss_D_A: 0.1478, Loss_D_B: 0.1448\n",
            "Epoch 4/60, Batch 0/13, Image: 58.png, Loss_G: 5.3291, Loss_D_A: 0.1870, Loss_D_B: 0.2159\n",
            "Epoch 4/60, Batch 1/13, Image: 50.png, Loss_G: 6.8604, Loss_D_A: 0.1768, Loss_D_B: 0.2141\n",
            "Epoch 4/60, Batch 2/13, Image: 17.png, Loss_G: 6.5591, Loss_D_A: 0.1605, Loss_D_B: 0.2018\n",
            "Epoch 4/60, Batch 3/13, Image: 77.png, Loss_G: 4.2546, Loss_D_A: 0.1651, Loss_D_B: 0.1482\n",
            "Epoch 4/60, Batch 4/13, Image: 35.png, Loss_G: 5.4590, Loss_D_A: 0.1726, Loss_D_B: 0.1650\n",
            "Epoch 4/60, Batch 5/13, Image: 82.png, Loss_G: 4.3622, Loss_D_A: 0.1629, Loss_D_B: 0.1855\n",
            "Epoch 4/60, Batch 6/13, Image: 36.png, Loss_G: 4.3609, Loss_D_A: 0.1517, Loss_D_B: 0.1691\n",
            "Epoch 4/60, Batch 7/13, Image: 72.png, Loss_G: 4.8392, Loss_D_A: 0.1581, Loss_D_B: 0.1968\n",
            "Epoch 4/60, Batch 8/13, Image: 22.png, Loss_G: 4.7212, Loss_D_A: 0.2369, Loss_D_B: 0.2405\n",
            "Epoch 4/60, Batch 9/13, Image: 74.png, Loss_G: 5.5924, Loss_D_A: 0.2521, Loss_D_B: 0.3096\n",
            "Epoch 4/60, Batch 10/13, Image: 95.png, Loss_G: 4.7410, Loss_D_A: 0.1896, Loss_D_B: 0.1872\n",
            "Epoch 4/60, Batch 11/13, Image: 90.png, Loss_G: 4.5526, Loss_D_A: 0.1818, Loss_D_B: 0.1969\n",
            "Epoch 4/60, Batch 12/13, Image: 54.png, Loss_G: 4.4362, Loss_D_A: 0.1654, Loss_D_B: 0.1732\n",
            "Epoch 5/60, Batch 0/13, Image: 88.png, Loss_G: 4.4440, Loss_D_A: 0.1961, Loss_D_B: 0.1838\n",
            "Epoch 5/60, Batch 1/13, Image: 5.png, Loss_G: 4.4888, Loss_D_A: 0.2132, Loss_D_B: 0.1991\n",
            "Epoch 5/60, Batch 2/13, Image: 76.png, Loss_G: 4.3549, Loss_D_A: 0.2699, Loss_D_B: 0.1859\n",
            "Epoch 5/60, Batch 3/13, Image: 68.png, Loss_G: 5.8785, Loss_D_A: 0.4501, Loss_D_B: 0.2470\n",
            "Epoch 5/60, Batch 4/13, Image: 45.png, Loss_G: 5.6038, Loss_D_A: 0.6241, Loss_D_B: 0.1725\n",
            "Epoch 5/60, Batch 5/13, Image: 92.png, Loss_G: 5.0815, Loss_D_A: 0.5400, Loss_D_B: 0.1734\n",
            "Epoch 5/60, Batch 6/13, Image: 39.png, Loss_G: 4.8246, Loss_D_A: 0.3372, Loss_D_B: 0.2140\n",
            "Epoch 5/60, Batch 7/13, Image: 77.png, Loss_G: 4.5892, Loss_D_A: 0.2248, Loss_D_B: 0.2151\n",
            "Epoch 5/60, Batch 8/13, Image: 66.png, Loss_G: 4.2411, Loss_D_A: 0.1722, Loss_D_B: 0.3096\n",
            "Epoch 5/60, Batch 9/13, Image: 12.png, Loss_G: 4.7861, Loss_D_A: 0.2122, Loss_D_B: 0.6817\n",
            "Epoch 5/60, Batch 10/13, Image: 91.png, Loss_G: 5.1330, Loss_D_A: 0.1691, Loss_D_B: 1.1551\n",
            "Epoch 5/60, Batch 11/13, Image: 53.png, Loss_G: 5.0810, Loss_D_A: 0.1511, Loss_D_B: 0.9516\n",
            "Epoch 5/60, Batch 12/13, Image: 57.png, Loss_G: 4.5737, Loss_D_A: 0.2355, Loss_D_B: 0.4849\n",
            "Epoch 6/60, Batch 0/13, Image: 24.png, Loss_G: 5.2111, Loss_D_A: 0.1601, Loss_D_B: 0.2620\n",
            "Epoch 6/60, Batch 1/13, Image: 19.png, Loss_G: 3.8203, Loss_D_A: 0.1666, Loss_D_B: 0.2619\n",
            "Epoch 6/60, Batch 2/13, Image: 31.png, Loss_G: 4.2704, Loss_D_A: 0.1709, Loss_D_B: 0.2227\n",
            "Epoch 6/60, Batch 3/13, Image: 28.png, Loss_G: 3.6149, Loss_D_A: 0.1525, Loss_D_B: 0.2097\n",
            "Epoch 6/60, Batch 4/13, Image: 45.png, Loss_G: 4.3837, Loss_D_A: 0.1478, Loss_D_B: 0.2130\n",
            "Epoch 6/60, Batch 5/13, Image: 35.png, Loss_G: 4.3872, Loss_D_A: 0.1596, Loss_D_B: 0.1985\n",
            "Epoch 6/60, Batch 6/13, Image: 75.png, Loss_G: 4.3345, Loss_D_A: 0.1535, Loss_D_B: 0.1969\n",
            "Epoch 6/60, Batch 7/13, Image: 38.png, Loss_G: 3.6519, Loss_D_A: 0.1283, Loss_D_B: 0.1949\n",
            "Epoch 6/60, Batch 8/13, Image: 5.png, Loss_G: 4.0075, Loss_D_A: 0.1736, Loss_D_B: 0.2134\n",
            "Epoch 6/60, Batch 9/13, Image: 18.png, Loss_G: 3.7792, Loss_D_A: 0.1678, Loss_D_B: 0.2041\n",
            "Epoch 6/60, Batch 10/13, Image: 40.png, Loss_G: 3.9274, Loss_D_A: 0.1611, Loss_D_B: 0.1861\n",
            "Epoch 6/60, Batch 11/13, Image: 88.png, Loss_G: 4.5373, Loss_D_A: 0.2073, Loss_D_B: 0.1685\n",
            "Epoch 6/60, Batch 12/13, Image: 46.png, Loss_G: 5.1962, Loss_D_A: 0.2577, Loss_D_B: 0.2099\n",
            "Epoch 7/60, Batch 0/13, Image: 57.png, Loss_G: 5.3040, Loss_D_A: 0.2045, Loss_D_B: 0.2192\n",
            "Epoch 7/60, Batch 1/13, Image: 6.png, Loss_G: 3.9620, Loss_D_A: 0.2105, Loss_D_B: 0.1958\n",
            "Epoch 7/60, Batch 2/13, Image: 18.png, Loss_G: 4.3357, Loss_D_A: 0.2325, Loss_D_B: 0.1987\n",
            "Epoch 7/60, Batch 3/13, Image: 39.png, Loss_G: 4.0096, Loss_D_A: 0.1855, Loss_D_B: 0.1618\n",
            "Epoch 7/60, Batch 4/13, Image: 82.png, Loss_G: 3.8690, Loss_D_A: 0.2593, Loss_D_B: 0.2341\n",
            "Epoch 7/60, Batch 5/13, Image: 22.png, Loss_G: 3.6186, Loss_D_A: 0.2210, Loss_D_B: 0.1948\n",
            "Epoch 7/60, Batch 6/13, Image: 83.png, Loss_G: 4.4014, Loss_D_A: 0.2363, Loss_D_B: 0.2021\n",
            "Epoch 7/60, Batch 7/13, Image: 77.png, Loss_G: 3.8616, Loss_D_A: 0.2793, Loss_D_B: 0.2406\n",
            "Epoch 7/60, Batch 8/13, Image: 79.png, Loss_G: 4.1599, Loss_D_A: 0.1793, Loss_D_B: 0.1938\n",
            "Epoch 7/60, Batch 9/13, Image: 61.png, Loss_G: 4.0698, Loss_D_A: 0.1827, Loss_D_B: 0.2147\n",
            "Epoch 7/60, Batch 10/13, Image: 45.png, Loss_G: 3.8831, Loss_D_A: 0.1858, Loss_D_B: 0.2487\n",
            "Epoch 7/60, Batch 11/13, Image: 54.png, Loss_G: 5.1893, Loss_D_A: 0.2115, Loss_D_B: 0.3350\n",
            "Epoch 7/60, Batch 12/13, Image: 70.png, Loss_G: 7.8434, Loss_D_A: 0.2458, Loss_D_B: 0.4272\n",
            "Epoch 8/60, Batch 0/13, Image: 40.png, Loss_G: 4.5813, Loss_D_A: 0.2360, Loss_D_B: 0.3173\n",
            "Epoch 8/60, Batch 1/13, Image: 80.png, Loss_G: 4.5444, Loss_D_A: 0.2294, Loss_D_B: 0.2030\n",
            "Epoch 8/60, Batch 2/13, Image: 95.png, Loss_G: 4.4260, Loss_D_A: 0.2766, Loss_D_B: 0.2749\n",
            "Epoch 8/60, Batch 3/13, Image: 27.png, Loss_G: 4.4634, Loss_D_A: 0.1721, Loss_D_B: 0.1615\n",
            "Epoch 8/60, Batch 4/13, Image: 49.png, Loss_G: 4.1503, Loss_D_A: 0.1864, Loss_D_B: 0.1969\n",
            "Epoch 8/60, Batch 5/13, Image: 100.png, Loss_G: 4.2423, Loss_D_A: 0.2037, Loss_D_B: 0.2026\n",
            "Epoch 8/60, Batch 6/13, Image: 81.png, Loss_G: 4.0884, Loss_D_A: 0.1914, Loss_D_B: 0.1895\n",
            "Epoch 8/60, Batch 7/13, Image: 28.png, Loss_G: 4.5494, Loss_D_A: 0.1847, Loss_D_B: 0.1875\n",
            "Epoch 8/60, Batch 8/13, Image: 11.png, Loss_G: 4.0751, Loss_D_A: 0.1749, Loss_D_B: 0.1810\n",
            "Epoch 8/60, Batch 9/13, Image: 87.png, Loss_G: 3.7488, Loss_D_A: 0.1783, Loss_D_B: 0.1520\n",
            "Epoch 8/60, Batch 10/13, Image: 21.png, Loss_G: 4.0794, Loss_D_A: 0.1854, Loss_D_B: 0.1816\n",
            "Epoch 8/60, Batch 11/13, Image: 29.png, Loss_G: 4.3008, Loss_D_A: 0.1832, Loss_D_B: 0.2064\n",
            "Epoch 8/60, Batch 12/13, Image: 88.png, Loss_G: 5.1641, Loss_D_A: 0.2761, Loss_D_B: 0.2924\n",
            "Epoch 9/60, Batch 0/13, Image: 36.png, Loss_G: 4.4548, Loss_D_A: 0.1648, Loss_D_B: 0.2131\n",
            "Epoch 9/60, Batch 1/13, Image: 24.png, Loss_G: 4.8993, Loss_D_A: 0.1618, Loss_D_B: 0.1735\n",
            "Epoch 9/60, Batch 2/13, Image: 20.png, Loss_G: 3.8988, Loss_D_A: 0.1678, Loss_D_B: 0.1524\n",
            "Epoch 9/60, Batch 3/13, Image: 99.png, Loss_G: 4.2938, Loss_D_A: 0.2842, Loss_D_B: 0.1870\n",
            "Epoch 9/60, Batch 4/13, Image: 1.png, Loss_G: 4.0627, Loss_D_A: 0.2849, Loss_D_B: 0.1940\n",
            "Epoch 9/60, Batch 5/13, Image: 90.png, Loss_G: 4.3508, Loss_D_A: 0.3093, Loss_D_B: 0.2194\n",
            "Epoch 9/60, Batch 6/13, Image: 83.png, Loss_G: 4.5687, Loss_D_A: 0.2863, Loss_D_B: 0.1907\n",
            "Epoch 9/60, Batch 7/13, Image: 10.png, Loss_G: 5.6621, Loss_D_A: 0.2939, Loss_D_B: 0.2080\n",
            "Epoch 9/60, Batch 8/13, Image: 79.png, Loss_G: 4.6468, Loss_D_A: 0.1588, Loss_D_B: 0.1331\n",
            "Epoch 9/60, Batch 9/13, Image: 87.png, Loss_G: 4.3389, Loss_D_A: 0.1859, Loss_D_B: 0.1865\n",
            "Epoch 9/60, Batch 10/13, Image: 15.png, Loss_G: 4.3021, Loss_D_A: 0.1763, Loss_D_B: 0.1616\n",
            "Epoch 9/60, Batch 11/13, Image: 88.png, Loss_G: 4.7998, Loss_D_A: 0.3096, Loss_D_B: 0.2394\n",
            "Epoch 9/60, Batch 12/13, Image: 13.png, Loss_G: 4.3645, Loss_D_A: 0.2155, Loss_D_B: 0.1716\n",
            "Epoch 10/60, Batch 0/13, Image: 10.png, Loss_G: 4.7461, Loss_D_A: 0.1880, Loss_D_B: 0.1594\n",
            "Epoch 10/60, Batch 1/13, Image: 3.png, Loss_G: 4.0016, Loss_D_A: 0.2217, Loss_D_B: 0.2102\n",
            "Epoch 10/60, Batch 2/13, Image: 79.png, Loss_G: 3.8552, Loss_D_A: 0.2006, Loss_D_B: 0.1907\n",
            "Epoch 10/60, Batch 3/13, Image: 96.png, Loss_G: 4.0087, Loss_D_A: 0.1595, Loss_D_B: 0.1760\n",
            "Epoch 10/60, Batch 4/13, Image: 51.png, Loss_G: 4.1051, Loss_D_A: 0.1943, Loss_D_B: 0.2200\n",
            "Epoch 10/60, Batch 5/13, Image: 26.png, Loss_G: 4.6648, Loss_D_A: 0.1551, Loss_D_B: 0.2148\n",
            "Epoch 10/60, Batch 6/13, Image: 71.png, Loss_G: 4.6769, Loss_D_A: 0.1626, Loss_D_B: 0.2293\n",
            "Epoch 10/60, Batch 7/13, Image: 37.png, Loss_G: 3.9089, Loss_D_A: 0.2196, Loss_D_B: 0.2178\n",
            "Epoch 10/60, Batch 8/13, Image: 57.png, Loss_G: 3.4646, Loss_D_A: 0.2392, Loss_D_B: 0.2190\n",
            "Epoch 10/60, Batch 9/13, Image: 56.png, Loss_G: 4.0240, Loss_D_A: 0.2206, Loss_D_B: 0.1932\n",
            "Epoch 10/60, Batch 10/13, Image: 62.png, Loss_G: 4.1221, Loss_D_A: 0.1643, Loss_D_B: 0.1852\n",
            "Epoch 10/60, Batch 11/13, Image: 20.png, Loss_G: 3.8310, Loss_D_A: 0.2395, Loss_D_B: 0.2338\n",
            "Epoch 10/60, Batch 12/13, Image: 7.png, Loss_G: 4.2405, Loss_D_A: 0.2512, Loss_D_B: 0.2359\n",
            "Epoch 11/60, Batch 0/13, Image: 34.png, Loss_G: 4.7096, Loss_D_A: 0.1998, Loss_D_B: 0.1970\n",
            "Epoch 11/60, Batch 1/13, Image: 63.png, Loss_G: 4.0374, Loss_D_A: 0.1938, Loss_D_B: 0.2400\n",
            "Epoch 11/60, Batch 2/13, Image: 95.png, Loss_G: 3.7398, Loss_D_A: 0.1867, Loss_D_B: 0.1941\n",
            "Epoch 11/60, Batch 3/13, Image: 54.png, Loss_G: 4.6519, Loss_D_A: 0.2233, Loss_D_B: 0.1924\n",
            "Epoch 11/60, Batch 4/13, Image: 92.png, Loss_G: 3.8147, Loss_D_A: 0.2210, Loss_D_B: 0.2152\n",
            "Epoch 11/60, Batch 5/13, Image: 44.png, Loss_G: 3.7910, Loss_D_A: 0.1899, Loss_D_B: 0.1747\n",
            "Epoch 11/60, Batch 6/13, Image: 37.png, Loss_G: 4.0977, Loss_D_A: 0.1777, Loss_D_B: 0.1880\n",
            "Epoch 11/60, Batch 7/13, Image: 45.png, Loss_G: 4.1315, Loss_D_A: 0.1361, Loss_D_B: 0.1787\n",
            "Epoch 11/60, Batch 8/13, Image: 30.png, Loss_G: 4.1332, Loss_D_A: 0.2097, Loss_D_B: 0.2530\n",
            "Epoch 11/60, Batch 9/13, Image: 33.png, Loss_G: 3.9477, Loss_D_A: 0.2760, Loss_D_B: 0.3267\n",
            "Epoch 11/60, Batch 10/13, Image: 38.png, Loss_G: 4.0474, Loss_D_A: 0.2562, Loss_D_B: 0.2441\n",
            "Epoch 11/60, Batch 11/13, Image: 66.png, Loss_G: 4.2757, Loss_D_A: 0.3918, Loss_D_B: 0.1857\n",
            "Epoch 11/60, Batch 12/13, Image: 41.png, Loss_G: 4.7163, Loss_D_A: 0.7961, Loss_D_B: 0.2100\n",
            "Epoch 12/60, Batch 0/13, Image: 60.png, Loss_G: 4.2592, Loss_D_A: 0.4839, Loss_D_B: 0.1576\n",
            "Epoch 12/60, Batch 1/13, Image: 73.png, Loss_G: 4.6731, Loss_D_A: 0.6759, Loss_D_B: 0.2389\n",
            "Epoch 12/60, Batch 2/13, Image: 2.png, Loss_G: 4.5904, Loss_D_A: 0.7360, Loss_D_B: 0.1753\n",
            "Epoch 12/60, Batch 3/13, Image: 34.png, Loss_G: 4.3404, Loss_D_A: 0.3698, Loss_D_B: 0.2167\n",
            "Epoch 12/60, Batch 4/13, Image: 47.png, Loss_G: 4.8746, Loss_D_A: 0.2685, Loss_D_B: 0.2597\n",
            "Epoch 12/60, Batch 5/13, Image: 53.png, Loss_G: 7.0037, Loss_D_A: 0.2712, Loss_D_B: 0.2063\n",
            "Epoch 12/60, Batch 6/13, Image: 81.png, Loss_G: 4.1071, Loss_D_A: 0.2648, Loss_D_B: 0.2121\n",
            "Epoch 12/60, Batch 7/13, Image: 41.png, Loss_G: 4.7644, Loss_D_A: 0.2434, Loss_D_B: 0.2052\n",
            "Epoch 12/60, Batch 8/13, Image: 98.png, Loss_G: 3.7442, Loss_D_A: 0.2075, Loss_D_B: 0.1726\n",
            "Epoch 12/60, Batch 9/13, Image: 40.png, Loss_G: 3.1759, Loss_D_A: 0.2263, Loss_D_B: 0.2065\n",
            "Epoch 12/60, Batch 10/13, Image: 70.png, Loss_G: 5.2526, Loss_D_A: 0.2438, Loss_D_B: 0.2828\n",
            "Epoch 12/60, Batch 11/13, Image: 97.png, Loss_G: 4.6770, Loss_D_A: 0.2227, Loss_D_B: 0.3173\n",
            "Epoch 12/60, Batch 12/13, Image: 62.png, Loss_G: 5.0558, Loss_D_A: 0.3048, Loss_D_B: 0.4098\n",
            "Epoch 13/60, Batch 0/13, Image: 30.png, Loss_G: 3.7213, Loss_D_A: 0.2529, Loss_D_B: 0.3052\n",
            "Epoch 13/60, Batch 1/13, Image: 94.png, Loss_G: 3.6579, Loss_D_A: 0.2233, Loss_D_B: 0.2166\n",
            "Epoch 13/60, Batch 2/13, Image: 10.png, Loss_G: 5.4423, Loss_D_A: 0.2053, Loss_D_B: 0.2057\n",
            "Epoch 13/60, Batch 3/13, Image: 70.png, Loss_G: 3.8629, Loss_D_A: 0.2151, Loss_D_B: 0.2183\n",
            "Epoch 13/60, Batch 4/13, Image: 4.png, Loss_G: 3.4447, Loss_D_A: 0.2004, Loss_D_B: 0.1874\n",
            "Epoch 13/60, Batch 5/13, Image: 82.png, Loss_G: 3.8469, Loss_D_A: 0.1916, Loss_D_B: 0.1720\n",
            "Epoch 13/60, Batch 6/13, Image: 97.png, Loss_G: 3.7090, Loss_D_A: 0.1851, Loss_D_B: 0.1506\n",
            "Epoch 13/60, Batch 7/13, Image: 46.png, Loss_G: 3.3355, Loss_D_A: 0.1878, Loss_D_B: 0.1421\n",
            "Epoch 13/60, Batch 8/13, Image: 18.png, Loss_G: 3.6077, Loss_D_A: 0.2127, Loss_D_B: 0.1725\n",
            "Epoch 13/60, Batch 9/13, Image: 58.png, Loss_G: 4.5954, Loss_D_A: 0.2612, Loss_D_B: 0.3279\n",
            "Epoch 13/60, Batch 10/13, Image: 75.png, Loss_G: 5.1173, Loss_D_A: 0.2343, Loss_D_B: 0.3862\n",
            "Epoch 13/60, Batch 11/13, Image: 69.png, Loss_G: 4.2242, Loss_D_A: 0.2144, Loss_D_B: 0.2294\n",
            "Epoch 13/60, Batch 12/13, Image: 32.png, Loss_G: 4.6810, Loss_D_A: 0.1754, Loss_D_B: 0.1585\n",
            "Epoch 14/60, Batch 0/13, Image: 51.png, Loss_G: 6.2540, Loss_D_A: 0.2299, Loss_D_B: 0.2069\n",
            "Epoch 14/60, Batch 1/13, Image: 22.png, Loss_G: 4.1852, Loss_D_A: 0.1873, Loss_D_B: 0.1582\n",
            "Epoch 14/60, Batch 2/13, Image: 80.png, Loss_G: 5.5153, Loss_D_A: 0.1834, Loss_D_B: 0.1698\n",
            "Epoch 14/60, Batch 3/13, Image: 20.png, Loss_G: 4.9466, Loss_D_A: 0.2465, Loss_D_B: 0.2592\n",
            "Epoch 14/60, Batch 4/13, Image: 65.png, Loss_G: 3.7942, Loss_D_A: 0.1805, Loss_D_B: 0.1935\n",
            "Epoch 14/60, Batch 5/13, Image: 43.png, Loss_G: 4.5895, Loss_D_A: 0.1470, Loss_D_B: 0.1503\n",
            "Epoch 14/60, Batch 6/13, Image: 84.png, Loss_G: 5.4847, Loss_D_A: 0.1835, Loss_D_B: 0.1936\n",
            "Epoch 14/60, Batch 7/13, Image: 25.png, Loss_G: 4.1352, Loss_D_A: 0.2051, Loss_D_B: 0.1957\n",
            "Epoch 14/60, Batch 8/13, Image: 88.png, Loss_G: 3.7187, Loss_D_A: 0.1924, Loss_D_B: 0.1868\n",
            "Epoch 14/60, Batch 9/13, Image: 38.png, Loss_G: 3.5115, Loss_D_A: 0.1822, Loss_D_B: 0.1742\n",
            "Epoch 14/60, Batch 10/13, Image: 52.png, Loss_G: 3.9933, Loss_D_A: 0.1402, Loss_D_B: 0.1510\n",
            "Epoch 14/60, Batch 11/13, Image: 59.png, Loss_G: 4.5511, Loss_D_A: 0.1504, Loss_D_B: 0.1593\n",
            "Epoch 14/60, Batch 12/13, Image: 93.png, Loss_G: 4.5502, Loss_D_A: 0.1665, Loss_D_B: 0.1762\n",
            "Epoch 15/60, Batch 0/13, Image: 48.png, Loss_G: 5.7045, Loss_D_A: 0.1544, Loss_D_B: 0.1726\n",
            "Epoch 15/60, Batch 1/13, Image: 45.png, Loss_G: 4.9966, Loss_D_A: 0.1096, Loss_D_B: 0.1244\n",
            "Epoch 15/60, Batch 2/13, Image: 95.png, Loss_G: 3.9796, Loss_D_A: 0.2154, Loss_D_B: 0.2099\n",
            "Epoch 15/60, Batch 3/13, Image: 1.png, Loss_G: 3.7411, Loss_D_A: 0.2745, Loss_D_B: 0.2399\n",
            "Epoch 15/60, Batch 4/13, Image: 8.png, Loss_G: 4.3355, Loss_D_A: 0.2077, Loss_D_B: 0.1862\n",
            "Epoch 15/60, Batch 5/13, Image: 39.png, Loss_G: 4.3833, Loss_D_A: 0.2063, Loss_D_B: 0.1985\n",
            "Epoch 15/60, Batch 6/13, Image: 72.png, Loss_G: 3.9168, Loss_D_A: 0.1683, Loss_D_B: 0.1633\n",
            "Epoch 15/60, Batch 7/13, Image: 51.png, Loss_G: 4.0240, Loss_D_A: 0.2085, Loss_D_B: 0.2092\n",
            "Epoch 15/60, Batch 8/13, Image: 10.png, Loss_G: 4.7551, Loss_D_A: 0.2198, Loss_D_B: 0.2338\n",
            "Epoch 15/60, Batch 9/13, Image: 75.png, Loss_G: 4.0391, Loss_D_A: 0.1800, Loss_D_B: 0.1955\n",
            "Epoch 15/60, Batch 10/13, Image: 37.png, Loss_G: 3.4075, Loss_D_A: 0.1457, Loss_D_B: 0.1821\n",
            "Epoch 15/60, Batch 11/13, Image: 12.png, Loss_G: 4.4458, Loss_D_A: 0.1637, Loss_D_B: 0.2634\n",
            "Epoch 15/60, Batch 12/13, Image: 18.png, Loss_G: 5.2612, Loss_D_A: 0.1889, Loss_D_B: 0.3235\n",
            "Epoch 16/60, Batch 0/13, Image: 68.png, Loss_G: 4.7280, Loss_D_A: 0.2020, Loss_D_B: 0.4018\n",
            "Epoch 16/60, Batch 1/13, Image: 93.png, Loss_G: 4.0148, Loss_D_A: 0.1890, Loss_D_B: 0.4489\n",
            "Epoch 16/60, Batch 2/13, Image: 36.png, Loss_G: 4.3460, Loss_D_A: 0.2431, Loss_D_B: 0.3618\n",
            "Epoch 16/60, Batch 3/13, Image: 3.png, Loss_G: 3.7427, Loss_D_A: 0.2692, Loss_D_B: 0.2223\n",
            "Epoch 16/60, Batch 4/13, Image: 83.png, Loss_G: 4.8652, Loss_D_A: 0.3379, Loss_D_B: 0.2182\n",
            "Epoch 16/60, Batch 5/13, Image: 39.png, Loss_G: 3.8562, Loss_D_A: 0.2574, Loss_D_B: 0.1770\n",
            "Epoch 16/60, Batch 6/13, Image: 35.png, Loss_G: 3.9614, Loss_D_A: 0.2229, Loss_D_B: 0.2002\n",
            "Epoch 16/60, Batch 7/13, Image: 41.png, Loss_G: 3.3341, Loss_D_A: 0.1649, Loss_D_B: 0.1490\n",
            "Epoch 16/60, Batch 8/13, Image: 25.png, Loss_G: 3.6679, Loss_D_A: 0.1588, Loss_D_B: 0.1466\n",
            "Epoch 16/60, Batch 9/13, Image: 90.png, Loss_G: 3.4083, Loss_D_A: 0.2070, Loss_D_B: 0.2009\n",
            "Epoch 16/60, Batch 10/13, Image: 52.png, Loss_G: 3.7567, Loss_D_A: 0.1860, Loss_D_B: 0.2015\n",
            "Epoch 16/60, Batch 11/13, Image: 23.png, Loss_G: 4.1926, Loss_D_A: 0.1792, Loss_D_B: 0.2085\n",
            "Epoch 16/60, Batch 12/13, Image: 32.png, Loss_G: 3.5777, Loss_D_A: 0.2273, Loss_D_B: 0.2364\n",
            "Epoch 17/60, Batch 0/13, Image: 10.png, Loss_G: 4.2503, Loss_D_A: 0.2072, Loss_D_B: 0.2424\n",
            "Epoch 17/60, Batch 1/13, Image: 67.png, Loss_G: 4.3742, Loss_D_A: 0.1553, Loss_D_B: 0.1755\n",
            "Epoch 17/60, Batch 2/13, Image: 49.png, Loss_G: 3.9701, Loss_D_A: 0.1604, Loss_D_B: 0.1624\n",
            "Epoch 17/60, Batch 3/13, Image: 14.png, Loss_G: 5.1079, Loss_D_A: 0.2034, Loss_D_B: 0.2017\n",
            "Epoch 17/60, Batch 4/13, Image: 21.png, Loss_G: 4.0552, Loss_D_A: 0.1549, Loss_D_B: 0.1795\n",
            "Epoch 17/60, Batch 5/13, Image: 6.png, Loss_G: 4.2119, Loss_D_A: 0.2252, Loss_D_B: 0.2034\n",
            "Epoch 17/60, Batch 6/13, Image: 90.png, Loss_G: 4.1528, Loss_D_A: 0.2269, Loss_D_B: 0.2358\n",
            "Epoch 17/60, Batch 7/13, Image: 69.png, Loss_G: 3.3734, Loss_D_A: 0.1884, Loss_D_B: 0.2688\n",
            "Epoch 17/60, Batch 8/13, Image: 80.png, Loss_G: 3.7560, Loss_D_A: 0.2199, Loss_D_B: 0.2691\n",
            "Epoch 17/60, Batch 9/13, Image: 78.png, Loss_G: 3.8555, Loss_D_A: 0.1481, Loss_D_B: 0.1480\n",
            "Epoch 17/60, Batch 10/13, Image: 58.png, Loss_G: 4.5013, Loss_D_A: 0.1746, Loss_D_B: 0.1722\n",
            "Epoch 17/60, Batch 11/13, Image: 17.png, Loss_G: 3.8969, Loss_D_A: 0.2150, Loss_D_B: 0.2478\n",
            "Epoch 17/60, Batch 12/13, Image: 18.png, Loss_G: 4.6860, Loss_D_A: 0.1593, Loss_D_B: 0.1564\n",
            "Epoch 18/60, Batch 0/13, Image: 86.png, Loss_G: 3.3099, Loss_D_A: 0.1890, Loss_D_B: 0.1613\n",
            "Epoch 18/60, Batch 1/13, Image: 64.png, Loss_G: 4.3420, Loss_D_A: 0.1614, Loss_D_B: 0.1306\n",
            "Epoch 18/60, Batch 2/13, Image: 90.png, Loss_G: 3.7707, Loss_D_A: 0.2199, Loss_D_B: 0.2155\n",
            "Epoch 18/60, Batch 3/13, Image: 91.png, Loss_G: 4.4941, Loss_D_A: 0.2330, Loss_D_B: 0.1930\n",
            "Epoch 18/60, Batch 4/13, Image: 62.png, Loss_G: 4.2905, Loss_D_A: 0.1643, Loss_D_B: 0.1876\n",
            "Epoch 18/60, Batch 5/13, Image: 39.png, Loss_G: 3.5325, Loss_D_A: 0.2493, Loss_D_B: 0.2576\n",
            "Epoch 18/60, Batch 6/13, Image: 71.png, Loss_G: 4.1830, Loss_D_A: 0.2264, Loss_D_B: 0.2684\n",
            "Epoch 18/60, Batch 7/13, Image: 85.png, Loss_G: 3.5856, Loss_D_A: 0.1933, Loss_D_B: 0.2260\n",
            "Epoch 18/60, Batch 8/13, Image: 31.png, Loss_G: 3.5912, Loss_D_A: 0.2684, Loss_D_B: 0.2495\n",
            "Epoch 18/60, Batch 9/13, Image: 8.png, Loss_G: 3.7872, Loss_D_A: 0.3426, Loss_D_B: 0.2434\n",
            "Epoch 18/60, Batch 10/13, Image: 96.png, Loss_G: 3.6695, Loss_D_A: 0.2597, Loss_D_B: 0.2021\n",
            "Epoch 18/60, Batch 11/13, Image: 56.png, Loss_G: 3.6175, Loss_D_A: 0.2225, Loss_D_B: 0.1974\n",
            "Epoch 18/60, Batch 12/13, Image: 61.png, Loss_G: 5.0412, Loss_D_A: 0.1283, Loss_D_B: 0.1374\n",
            "Epoch 19/60, Batch 0/13, Image: 64.png, Loss_G: 3.6644, Loss_D_A: 0.1699, Loss_D_B: 0.1715\n",
            "Epoch 19/60, Batch 1/13, Image: 29.png, Loss_G: 4.7375, Loss_D_A: 0.2365, Loss_D_B: 0.2390\n",
            "Epoch 19/60, Batch 2/13, Image: 2.png, Loss_G: 4.0486, Loss_D_A: 0.1987, Loss_D_B: 0.2280\n",
            "Epoch 19/60, Batch 3/13, Image: 36.png, Loss_G: 4.1625, Loss_D_A: 0.1501, Loss_D_B: 0.1669\n",
            "Epoch 19/60, Batch 4/13, Image: 77.png, Loss_G: 4.7285, Loss_D_A: 0.3024, Loss_D_B: 0.3257\n",
            "Epoch 19/60, Batch 5/13, Image: 78.png, Loss_G: 4.7464, Loss_D_A: 0.1309, Loss_D_B: 0.1408\n",
            "Epoch 19/60, Batch 6/13, Image: 86.png, Loss_G: 3.4216, Loss_D_A: 0.1525, Loss_D_B: 0.1713\n",
            "Epoch 19/60, Batch 7/13, Image: 53.png, Loss_G: 3.9762, Loss_D_A: 0.1750, Loss_D_B: 0.1681\n",
            "Epoch 19/60, Batch 8/13, Image: 42.png, Loss_G: 3.9542, Loss_D_A: 0.1685, Loss_D_B: 0.1831\n",
            "Epoch 19/60, Batch 9/13, Image: 8.png, Loss_G: 3.2044, Loss_D_A: 0.1261, Loss_D_B: 0.1614\n",
            "Epoch 19/60, Batch 10/13, Image: 40.png, Loss_G: 4.1120, Loss_D_A: 0.1472, Loss_D_B: 0.1884\n",
            "Epoch 19/60, Batch 11/13, Image: 14.png, Loss_G: 4.4503, Loss_D_A: 0.2378, Loss_D_B: 0.2664\n",
            "Epoch 19/60, Batch 12/13, Image: 4.png, Loss_G: 4.6061, Loss_D_A: 0.2538, Loss_D_B: 0.2826\n",
            "Epoch 20/60, Batch 0/13, Image: 35.png, Loss_G: 4.1514, Loss_D_A: 0.1184, Loss_D_B: 0.1648\n",
            "Epoch 20/60, Batch 1/13, Image: 98.png, Loss_G: 3.5775, Loss_D_A: 0.2337, Loss_D_B: 0.2611\n",
            "Epoch 20/60, Batch 2/13, Image: 88.png, Loss_G: 3.4953, Loss_D_A: 0.1635, Loss_D_B: 0.1704\n",
            "Epoch 20/60, Batch 3/13, Image: 29.png, Loss_G: 4.0171, Loss_D_A: 0.2407, Loss_D_B: 0.2452\n",
            "Epoch 20/60, Batch 4/13, Image: 87.png, Loss_G: 3.6925, Loss_D_A: 0.0919, Loss_D_B: 0.1216\n",
            "Epoch 20/60, Batch 5/13, Image: 91.png, Loss_G: 4.2900, Loss_D_A: 0.1196, Loss_D_B: 0.1268\n",
            "Epoch 20/60, Batch 6/13, Image: 1.png, Loss_G: 3.6674, Loss_D_A: 0.3107, Loss_D_B: 0.2951\n",
            "Epoch 20/60, Batch 7/13, Image: 42.png, Loss_G: 3.3822, Loss_D_A: 0.1635, Loss_D_B: 0.1586\n",
            "Epoch 20/60, Batch 8/13, Image: 76.png, Loss_G: 3.9701, Loss_D_A: 0.2108, Loss_D_B: 0.2105\n",
            "Epoch 20/60, Batch 9/13, Image: 47.png, Loss_G: 3.6591, Loss_D_A: 0.1651, Loss_D_B: 0.1730\n",
            "Epoch 20/60, Batch 10/13, Image: 2.png, Loss_G: 3.3815, Loss_D_A: 0.1221, Loss_D_B: 0.1272\n",
            "Epoch 20/60, Batch 11/13, Image: 16.png, Loss_G: 3.6491, Loss_D_A: 0.2324, Loss_D_B: 0.2103\n",
            "Epoch 20/60, Batch 12/13, Image: 56.png, Loss_G: 3.2593, Loss_D_A: 0.1692, Loss_D_B: 0.1635\n",
            "Epoch 21/60, Batch 0/13, Image: 49.png, Loss_G: 3.2679, Loss_D_A: 0.1520, Loss_D_B: 0.1593\n",
            "Epoch 21/60, Batch 1/13, Image: 52.png, Loss_G: 4.1242, Loss_D_A: 0.1233, Loss_D_B: 0.1171\n",
            "Epoch 21/60, Batch 2/13, Image: 65.png, Loss_G: 3.6959, Loss_D_A: 0.1843, Loss_D_B: 0.1718\n",
            "Epoch 21/60, Batch 3/13, Image: 3.png, Loss_G: 3.4838, Loss_D_A: 0.1515, Loss_D_B: 0.1457\n",
            "Epoch 21/60, Batch 4/13, Image: 61.png, Loss_G: 3.4582, Loss_D_A: 0.2771, Loss_D_B: 0.2466\n",
            "Epoch 21/60, Batch 5/13, Image: 10.png, Loss_G: 3.4790, Loss_D_A: 0.1197, Loss_D_B: 0.1213\n",
            "Epoch 21/60, Batch 6/13, Image: 51.png, Loss_G: 3.5689, Loss_D_A: 0.1812, Loss_D_B: 0.1636\n",
            "Epoch 21/60, Batch 7/13, Image: 74.png, Loss_G: 3.7393, Loss_D_A: 0.1891, Loss_D_B: 0.1944\n",
            "Epoch 21/60, Batch 8/13, Image: 17.png, Loss_G: 3.6250, Loss_D_A: 0.2189, Loss_D_B: 0.1841\n",
            "Epoch 21/60, Batch 9/13, Image: 60.png, Loss_G: 3.8752, Loss_D_A: 0.1525, Loss_D_B: 0.1450\n",
            "Epoch 21/60, Batch 10/13, Image: 84.png, Loss_G: 4.0899, Loss_D_A: 0.2205, Loss_D_B: 0.2119\n",
            "Epoch 21/60, Batch 11/13, Image: 88.png, Loss_G: 3.8220, Loss_D_A: 0.2078, Loss_D_B: 0.1977\n",
            "Epoch 21/60, Batch 12/13, Image: 64.png, Loss_G: 5.6136, Loss_D_A: 0.1818, Loss_D_B: 0.1866\n",
            "Epoch 22/60, Batch 0/13, Image: 27.png, Loss_G: 3.7691, Loss_D_A: 0.2419, Loss_D_B: 0.2397\n",
            "Epoch 22/60, Batch 1/13, Image: 16.png, Loss_G: 3.1903, Loss_D_A: 0.1675, Loss_D_B: 0.1599\n",
            "Epoch 22/60, Batch 2/13, Image: 25.png, Loss_G: 3.7678, Loss_D_A: 0.1638, Loss_D_B: 0.1746\n",
            "Epoch 22/60, Batch 3/13, Image: 74.png, Loss_G: 3.9323, Loss_D_A: 0.1225, Loss_D_B: 0.1584\n",
            "Epoch 22/60, Batch 4/13, Image: 49.png, Loss_G: 3.6023, Loss_D_A: 0.2167, Loss_D_B: 0.2068\n",
            "Epoch 22/60, Batch 5/13, Image: 66.png, Loss_G: 4.1477, Loss_D_A: 0.1715, Loss_D_B: 0.1643\n",
            "Epoch 22/60, Batch 6/13, Image: 40.png, Loss_G: 3.2332, Loss_D_A: 0.1600, Loss_D_B: 0.1571\n",
            "Epoch 22/60, Batch 7/13, Image: 65.png, Loss_G: 3.2322, Loss_D_A: 0.2025, Loss_D_B: 0.2245\n",
            "Epoch 22/60, Batch 8/13, Image: 34.png, Loss_G: 3.8575, Loss_D_A: 0.1641, Loss_D_B: 0.1818\n",
            "Epoch 22/60, Batch 9/13, Image: 86.png, Loss_G: 3.8262, Loss_D_A: 0.1968, Loss_D_B: 0.1892\n",
            "Epoch 22/60, Batch 10/13, Image: 63.png, Loss_G: 3.4280, Loss_D_A: 0.1704, Loss_D_B: 0.1753\n",
            "Epoch 22/60, Batch 11/13, Image: 78.png, Loss_G: 3.7287, Loss_D_A: 0.1142, Loss_D_B: 0.1153\n",
            "Epoch 22/60, Batch 12/13, Image: 99.png, Loss_G: 3.5546, Loss_D_A: 0.2300, Loss_D_B: 0.1987\n",
            "Epoch 23/60, Batch 0/13, Image: 3.png, Loss_G: 3.4980, Loss_D_A: 0.2419, Loss_D_B: 0.2463\n",
            "Epoch 23/60, Batch 1/13, Image: 59.png, Loss_G: 3.6632, Loss_D_A: 0.0961, Loss_D_B: 0.1160\n",
            "Epoch 23/60, Batch 2/13, Image: 76.png, Loss_G: 3.5204, Loss_D_A: 0.2596, Loss_D_B: 0.2755\n",
            "Epoch 23/60, Batch 3/13, Image: 54.png, Loss_G: 4.4230, Loss_D_A: 0.1602, Loss_D_B: 0.1746\n",
            "Epoch 23/60, Batch 4/13, Image: 84.png, Loss_G: 3.5341, Loss_D_A: 0.1345, Loss_D_B: 0.1491\n",
            "Epoch 23/60, Batch 5/13, Image: 75.png, Loss_G: 4.1699, Loss_D_A: 0.1891, Loss_D_B: 0.2173\n",
            "Epoch 23/60, Batch 6/13, Image: 73.png, Loss_G: 3.5641, Loss_D_A: 0.1157, Loss_D_B: 0.1395\n",
            "Epoch 23/60, Batch 7/13, Image: 24.png, Loss_G: 4.0611, Loss_D_A: 0.1554, Loss_D_B: 0.1779\n",
            "Epoch 23/60, Batch 8/13, Image: 35.png, Loss_G: 3.8179, Loss_D_A: 0.1076, Loss_D_B: 0.1210\n",
            "Epoch 23/60, Batch 9/13, Image: 89.png, Loss_G: 3.4864, Loss_D_A: 0.1399, Loss_D_B: 0.1409\n",
            "Epoch 23/60, Batch 10/13, Image: 25.png, Loss_G: 3.4271, Loss_D_A: 0.2357, Loss_D_B: 0.2269\n",
            "Epoch 23/60, Batch 11/13, Image: 33.png, Loss_G: 4.1162, Loss_D_A: 0.1713, Loss_D_B: 0.1817\n",
            "Epoch 23/60, Batch 12/13, Image: 8.png, Loss_G: 4.0936, Loss_D_A: 0.2323, Loss_D_B: 0.2684\n",
            "Epoch 24/60, Batch 0/13, Image: 80.png, Loss_G: 3.1621, Loss_D_A: 0.1832, Loss_D_B: 0.2236\n",
            "Epoch 24/60, Batch 1/13, Image: 49.png, Loss_G: 4.1688, Loss_D_A: 0.1656, Loss_D_B: 0.1898\n",
            "Epoch 24/60, Batch 2/13, Image: 15.png, Loss_G: 4.0591, Loss_D_A: 0.1111, Loss_D_B: 0.1481\n",
            "Epoch 24/60, Batch 3/13, Image: 92.png, Loss_G: 3.2516, Loss_D_A: 0.1922, Loss_D_B: 0.2117\n",
            "Epoch 24/60, Batch 4/13, Image: 89.png, Loss_G: 3.3626, Loss_D_A: 0.1869, Loss_D_B: 0.1863\n",
            "Epoch 24/60, Batch 5/13, Image: 93.png, Loss_G: 3.7929, Loss_D_A: 0.2410, Loss_D_B: 0.2349\n",
            "Epoch 24/60, Batch 6/13, Image: 52.png, Loss_G: 3.9242, Loss_D_A: 0.1711, Loss_D_B: 0.1103\n",
            "Epoch 24/60, Batch 7/13, Image: 28.png, Loss_G: 3.2014, Loss_D_A: 0.1877, Loss_D_B: 0.1500\n",
            "Epoch 24/60, Batch 8/13, Image: 98.png, Loss_G: 4.1914, Loss_D_A: 0.1873, Loss_D_B: 0.1871\n",
            "Epoch 24/60, Batch 9/13, Image: 67.png, Loss_G: 3.5292, Loss_D_A: 0.1606, Loss_D_B: 0.1262\n",
            "Epoch 24/60, Batch 10/13, Image: 84.png, Loss_G: 3.6102, Loss_D_A: 0.1860, Loss_D_B: 0.1632\n",
            "Epoch 24/60, Batch 11/13, Image: 42.png, Loss_G: 4.4950, Loss_D_A: 0.1257, Loss_D_B: 0.1273\n",
            "Epoch 24/60, Batch 12/13, Image: 88.png, Loss_G: 4.4654, Loss_D_A: 0.1866, Loss_D_B: 0.1831\n",
            "Epoch 25/60, Batch 0/13, Image: 27.png, Loss_G: 3.8625, Loss_D_A: 0.1623, Loss_D_B: 0.1592\n",
            "Epoch 25/60, Batch 1/13, Image: 89.png, Loss_G: 3.5459, Loss_D_A: 0.1522, Loss_D_B: 0.1667\n",
            "Epoch 25/60, Batch 2/13, Image: 53.png, Loss_G: 4.1220, Loss_D_A: 0.1009, Loss_D_B: 0.1223\n",
            "Epoch 25/60, Batch 3/13, Image: 42.png, Loss_G: 3.5099, Loss_D_A: 0.1686, Loss_D_B: 0.1747\n",
            "Epoch 25/60, Batch 4/13, Image: 54.png, Loss_G: 3.5069, Loss_D_A: 0.1899, Loss_D_B: 0.1830\n",
            "Epoch 25/60, Batch 5/13, Image: 11.png, Loss_G: 3.8673, Loss_D_A: 0.2120, Loss_D_B: 0.2206\n",
            "Epoch 25/60, Batch 6/13, Image: 69.png, Loss_G: 3.8080, Loss_D_A: 0.2198, Loss_D_B: 0.2036\n",
            "Epoch 25/60, Batch 7/13, Image: 13.png, Loss_G: 4.2925, Loss_D_A: 0.1847, Loss_D_B: 0.2034\n",
            "Epoch 25/60, Batch 8/13, Image: 21.png, Loss_G: 3.9306, Loss_D_A: 0.2112, Loss_D_B: 0.1906\n",
            "Epoch 25/60, Batch 9/13, Image: 39.png, Loss_G: 4.3099, Loss_D_A: 0.1232, Loss_D_B: 0.1421\n",
            "Epoch 25/60, Batch 10/13, Image: 33.png, Loss_G: 4.7689, Loss_D_A: 0.1580, Loss_D_B: 0.1732\n",
            "Epoch 25/60, Batch 11/13, Image: 44.png, Loss_G: 4.8220, Loss_D_A: 0.1218, Loss_D_B: 0.1446\n",
            "Epoch 25/60, Batch 12/13, Image: 35.png, Loss_G: 4.7572, Loss_D_A: 0.0845, Loss_D_B: 0.0895\n",
            "Epoch 26/60, Batch 0/13, Image: 3.png, Loss_G: 3.1574, Loss_D_A: 0.1183, Loss_D_B: 0.1455\n",
            "Epoch 26/60, Batch 1/13, Image: 100.png, Loss_G: 3.6049, Loss_D_A: 0.1535, Loss_D_B: 0.1348\n",
            "Epoch 26/60, Batch 2/13, Image: 15.png, Loss_G: 3.6236, Loss_D_A: 0.2645, Loss_D_B: 0.2306\n",
            "Epoch 26/60, Batch 3/13, Image: 95.png, Loss_G: 3.8779, Loss_D_A: 0.3000, Loss_D_B: 0.2441\n",
            "Epoch 26/60, Batch 4/13, Image: 22.png, Loss_G: 3.7113, Loss_D_A: 0.4829, Loss_D_B: 0.3754\n",
            "Epoch 26/60, Batch 5/13, Image: 30.png, Loss_G: 4.0266, Loss_D_A: 0.2874, Loss_D_B: 0.2064\n",
            "Epoch 26/60, Batch 6/13, Image: 74.png, Loss_G: 3.4500, Loss_D_A: 0.2041, Loss_D_B: 0.1659\n",
            "Epoch 26/60, Batch 7/13, Image: 66.png, Loss_G: 3.0919, Loss_D_A: 0.1615, Loss_D_B: 0.1547\n",
            "Epoch 26/60, Batch 8/13, Image: 55.png, Loss_G: 4.0390, Loss_D_A: 0.3133, Loss_D_B: 0.2550\n",
            "Epoch 26/60, Batch 9/13, Image: 84.png, Loss_G: 3.7790, Loss_D_A: 0.2134, Loss_D_B: 0.1792\n",
            "Epoch 26/60, Batch 10/13, Image: 42.png, Loss_G: 4.7227, Loss_D_A: 0.1839, Loss_D_B: 0.1787\n",
            "Epoch 26/60, Batch 11/13, Image: 45.png, Loss_G: 3.4257, Loss_D_A: 0.1387, Loss_D_B: 0.1202\n",
            "Epoch 26/60, Batch 12/13, Image: 36.png, Loss_G: 3.7792, Loss_D_A: 0.1968, Loss_D_B: 0.1932\n",
            "Epoch 27/60, Batch 0/13, Image: 38.png, Loss_G: 4.0429, Loss_D_A: 0.2021, Loss_D_B: 0.1984\n",
            "Epoch 27/60, Batch 1/13, Image: 51.png, Loss_G: 3.3541, Loss_D_A: 0.1891, Loss_D_B: 0.2001\n",
            "Epoch 27/60, Batch 2/13, Image: 47.png, Loss_G: 3.1849, Loss_D_A: 0.2327, Loss_D_B: 0.2653\n",
            "Epoch 27/60, Batch 3/13, Image: 35.png, Loss_G: 3.3780, Loss_D_A: 0.1336, Loss_D_B: 0.1957\n",
            "Epoch 27/60, Batch 4/13, Image: 32.png, Loss_G: 3.6144, Loss_D_A: 0.1692, Loss_D_B: 0.1896\n",
            "Epoch 27/60, Batch 5/13, Image: 8.png, Loss_G: 3.9171, Loss_D_A: 0.1472, Loss_D_B: 0.1515\n",
            "Epoch 27/60, Batch 6/13, Image: 53.png, Loss_G: 3.3016, Loss_D_A: 0.2007, Loss_D_B: 0.2252\n",
            "Epoch 27/60, Batch 7/13, Image: 79.png, Loss_G: 3.8410, Loss_D_A: 0.1220, Loss_D_B: 0.1288\n",
            "Epoch 27/60, Batch 8/13, Image: 26.png, Loss_G: 4.0452, Loss_D_A: 0.3007, Loss_D_B: 0.2489\n",
            "Epoch 27/60, Batch 9/13, Image: 41.png, Loss_G: 4.0258, Loss_D_A: 0.2572, Loss_D_B: 0.2408\n",
            "Epoch 27/60, Batch 10/13, Image: 31.png, Loss_G: 3.5629, Loss_D_A: 0.1423, Loss_D_B: 0.1392\n",
            "Epoch 27/60, Batch 11/13, Image: 70.png, Loss_G: 3.4343, Loss_D_A: 0.1523, Loss_D_B: 0.1314\n",
            "Epoch 27/60, Batch 12/13, Image: 19.png, Loss_G: 4.3658, Loss_D_A: 0.2158, Loss_D_B: 0.2074\n",
            "Epoch 28/60, Batch 0/13, Image: 96.png, Loss_G: 4.1911, Loss_D_A: 0.1832, Loss_D_B: 0.1682\n",
            "Epoch 28/60, Batch 1/13, Image: 76.png, Loss_G: 3.7467, Loss_D_A: 0.1362, Loss_D_B: 0.1465\n",
            "Epoch 28/60, Batch 2/13, Image: 31.png, Loss_G: 3.6686, Loss_D_A: 0.2198, Loss_D_B: 0.2048\n",
            "Epoch 28/60, Batch 3/13, Image: 27.png, Loss_G: 4.8390, Loss_D_A: 0.1235, Loss_D_B: 0.1604\n",
            "Epoch 28/60, Batch 4/13, Image: 51.png, Loss_G: 3.3142, Loss_D_A: 0.2125, Loss_D_B: 0.2027\n",
            "Epoch 28/60, Batch 5/13, Image: 80.png, Loss_G: 3.9672, Loss_D_A: 0.0999, Loss_D_B: 0.0945\n",
            "Epoch 28/60, Batch 6/13, Image: 33.png, Loss_G: 3.4437, Loss_D_A: 0.2333, Loss_D_B: 0.2140\n",
            "Epoch 28/60, Batch 7/13, Image: 68.png, Loss_G: 3.8322, Loss_D_A: 0.2107, Loss_D_B: 0.2241\n",
            "Epoch 28/60, Batch 8/13, Image: 50.png, Loss_G: 3.9336, Loss_D_A: 0.1315, Loss_D_B: 0.1121\n",
            "Epoch 28/60, Batch 9/13, Image: 9.png, Loss_G: 3.3599, Loss_D_A: 0.1669, Loss_D_B: 0.1489\n",
            "Epoch 28/60, Batch 10/13, Image: 100.png, Loss_G: 4.5168, Loss_D_A: 0.1367, Loss_D_B: 0.1167\n",
            "Epoch 28/60, Batch 11/13, Image: 64.png, Loss_G: 4.6615, Loss_D_A: 0.1106, Loss_D_B: 0.1025\n",
            "Epoch 28/60, Batch 12/13, Image: 75.png, Loss_G: 3.9800, Loss_D_A: 0.1429, Loss_D_B: 0.1879\n",
            "Epoch 29/60, Batch 0/13, Image: 68.png, Loss_G: 3.2903, Loss_D_A: 0.1463, Loss_D_B: 0.1851\n",
            "Epoch 29/60, Batch 1/13, Image: 18.png, Loss_G: 3.3137, Loss_D_A: 0.1567, Loss_D_B: 0.1945\n",
            "Epoch 29/60, Batch 2/13, Image: 82.png, Loss_G: 4.1516, Loss_D_A: 0.2344, Loss_D_B: 0.3326\n",
            "Epoch 29/60, Batch 3/13, Image: 7.png, Loss_G: 4.1771, Loss_D_A: 0.2502, Loss_D_B: 0.3438\n",
            "Epoch 29/60, Batch 4/13, Image: 58.png, Loss_G: 3.5973, Loss_D_A: 0.2641, Loss_D_B: 0.2575\n",
            "Epoch 29/60, Batch 5/13, Image: 59.png, Loss_G: 3.8323, Loss_D_A: 0.2128, Loss_D_B: 0.2229\n",
            "Epoch 29/60, Batch 6/13, Image: 93.png, Loss_G: 3.6245, Loss_D_A: 0.1789, Loss_D_B: 0.1868\n",
            "Epoch 29/60, Batch 7/13, Image: 26.png, Loss_G: 4.9200, Loss_D_A: 0.1732, Loss_D_B: 0.1548\n",
            "Epoch 29/60, Batch 8/13, Image: 46.png, Loss_G: 5.0254, Loss_D_A: 0.2296, Loss_D_B: 0.2340\n",
            "Epoch 29/60, Batch 9/13, Image: 3.png, Loss_G: 4.1081, Loss_D_A: 0.1683, Loss_D_B: 0.1808\n",
            "Epoch 29/60, Batch 10/13, Image: 39.png, Loss_G: 5.8219, Loss_D_A: 0.1202, Loss_D_B: 0.1233\n",
            "Epoch 29/60, Batch 11/13, Image: 97.png, Loss_G: 3.3612, Loss_D_A: 0.2187, Loss_D_B: 0.1992\n",
            "Epoch 29/60, Batch 12/13, Image: 81.png, Loss_G: 3.7102, Loss_D_A: 0.2017, Loss_D_B: 0.1992\n",
            "Epoch 30/60, Batch 0/13, Image: 8.png, Loss_G: 3.3013, Loss_D_A: 0.2669, Loss_D_B: 0.2481\n",
            "Epoch 30/60, Batch 1/13, Image: 49.png, Loss_G: 4.8385, Loss_D_A: 0.1858, Loss_D_B: 0.1760\n",
            "Epoch 30/60, Batch 2/13, Image: 92.png, Loss_G: 3.4525, Loss_D_A: 0.1994, Loss_D_B: 0.1819\n",
            "Epoch 30/60, Batch 3/13, Image: 64.png, Loss_G: 4.2621, Loss_D_A: 0.1233, Loss_D_B: 0.0960\n",
            "Epoch 30/60, Batch 4/13, Image: 12.png, Loss_G: 3.9678, Loss_D_A: 0.2026, Loss_D_B: 0.1639\n",
            "Epoch 30/60, Batch 5/13, Image: 1.png, Loss_G: 4.5644, Loss_D_A: 0.1336, Loss_D_B: 0.1156\n",
            "Epoch 30/60, Batch 6/13, Image: 100.png, Loss_G: 3.7861, Loss_D_A: 0.2049, Loss_D_B: 0.1723\n",
            "Epoch 30/60, Batch 7/13, Image: 22.png, Loss_G: 3.5928, Loss_D_A: 0.2191, Loss_D_B: 0.1916\n",
            "Epoch 30/60, Batch 8/13, Image: 5.png, Loss_G: 4.6056, Loss_D_A: 0.1660, Loss_D_B: 0.1736\n",
            "Epoch 30/60, Batch 9/13, Image: 7.png, Loss_G: 4.2814, Loss_D_A: 0.2218, Loss_D_B: 0.1999\n",
            "Epoch 30/60, Batch 10/13, Image: 77.png, Loss_G: 3.2042, Loss_D_A: 0.1750, Loss_D_B: 0.1596\n",
            "Epoch 30/60, Batch 11/13, Image: 91.png, Loss_G: 3.5256, Loss_D_A: 0.1555, Loss_D_B: 0.1266\n",
            "Epoch 30/60, Batch 12/13, Image: 63.png, Loss_G: 4.5513, Loss_D_A: 0.0647, Loss_D_B: 0.0619\n",
            "Epoch 31/60, Batch 0/13, Image: 75.png, Loss_G: 3.8350, Loss_D_A: 0.1699, Loss_D_B: 0.1360\n",
            "Epoch 31/60, Batch 1/13, Image: 40.png, Loss_G: 2.8312, Loss_D_A: 0.2778, Loss_D_B: 0.2097\n",
            "Epoch 31/60, Batch 2/13, Image: 83.png, Loss_G: 4.3628, Loss_D_A: 0.2295, Loss_D_B: 0.1318\n",
            "Epoch 31/60, Batch 3/13, Image: 3.png, Loss_G: 4.6678, Loss_D_A: 0.1814, Loss_D_B: 0.1237\n",
            "Epoch 31/60, Batch 4/13, Image: 41.png, Loss_G: 3.9100, Loss_D_A: 0.2534, Loss_D_B: 0.2266\n",
            "Epoch 31/60, Batch 5/13, Image: 33.png, Loss_G: 4.0587, Loss_D_A: 0.2129, Loss_D_B: 0.2022\n",
            "Epoch 31/60, Batch 6/13, Image: 87.png, Loss_G: 3.2498, Loss_D_A: 0.2073, Loss_D_B: 0.1966\n",
            "Epoch 31/60, Batch 7/13, Image: 50.png, Loss_G: 4.5003, Loss_D_A: 0.0739, Loss_D_B: 0.1171\n",
            "Epoch 31/60, Batch 8/13, Image: 46.png, Loss_G: 4.8631, Loss_D_A: 0.1608, Loss_D_B: 0.1795\n",
            "Epoch 31/60, Batch 9/13, Image: 22.png, Loss_G: 3.4707, Loss_D_A: 0.1480, Loss_D_B: 0.1380\n",
            "Epoch 31/60, Batch 10/13, Image: 66.png, Loss_G: 3.7660, Loss_D_A: 0.2023, Loss_D_B: 0.1924\n",
            "Epoch 31/60, Batch 11/13, Image: 45.png, Loss_G: 3.8583, Loss_D_A: 0.1103, Loss_D_B: 0.1376\n",
            "Epoch 31/60, Batch 12/13, Image: 99.png, Loss_G: 4.0635, Loss_D_A: 0.2432, Loss_D_B: 0.2345\n",
            "Epoch 32/60, Batch 0/13, Image: 86.png, Loss_G: 3.6165, Loss_D_A: 0.1395, Loss_D_B: 0.1210\n",
            "Epoch 32/60, Batch 1/13, Image: 66.png, Loss_G: 3.8854, Loss_D_A: 0.1855, Loss_D_B: 0.2063\n",
            "Epoch 32/60, Batch 2/13, Image: 5.png, Loss_G: 4.0698, Loss_D_A: 0.2811, Loss_D_B: 0.2829\n",
            "Epoch 32/60, Batch 3/13, Image: 75.png, Loss_G: 3.9197, Loss_D_A: 0.1198, Loss_D_B: 0.1740\n",
            "Epoch 32/60, Batch 4/13, Image: 43.png, Loss_G: 4.5517, Loss_D_A: 0.0990, Loss_D_B: 0.0978\n",
            "Epoch 32/60, Batch 5/13, Image: 98.png, Loss_G: 3.8509, Loss_D_A: 0.1876, Loss_D_B: 0.1592\n",
            "Epoch 32/60, Batch 6/13, Image: 51.png, Loss_G: 4.3240, Loss_D_A: 0.1985, Loss_D_B: 0.1797\n",
            "Epoch 32/60, Batch 7/13, Image: 79.png, Loss_G: 3.7739, Loss_D_A: 0.1089, Loss_D_B: 0.1145\n",
            "Epoch 32/60, Batch 8/13, Image: 90.png, Loss_G: 4.4058, Loss_D_A: 0.1553, Loss_D_B: 0.1610\n",
            "Epoch 32/60, Batch 9/13, Image: 9.png, Loss_G: 3.2926, Loss_D_A: 0.2022, Loss_D_B: 0.1655\n",
            "Epoch 32/60, Batch 10/13, Image: 85.png, Loss_G: 3.7287, Loss_D_A: 0.2121, Loss_D_B: 0.2175\n",
            "Epoch 32/60, Batch 11/13, Image: 70.png, Loss_G: 3.2594, Loss_D_A: 0.2413, Loss_D_B: 0.2077\n",
            "Epoch 32/60, Batch 12/13, Image: 34.png, Loss_G: 3.8370, Loss_D_A: 0.1623, Loss_D_B: 0.1539\n",
            "Epoch 33/60, Batch 0/13, Image: 38.png, Loss_G: 4.7377, Loss_D_A: 0.2182, Loss_D_B: 0.2305\n",
            "Epoch 33/60, Batch 1/13, Image: 13.png, Loss_G: 4.0162, Loss_D_A: 0.1615, Loss_D_B: 0.1412\n",
            "Epoch 33/60, Batch 2/13, Image: 99.png, Loss_G: 4.4658, Loss_D_A: 0.2110, Loss_D_B: 0.1912\n",
            "Epoch 33/60, Batch 3/13, Image: 28.png, Loss_G: 4.2107, Loss_D_A: 0.1109, Loss_D_B: 0.0981\n",
            "Epoch 33/60, Batch 4/13, Image: 61.png, Loss_G: 4.2837, Loss_D_A: 0.1716, Loss_D_B: 0.1557\n",
            "Epoch 33/60, Batch 5/13, Image: 14.png, Loss_G: 4.4624, Loss_D_A: 0.1782, Loss_D_B: 0.1570\n",
            "Epoch 33/60, Batch 6/13, Image: 69.png, Loss_G: 3.4523, Loss_D_A: 0.1883, Loss_D_B: 0.1395\n",
            "Epoch 33/60, Batch 7/13, Image: 67.png, Loss_G: 4.4144, Loss_D_A: 0.1392, Loss_D_B: 0.1221\n",
            "Epoch 33/60, Batch 8/13, Image: 45.png, Loss_G: 4.3120, Loss_D_A: 0.1840, Loss_D_B: 0.1973\n",
            "Epoch 33/60, Batch 9/13, Image: 47.png, Loss_G: 2.6029, Loss_D_A: 0.2912, Loss_D_B: 0.2976\n",
            "Epoch 33/60, Batch 10/13, Image: 16.png, Loss_G: 4.3982, Loss_D_A: 0.2457, Loss_D_B: 0.2301\n",
            "Epoch 33/60, Batch 11/13, Image: 34.png, Loss_G: 3.5800, Loss_D_A: 0.2477, Loss_D_B: 0.1452\n",
            "Epoch 33/60, Batch 12/13, Image: 81.png, Loss_G: 3.4006, Loss_D_A: 0.1459, Loss_D_B: 0.1419\n",
            "Epoch 34/60, Batch 0/13, Image: 57.png, Loss_G: 4.3895, Loss_D_A: 0.2751, Loss_D_B: 0.2160\n",
            "Epoch 34/60, Batch 1/13, Image: 94.png, Loss_G: 4.6160, Loss_D_A: 0.1366, Loss_D_B: 0.1385\n",
            "Epoch 34/60, Batch 2/13, Image: 28.png, Loss_G: 3.3175, Loss_D_A: 0.2213, Loss_D_B: 0.1783\n",
            "Epoch 34/60, Batch 3/13, Image: 14.png, Loss_G: 4.4415, Loss_D_A: 0.1791, Loss_D_B: 0.1696\n",
            "Epoch 34/60, Batch 4/13, Image: 56.png, Loss_G: 3.1283, Loss_D_A: 0.2071, Loss_D_B: 0.1460\n",
            "Epoch 34/60, Batch 5/13, Image: 15.png, Loss_G: 3.7933, Loss_D_A: 0.1539, Loss_D_B: 0.1071\n",
            "Epoch 34/60, Batch 6/13, Image: 89.png, Loss_G: 4.8241, Loss_D_A: 0.0872, Loss_D_B: 0.0742\n",
            "Epoch 34/60, Batch 7/13, Image: 74.png, Loss_G: 3.5642, Loss_D_A: 0.1420, Loss_D_B: 0.1324\n",
            "Epoch 34/60, Batch 8/13, Image: 27.png, Loss_G: 4.2699, Loss_D_A: 0.2057, Loss_D_B: 0.1939\n",
            "Epoch 34/60, Batch 9/13, Image: 12.png, Loss_G: 3.1730, Loss_D_A: 0.2591, Loss_D_B: 0.2450\n",
            "Epoch 34/60, Batch 10/13, Image: 81.png, Loss_G: 3.7327, Loss_D_A: 0.1806, Loss_D_B: 0.1796\n",
            "Epoch 34/60, Batch 11/13, Image: 36.png, Loss_G: 3.2204, Loss_D_A: 0.1797, Loss_D_B: 0.1782\n",
            "Epoch 34/60, Batch 12/13, Image: 42.png, Loss_G: 3.9848, Loss_D_A: 0.1311, Loss_D_B: 0.1421\n",
            "Epoch 35/60, Batch 0/13, Image: 89.png, Loss_G: 3.9111, Loss_D_A: 0.0748, Loss_D_B: 0.0843\n",
            "Epoch 35/60, Batch 1/13, Image: 76.png, Loss_G: 4.7260, Loss_D_A: 0.1859, Loss_D_B: 0.1460\n",
            "Epoch 35/60, Batch 2/13, Image: 62.png, Loss_G: 3.7448, Loss_D_A: 0.1636, Loss_D_B: 0.0987\n",
            "Epoch 35/60, Batch 3/13, Image: 1.png, Loss_G: 3.6255, Loss_D_A: 0.2671, Loss_D_B: 0.1942\n",
            "Epoch 35/60, Batch 4/13, Image: 51.png, Loss_G: 4.2109, Loss_D_A: 0.1914, Loss_D_B: 0.1932\n",
            "Epoch 35/60, Batch 5/13, Image: 88.png, Loss_G: 4.0830, Loss_D_A: 0.1206, Loss_D_B: 0.1440\n",
            "Epoch 35/60, Batch 6/13, Image: 73.png, Loss_G: 4.6678, Loss_D_A: 0.1754, Loss_D_B: 0.0835\n",
            "Epoch 35/60, Batch 7/13, Image: 25.png, Loss_G: 3.8115, Loss_D_A: 0.1587, Loss_D_B: 0.1273\n",
            "Epoch 35/60, Batch 8/13, Image: 75.png, Loss_G: 4.3373, Loss_D_A: 0.2030, Loss_D_B: 0.2090\n",
            "Epoch 35/60, Batch 9/13, Image: 86.png, Loss_G: 3.9068, Loss_D_A: 0.2210, Loss_D_B: 0.2373\n",
            "Epoch 35/60, Batch 10/13, Image: 82.png, Loss_G: 4.3604, Loss_D_A: 0.2061, Loss_D_B: 0.2336\n",
            "Epoch 35/60, Batch 11/13, Image: 21.png, Loss_G: 4.0599, Loss_D_A: 0.1224, Loss_D_B: 0.1368\n",
            "Epoch 35/60, Batch 12/13, Image: 81.png, Loss_G: 3.7150, Loss_D_A: 0.2579, Loss_D_B: 0.2526\n",
            "Epoch 36/60, Batch 0/13, Image: 18.png, Loss_G: 3.8368, Loss_D_A: 0.1212, Loss_D_B: 0.1227\n",
            "Epoch 36/60, Batch 1/13, Image: 98.png, Loss_G: 3.7723, Loss_D_A: 0.1412, Loss_D_B: 0.1211\n",
            "Epoch 36/60, Batch 2/13, Image: 49.png, Loss_G: 4.5433, Loss_D_A: 0.1530, Loss_D_B: 0.1486\n",
            "Epoch 36/60, Batch 3/13, Image: 11.png, Loss_G: 4.7418, Loss_D_A: 0.1740, Loss_D_B: 0.1639\n",
            "Epoch 36/60, Batch 4/13, Image: 1.png, Loss_G: 3.4428, Loss_D_A: 0.2014, Loss_D_B: 0.1819\n",
            "Epoch 36/60, Batch 5/13, Image: 40.png, Loss_G: 3.4251, Loss_D_A: 0.1501, Loss_D_B: 0.1264\n",
            "Epoch 36/60, Batch 6/13, Image: 38.png, Loss_G: 3.8521, Loss_D_A: 0.1918, Loss_D_B: 0.2075\n",
            "Epoch 36/60, Batch 7/13, Image: 73.png, Loss_G: 4.7011, Loss_D_A: 0.1651, Loss_D_B: 0.1826\n",
            "Epoch 36/60, Batch 8/13, Image: 66.png, Loss_G: 3.9663, Loss_D_A: 0.1273, Loss_D_B: 0.1037\n",
            "Epoch 36/60, Batch 9/13, Image: 68.png, Loss_G: 3.4142, Loss_D_A: 0.1984, Loss_D_B: 0.1617\n",
            "Epoch 36/60, Batch 10/13, Image: 89.png, Loss_G: 4.7348, Loss_D_A: 0.2108, Loss_D_B: 0.2034\n",
            "Epoch 36/60, Batch 11/13, Image: 29.png, Loss_G: 4.4925, Loss_D_A: 0.1748, Loss_D_B: 0.1307\n",
            "Epoch 36/60, Batch 12/13, Image: 30.png, Loss_G: 3.5532, Loss_D_A: 0.2579, Loss_D_B: 0.1885\n",
            "Epoch 37/60, Batch 0/13, Image: 8.png, Loss_G: 3.5480, Loss_D_A: 0.3121, Loss_D_B: 0.2045\n",
            "Epoch 37/60, Batch 1/13, Image: 75.png, Loss_G: 3.4988, Loss_D_A: 0.1790, Loss_D_B: 0.1536\n",
            "Epoch 37/60, Batch 2/13, Image: 79.png, Loss_G: 3.8298, Loss_D_A: 0.1603, Loss_D_B: 0.1385\n",
            "Epoch 37/60, Batch 3/13, Image: 90.png, Loss_G: 3.7642, Loss_D_A: 0.1969, Loss_D_B: 0.1669\n",
            "Epoch 37/60, Batch 4/13, Image: 34.png, Loss_G: 3.4881, Loss_D_A: 0.1084, Loss_D_B: 0.1182\n",
            "Epoch 37/60, Batch 5/13, Image: 10.png, Loss_G: 3.0046, Loss_D_A: 0.2223, Loss_D_B: 0.1897\n",
            "Epoch 37/60, Batch 6/13, Image: 93.png, Loss_G: 3.4403, Loss_D_A: 0.0913, Loss_D_B: 0.1000\n",
            "Epoch 37/60, Batch 7/13, Image: 37.png, Loss_G: 3.7436, Loss_D_A: 0.2420, Loss_D_B: 0.2277\n",
            "Epoch 37/60, Batch 8/13, Image: 43.png, Loss_G: 3.9521, Loss_D_A: 0.1017, Loss_D_B: 0.1060\n",
            "Epoch 37/60, Batch 9/13, Image: 91.png, Loss_G: 4.1675, Loss_D_A: 0.1564, Loss_D_B: 0.1871\n",
            "Epoch 37/60, Batch 10/13, Image: 99.png, Loss_G: 3.7108, Loss_D_A: 0.1243, Loss_D_B: 0.1200\n",
            "Epoch 37/60, Batch 11/13, Image: 18.png, Loss_G: 3.6380, Loss_D_A: 0.2467, Loss_D_B: 0.1609\n",
            "Epoch 37/60, Batch 12/13, Image: 40.png, Loss_G: 4.7345, Loss_D_A: 0.3380, Loss_D_B: 0.1921\n",
            "Epoch 38/60, Batch 0/13, Image: 77.png, Loss_G: 4.6667, Loss_D_A: 0.2015, Loss_D_B: 0.0967\n",
            "Epoch 38/60, Batch 1/13, Image: 6.png, Loss_G: 4.5280, Loss_D_A: 0.2052, Loss_D_B: 0.1109\n",
            "Epoch 38/60, Batch 2/13, Image: 91.png, Loss_G: 4.7947, Loss_D_A: 0.2004, Loss_D_B: 0.1022\n",
            "Epoch 38/60, Batch 3/13, Image: 75.png, Loss_G: 4.1342, Loss_D_A: 0.1564, Loss_D_B: 0.0999\n",
            "Epoch 38/60, Batch 4/13, Image: 94.png, Loss_G: 3.1512, Loss_D_A: 0.1913, Loss_D_B: 0.1689\n",
            "Epoch 38/60, Batch 5/13, Image: 55.png, Loss_G: 6.8283, Loss_D_A: 0.1257, Loss_D_B: 0.1006\n",
            "Epoch 38/60, Batch 6/13, Image: 76.png, Loss_G: 3.8494, Loss_D_A: 0.1990, Loss_D_B: 0.1675\n",
            "Epoch 38/60, Batch 7/13, Image: 50.png, Loss_G: 3.6168, Loss_D_A: 0.1444, Loss_D_B: 0.1415\n",
            "Epoch 38/60, Batch 8/13, Image: 27.png, Loss_G: 3.3632, Loss_D_A: 0.1725, Loss_D_B: 0.2295\n",
            "Epoch 38/60, Batch 9/13, Image: 41.png, Loss_G: 3.7001, Loss_D_A: 0.1171, Loss_D_B: 0.1366\n",
            "Epoch 38/60, Batch 10/13, Image: 88.png, Loss_G: 3.5447, Loss_D_A: 0.1497, Loss_D_B: 0.1851\n",
            "Epoch 38/60, Batch 11/13, Image: 1.png, Loss_G: 4.7359, Loss_D_A: 0.1589, Loss_D_B: 0.1823\n",
            "Epoch 38/60, Batch 12/13, Image: 83.png, Loss_G: 3.1630, Loss_D_A: 0.1191, Loss_D_B: 0.1581\n",
            "Epoch 39/60, Batch 0/13, Image: 95.png, Loss_G: 3.8138, Loss_D_A: 0.2169, Loss_D_B: 0.1908\n",
            "Epoch 39/60, Batch 1/13, Image: 98.png, Loss_G: 4.1350, Loss_D_A: 0.1797, Loss_D_B: 0.2295\n",
            "Epoch 39/60, Batch 2/13, Image: 42.png, Loss_G: 3.5769, Loss_D_A: 0.1396, Loss_D_B: 0.1407\n",
            "Epoch 39/60, Batch 3/13, Image: 51.png, Loss_G: 5.9909, Loss_D_A: 0.1357, Loss_D_B: 0.1130\n",
            "Epoch 39/60, Batch 4/13, Image: 85.png, Loss_G: 4.3333, Loss_D_A: 0.2190, Loss_D_B: 0.1714\n",
            "Epoch 39/60, Batch 5/13, Image: 80.png, Loss_G: 4.3556, Loss_D_A: 0.2373, Loss_D_B: 0.1740\n",
            "Epoch 39/60, Batch 6/13, Image: 16.png, Loss_G: 3.8154, Loss_D_A: 0.1116, Loss_D_B: 0.1273\n",
            "Epoch 39/60, Batch 7/13, Image: 66.png, Loss_G: 3.9338, Loss_D_A: 0.1840, Loss_D_B: 0.2220\n",
            "Epoch 39/60, Batch 8/13, Image: 68.png, Loss_G: 3.7376, Loss_D_A: 0.1632, Loss_D_B: 0.2542\n",
            "Epoch 39/60, Batch 9/13, Image: 30.png, Loss_G: 4.2117, Loss_D_A: 0.1180, Loss_D_B: 0.1404\n",
            "Epoch 39/60, Batch 10/13, Image: 45.png, Loss_G: 3.9342, Loss_D_A: 0.1055, Loss_D_B: 0.1095\n",
            "Epoch 39/60, Batch 11/13, Image: 31.png, Loss_G: 3.9070, Loss_D_A: 0.1270, Loss_D_B: 0.1544\n",
            "Epoch 39/60, Batch 12/13, Image: 34.png, Loss_G: 4.5882, Loss_D_A: 0.1313, Loss_D_B: 0.1186\n",
            "Epoch 40/60, Batch 0/13, Image: 89.png, Loss_G: 3.5627, Loss_D_A: 0.1401, Loss_D_B: 0.1318\n",
            "Epoch 40/60, Batch 1/13, Image: 27.png, Loss_G: 3.3513, Loss_D_A: 0.1168, Loss_D_B: 0.1498\n",
            "Epoch 40/60, Batch 2/13, Image: 98.png, Loss_G: 3.7428, Loss_D_A: 0.1272, Loss_D_B: 0.1518\n",
            "Epoch 40/60, Batch 3/13, Image: 13.png, Loss_G: 3.3155, Loss_D_A: 0.1926, Loss_D_B: 0.2249\n",
            "Epoch 40/60, Batch 4/13, Image: 44.png, Loss_G: 2.9247, Loss_D_A: 0.1816, Loss_D_B: 0.2082\n",
            "Epoch 40/60, Batch 5/13, Image: 74.png, Loss_G: 3.3570, Loss_D_A: 0.1357, Loss_D_B: 0.1697\n",
            "Epoch 40/60, Batch 6/13, Image: 57.png, Loss_G: 3.2285, Loss_D_A: 0.1582, Loss_D_B: 0.1680\n",
            "Epoch 40/60, Batch 7/13, Image: 67.png, Loss_G: 4.0929, Loss_D_A: 0.0906, Loss_D_B: 0.1008\n",
            "Epoch 40/60, Batch 8/13, Image: 90.png, Loss_G: 3.4901, Loss_D_A: 0.1876, Loss_D_B: 0.2434\n",
            "Epoch 40/60, Batch 9/13, Image: 52.png, Loss_G: 3.8327, Loss_D_A: 0.1283, Loss_D_B: 0.1667\n",
            "Epoch 40/60, Batch 10/13, Image: 17.png, Loss_G: 4.0565, Loss_D_A: 0.1858, Loss_D_B: 0.1682\n",
            "Epoch 40/60, Batch 11/13, Image: 33.png, Loss_G: 4.2826, Loss_D_A: 0.1552, Loss_D_B: 0.1627\n",
            "Epoch 40/60, Batch 12/13, Image: 39.png, Loss_G: 4.2073, Loss_D_A: 0.1141, Loss_D_B: 0.1556\n",
            "Epoch 41/60, Batch 0/13, Image: 63.png, Loss_G: 3.1562, Loss_D_A: 0.1546, Loss_D_B: 0.1748\n",
            "Epoch 41/60, Batch 1/13, Image: 37.png, Loss_G: 3.6074, Loss_D_A: 0.1901, Loss_D_B: 0.1625\n",
            "Epoch 41/60, Batch 2/13, Image: 47.png, Loss_G: 3.3128, Loss_D_A: 0.2267, Loss_D_B: 0.1657\n",
            "Epoch 41/60, Batch 3/13, Image: 21.png, Loss_G: 3.8965, Loss_D_A: 0.0890, Loss_D_B: 0.1302\n",
            "Epoch 41/60, Batch 4/13, Image: 67.png, Loss_G: 4.1568, Loss_D_A: 0.1599, Loss_D_B: 0.1476\n",
            "Epoch 41/60, Batch 5/13, Image: 69.png, Loss_G: 3.2710, Loss_D_A: 0.1892, Loss_D_B: 0.1521\n",
            "Epoch 41/60, Batch 6/13, Image: 38.png, Loss_G: 3.5429, Loss_D_A: 0.1489, Loss_D_B: 0.1054\n",
            "Epoch 41/60, Batch 7/13, Image: 85.png, Loss_G: 4.0574, Loss_D_A: 0.0969, Loss_D_B: 0.0786\n",
            "Epoch 41/60, Batch 8/13, Image: 20.png, Loss_G: 3.2450, Loss_D_A: 0.1719, Loss_D_B: 0.1746\n",
            "Epoch 41/60, Batch 9/13, Image: 83.png, Loss_G: 3.0339, Loss_D_A: 0.1734, Loss_D_B: 0.1953\n",
            "Epoch 41/60, Batch 10/13, Image: 30.png, Loss_G: 3.6025, Loss_D_A: 0.1927, Loss_D_B: 0.1474\n",
            "Epoch 41/60, Batch 11/13, Image: 19.png, Loss_G: 3.5992, Loss_D_A: 0.1805, Loss_D_B: 0.1296\n",
            "Epoch 41/60, Batch 12/13, Image: 48.png, Loss_G: 3.8697, Loss_D_A: 0.0828, Loss_D_B: 0.0783\n",
            "Epoch 42/60, Batch 0/13, Image: 53.png, Loss_G: 3.4635, Loss_D_A: 0.1258, Loss_D_B: 0.1546\n",
            "Epoch 42/60, Batch 1/13, Image: 81.png, Loss_G: 3.7405, Loss_D_A: 0.1318, Loss_D_B: 0.1241\n",
            "Epoch 42/60, Batch 2/13, Image: 55.png, Loss_G: 3.0990, Loss_D_A: 0.1657, Loss_D_B: 0.1352\n",
            "Epoch 42/60, Batch 3/13, Image: 8.png, Loss_G: 3.4239, Loss_D_A: 0.1829, Loss_D_B: 0.1206\n",
            "Epoch 42/60, Batch 4/13, Image: 33.png, Loss_G: 4.2839, Loss_D_A: 0.1248, Loss_D_B: 0.0899\n",
            "Epoch 42/60, Batch 5/13, Image: 96.png, Loss_G: 4.5296, Loss_D_A: 0.1047, Loss_D_B: 0.0776\n",
            "Epoch 42/60, Batch 6/13, Image: 4.png, Loss_G: 3.3023, Loss_D_A: 0.2317, Loss_D_B: 0.1903\n",
            "Epoch 42/60, Batch 7/13, Image: 61.png, Loss_G: 3.1810, Loss_D_A: 0.1675, Loss_D_B: 0.1646\n",
            "Epoch 42/60, Batch 8/13, Image: 15.png, Loss_G: 3.1263, Loss_D_A: 0.1296, Loss_D_B: 0.1393\n",
            "Epoch 42/60, Batch 9/13, Image: 2.png, Loss_G: 4.3393, Loss_D_A: 0.1698, Loss_D_B: 0.1299\n",
            "Epoch 42/60, Batch 10/13, Image: 52.png, Loss_G: 2.8879, Loss_D_A: 0.2415, Loss_D_B: 0.1785\n",
            "Epoch 42/60, Batch 11/13, Image: 58.png, Loss_G: 3.1523, Loss_D_A: 0.1828, Loss_D_B: 0.1513\n",
            "Epoch 42/60, Batch 12/13, Image: 44.png, Loss_G: 3.7369, Loss_D_A: 0.2445, Loss_D_B: 0.2153\n",
            "Epoch 43/60, Batch 0/13, Image: 50.png, Loss_G: 4.2809, Loss_D_A: 0.1561, Loss_D_B: 0.1546\n",
            "Epoch 43/60, Batch 1/13, Image: 91.png, Loss_G: 3.2654, Loss_D_A: 0.1379, Loss_D_B: 0.1034\n",
            "Epoch 43/60, Batch 2/13, Image: 8.png, Loss_G: 3.0995, Loss_D_A: 0.2590, Loss_D_B: 0.1836\n",
            "Epoch 43/60, Batch 3/13, Image: 22.png, Loss_G: 3.3485, Loss_D_A: 0.1404, Loss_D_B: 0.1270\n",
            "Epoch 43/60, Batch 4/13, Image: 51.png, Loss_G: 3.9748, Loss_D_A: 0.1469, Loss_D_B: 0.1548\n",
            "Epoch 43/60, Batch 5/13, Image: 99.png, Loss_G: 3.6450, Loss_D_A: 0.1817, Loss_D_B: 0.1768\n",
            "Epoch 43/60, Batch 6/13, Image: 55.png, Loss_G: 3.0826, Loss_D_A: 0.1957, Loss_D_B: 0.1560\n",
            "Epoch 43/60, Batch 7/13, Image: 13.png, Loss_G: 3.4534, Loss_D_A: 0.1548, Loss_D_B: 0.1490\n",
            "Epoch 43/60, Batch 8/13, Image: 81.png, Loss_G: 3.0408, Loss_D_A: 0.1609, Loss_D_B: 0.1606\n",
            "Epoch 43/60, Batch 9/13, Image: 15.png, Loss_G: 3.4549, Loss_D_A: 0.1935, Loss_D_B: 0.1767\n",
            "Epoch 43/60, Batch 10/13, Image: 14.png, Loss_G: 3.7781, Loss_D_A: 0.1376, Loss_D_B: 0.1321\n",
            "Epoch 43/60, Batch 11/13, Image: 95.png, Loss_G: 2.9880, Loss_D_A: 0.1344, Loss_D_B: 0.1401\n",
            "Epoch 43/60, Batch 12/13, Image: 73.png, Loss_G: 4.1023, Loss_D_A: 0.1522, Loss_D_B: 0.1519\n",
            "Epoch 44/60, Batch 0/13, Image: 86.png, Loss_G: 3.6081, Loss_D_A: 0.1845, Loss_D_B: 0.1378\n",
            "Epoch 44/60, Batch 1/13, Image: 95.png, Loss_G: 3.3250, Loss_D_A: 0.2261, Loss_D_B: 0.2031\n",
            "Epoch 44/60, Batch 2/13, Image: 96.png, Loss_G: 3.6791, Loss_D_A: 0.1583, Loss_D_B: 0.1217\n",
            "Epoch 44/60, Batch 3/13, Image: 40.png, Loss_G: 4.6445, Loss_D_A: 0.1203, Loss_D_B: 0.1293\n",
            "Epoch 44/60, Batch 4/13, Image: 7.png, Loss_G: 3.4056, Loss_D_A: 0.2069, Loss_D_B: 0.2084\n",
            "Epoch 44/60, Batch 5/13, Image: 65.png, Loss_G: 3.1989, Loss_D_A: 0.1866, Loss_D_B: 0.1800\n",
            "Epoch 44/60, Batch 6/13, Image: 28.png, Loss_G: 3.0061, Loss_D_A: 0.2055, Loss_D_B: 0.1576\n",
            "Epoch 44/60, Batch 7/13, Image: 33.png, Loss_G: 3.9171, Loss_D_A: 0.1583, Loss_D_B: 0.1416\n",
            "Epoch 44/60, Batch 8/13, Image: 72.png, Loss_G: 4.2504, Loss_D_A: 0.1723, Loss_D_B: 0.1748\n",
            "Epoch 44/60, Batch 9/13, Image: 78.png, Loss_G: 3.5941, Loss_D_A: 0.1573, Loss_D_B: 0.1193\n",
            "Epoch 44/60, Batch 10/13, Image: 11.png, Loss_G: 3.7101, Loss_D_A: 0.1871, Loss_D_B: 0.1862\n",
            "Epoch 44/60, Batch 11/13, Image: 80.png, Loss_G: 3.6116, Loss_D_A: 0.1900, Loss_D_B: 0.1881\n",
            "Epoch 44/60, Batch 12/13, Image: 76.png, Loss_G: 3.6742, Loss_D_A: 0.1427, Loss_D_B: 0.1105\n",
            "Epoch 45/60, Batch 0/13, Image: 69.png, Loss_G: 3.3209, Loss_D_A: 0.1662, Loss_D_B: 0.1142\n",
            "Epoch 45/60, Batch 1/13, Image: 59.png, Loss_G: 3.1910, Loss_D_A: 0.2358, Loss_D_B: 0.1708\n",
            "Epoch 45/60, Batch 2/13, Image: 82.png, Loss_G: 3.1926, Loss_D_A: 0.2130, Loss_D_B: 0.2387\n",
            "Epoch 45/60, Batch 3/13, Image: 80.png, Loss_G: 5.1414, Loss_D_A: 0.1638, Loss_D_B: 0.1619\n",
            "Epoch 45/60, Batch 4/13, Image: 40.png, Loss_G: 4.1796, Loss_D_A: 0.1985, Loss_D_B: 0.1597\n",
            "Epoch 45/60, Batch 5/13, Image: 6.png, Loss_G: 3.1563, Loss_D_A: 0.2362, Loss_D_B: 0.1247\n",
            "Epoch 45/60, Batch 6/13, Image: 39.png, Loss_G: 3.6307, Loss_D_A: 0.1966, Loss_D_B: 0.1476\n",
            "Epoch 45/60, Batch 7/13, Image: 47.png, Loss_G: 2.8962, Loss_D_A: 0.2196, Loss_D_B: 0.2122\n",
            "Epoch 45/60, Batch 8/13, Image: 84.png, Loss_G: 3.3526, Loss_D_A: 0.1243, Loss_D_B: 0.1146\n",
            "Epoch 45/60, Batch 9/13, Image: 48.png, Loss_G: 3.7495, Loss_D_A: 0.1775, Loss_D_B: 0.1481\n",
            "Epoch 45/60, Batch 10/13, Image: 41.png, Loss_G: 3.2687, Loss_D_A: 0.2016, Loss_D_B: 0.1203\n",
            "Epoch 45/60, Batch 11/13, Image: 71.png, Loss_G: 3.5994, Loss_D_A: 0.1175, Loss_D_B: 0.1082\n",
            "Epoch 45/60, Batch 12/13, Image: 77.png, Loss_G: 4.7726, Loss_D_A: 0.1463, Loss_D_B: 0.1308\n",
            "Epoch 46/60, Batch 0/13, Image: 37.png, Loss_G: 3.3402, Loss_D_A: 0.1680, Loss_D_B: 0.1265\n",
            "Epoch 46/60, Batch 1/13, Image: 49.png, Loss_G: 3.5976, Loss_D_A: 0.1470, Loss_D_B: 0.1052\n",
            "Epoch 46/60, Batch 2/13, Image: 31.png, Loss_G: 3.3306, Loss_D_A: 0.1620, Loss_D_B: 0.1137\n",
            "Epoch 46/60, Batch 3/13, Image: 21.png, Loss_G: 3.8202, Loss_D_A: 0.1840, Loss_D_B: 0.1526\n",
            "Epoch 46/60, Batch 4/13, Image: 68.png, Loss_G: 4.2400, Loss_D_A: 0.0651, Loss_D_B: 0.0788\n",
            "Epoch 46/60, Batch 5/13, Image: 38.png, Loss_G: 4.5965, Loss_D_A: 0.2356, Loss_D_B: 0.2024\n",
            "Epoch 46/60, Batch 6/13, Image: 96.png, Loss_G: 3.4016, Loss_D_A: 0.1862, Loss_D_B: 0.1189\n",
            "Epoch 46/60, Batch 7/13, Image: 62.png, Loss_G: 4.3973, Loss_D_A: 0.1930, Loss_D_B: 0.1316\n",
            "Epoch 46/60, Batch 8/13, Image: 46.png, Loss_G: 3.4475, Loss_D_A: 0.1683, Loss_D_B: 0.1490\n",
            "Epoch 46/60, Batch 9/13, Image: 18.png, Loss_G: 3.4838, Loss_D_A: 0.1497, Loss_D_B: 0.1276\n",
            "Epoch 46/60, Batch 10/13, Image: 71.png, Loss_G: 2.9788, Loss_D_A: 0.2254, Loss_D_B: 0.1722\n",
            "Epoch 46/60, Batch 11/13, Image: 66.png, Loss_G: 4.0360, Loss_D_A: 0.1562, Loss_D_B: 0.0922\n",
            "Epoch 46/60, Batch 12/13, Image: 35.png, Loss_G: 3.2690, Loss_D_A: 0.0944, Loss_D_B: 0.0959\n",
            "Epoch 47/60, Batch 0/13, Image: 10.png, Loss_G: 3.3724, Loss_D_A: 0.1544, Loss_D_B: 0.1687\n",
            "Epoch 47/60, Batch 1/13, Image: 19.png, Loss_G: 4.0704, Loss_D_A: 0.1635, Loss_D_B: 0.1230\n",
            "Epoch 47/60, Batch 2/13, Image: 11.png, Loss_G: 4.6933, Loss_D_A: 0.1717, Loss_D_B: 0.1178\n",
            "Epoch 47/60, Batch 3/13, Image: 24.png, Loss_G: 3.4477, Loss_D_A: 0.1065, Loss_D_B: 0.1239\n",
            "Epoch 47/60, Batch 4/13, Image: 29.png, Loss_G: 3.6542, Loss_D_A: 0.1189, Loss_D_B: 0.1781\n",
            "Epoch 47/60, Batch 5/13, Image: 89.png, Loss_G: 3.8955, Loss_D_A: 0.2007, Loss_D_B: 0.1515\n",
            "Epoch 47/60, Batch 6/13, Image: 25.png, Loss_G: 3.3722, Loss_D_A: 0.1497, Loss_D_B: 0.0970\n",
            "Epoch 47/60, Batch 7/13, Image: 39.png, Loss_G: 4.1984, Loss_D_A: 0.1126, Loss_D_B: 0.1193\n",
            "Epoch 47/60, Batch 8/13, Image: 96.png, Loss_G: 3.7221, Loss_D_A: 0.1100, Loss_D_B: 0.1488\n",
            "Epoch 47/60, Batch 9/13, Image: 71.png, Loss_G: 3.1087, Loss_D_A: 0.1258, Loss_D_B: 0.1560\n",
            "Epoch 47/60, Batch 10/13, Image: 5.png, Loss_G: 3.5148, Loss_D_A: 0.2629, Loss_D_B: 0.2314\n",
            "Epoch 47/60, Batch 11/13, Image: 87.png, Loss_G: 3.6970, Loss_D_A: 0.2192, Loss_D_B: 0.1244\n",
            "Epoch 47/60, Batch 12/13, Image: 69.png, Loss_G: 3.3073, Loss_D_A: 0.1688, Loss_D_B: 0.1976\n",
            "Epoch 48/60, Batch 0/13, Image: 32.png, Loss_G: 3.5720, Loss_D_A: 0.1383, Loss_D_B: 0.1686\n",
            "Epoch 48/60, Batch 1/13, Image: 61.png, Loss_G: 3.7611, Loss_D_A: 0.1322, Loss_D_B: 0.1093\n",
            "Epoch 48/60, Batch 2/13, Image: 18.png, Loss_G: 2.9888, Loss_D_A: 0.2639, Loss_D_B: 0.1720\n",
            "Epoch 48/60, Batch 3/13, Image: 20.png, Loss_G: 3.3006, Loss_D_A: 0.2542, Loss_D_B: 0.1573\n",
            "Epoch 48/60, Batch 4/13, Image: 35.png, Loss_G: 3.4596, Loss_D_A: 0.1266, Loss_D_B: 0.1398\n",
            "Epoch 48/60, Batch 5/13, Image: 92.png, Loss_G: 3.0845, Loss_D_A: 0.1654, Loss_D_B: 0.1665\n",
            "Epoch 48/60, Batch 6/13, Image: 8.png, Loss_G: 2.8177, Loss_D_A: 0.1632, Loss_D_B: 0.1371\n",
            "Epoch 48/60, Batch 7/13, Image: 40.png, Loss_G: 3.6493, Loss_D_A: 0.1618, Loss_D_B: 0.0855\n",
            "Epoch 48/60, Batch 8/13, Image: 50.png, Loss_G: 3.2083, Loss_D_A: 0.1897, Loss_D_B: 0.1200\n",
            "Epoch 48/60, Batch 9/13, Image: 5.png, Loss_G: 4.4211, Loss_D_A: 0.1242, Loss_D_B: 0.1245\n",
            "Epoch 48/60, Batch 10/13, Image: 28.png, Loss_G: 3.4382, Loss_D_A: 0.1283, Loss_D_B: 0.1509\n",
            "Epoch 48/60, Batch 11/13, Image: 33.png, Loss_G: 3.7176, Loss_D_A: 0.1594, Loss_D_B: 0.1125\n",
            "Epoch 48/60, Batch 12/13, Image: 88.png, Loss_G: 4.5382, Loss_D_A: 0.2704, Loss_D_B: 0.1798\n",
            "Epoch 49/60, Batch 0/13, Image: 80.png, Loss_G: 4.5008, Loss_D_A: 0.1219, Loss_D_B: 0.1004\n",
            "Epoch 49/60, Batch 1/13, Image: 26.png, Loss_G: 3.6369, Loss_D_A: 0.2092, Loss_D_B: 0.2136\n",
            "Epoch 49/60, Batch 2/13, Image: 6.png, Loss_G: 3.4108, Loss_D_A: 0.1618, Loss_D_B: 0.1568\n",
            "Epoch 49/60, Batch 3/13, Image: 61.png, Loss_G: 3.2199, Loss_D_A: 0.1758, Loss_D_B: 0.1193\n",
            "Epoch 49/60, Batch 4/13, Image: 12.png, Loss_G: 3.8132, Loss_D_A: 0.1523, Loss_D_B: 0.0873\n",
            "Epoch 49/60, Batch 5/13, Image: 84.png, Loss_G: 4.0696, Loss_D_A: 0.1495, Loss_D_B: 0.1184\n",
            "Epoch 49/60, Batch 6/13, Image: 41.png, Loss_G: 3.5613, Loss_D_A: 0.1367, Loss_D_B: 0.1181\n",
            "Epoch 49/60, Batch 7/13, Image: 40.png, Loss_G: 4.0692, Loss_D_A: 0.1555, Loss_D_B: 0.1473\n",
            "Epoch 49/60, Batch 8/13, Image: 32.png, Loss_G: 3.3222, Loss_D_A: 0.1577, Loss_D_B: 0.1324\n",
            "Epoch 49/60, Batch 9/13, Image: 97.png, Loss_G: 3.3422, Loss_D_A: 0.2636, Loss_D_B: 0.1896\n",
            "Epoch 49/60, Batch 10/13, Image: 82.png, Loss_G: 3.2691, Loss_D_A: 0.1557, Loss_D_B: 0.1536\n",
            "Epoch 49/60, Batch 11/13, Image: 46.png, Loss_G: 3.0675, Loss_D_A: 0.3074, Loss_D_B: 0.1962\n",
            "Epoch 49/60, Batch 12/13, Image: 3.png, Loss_G: 3.6447, Loss_D_A: 0.1688, Loss_D_B: 0.1671\n",
            "Epoch 50/60, Batch 0/13, Image: 79.png, Loss_G: 4.6990, Loss_D_A: 0.1674, Loss_D_B: 0.1400\n",
            "Epoch 50/60, Batch 1/13, Image: 50.png, Loss_G: 3.8540, Loss_D_A: 0.1803, Loss_D_B: 0.1389\n",
            "Epoch 50/60, Batch 2/13, Image: 65.png, Loss_G: 3.9902, Loss_D_A: 0.1751, Loss_D_B: 0.1491\n",
            "Epoch 50/60, Batch 3/13, Image: 98.png, Loss_G: 3.4397, Loss_D_A: 0.1734, Loss_D_B: 0.1689\n",
            "Epoch 50/60, Batch 4/13, Image: 17.png, Loss_G: 3.3136, Loss_D_A: 0.2955, Loss_D_B: 0.2470\n",
            "Epoch 50/60, Batch 5/13, Image: 36.png, Loss_G: 3.2978, Loss_D_A: 0.2024, Loss_D_B: 0.1270\n",
            "Epoch 50/60, Batch 6/13, Image: 13.png, Loss_G: 3.9419, Loss_D_A: 0.1374, Loss_D_B: 0.0979\n",
            "Epoch 50/60, Batch 7/13, Image: 52.png, Loss_G: 3.3662, Loss_D_A: 0.1373, Loss_D_B: 0.1076\n",
            "Epoch 50/60, Batch 8/13, Image: 33.png, Loss_G: 3.2985, Loss_D_A: 0.1340, Loss_D_B: 0.1347\n",
            "Epoch 50/60, Batch 9/13, Image: 88.png, Loss_G: 3.4426, Loss_D_A: 0.1745, Loss_D_B: 0.1707\n",
            "Epoch 50/60, Batch 10/13, Image: 37.png, Loss_G: 3.5009, Loss_D_A: 0.1775, Loss_D_B: 0.1188\n",
            "Epoch 50/60, Batch 11/13, Image: 82.png, Loss_G: 3.4028, Loss_D_A: 0.1822, Loss_D_B: 0.1392\n",
            "Epoch 50/60, Batch 12/13, Image: 41.png, Loss_G: 3.2111, Loss_D_A: 0.1272, Loss_D_B: 0.0970\n",
            "Epoch 51/60, Batch 0/13, Image: 95.png, Loss_G: 3.3166, Loss_D_A: 0.1150, Loss_D_B: 0.1371\n",
            "Epoch 51/60, Batch 1/13, Image: 35.png, Loss_G: 3.9865, Loss_D_A: 0.1295, Loss_D_B: 0.1281\n",
            "Epoch 51/60, Batch 2/13, Image: 73.png, Loss_G: 3.0693, Loss_D_A: 0.2262, Loss_D_B: 0.1406\n",
            "Epoch 51/60, Batch 3/13, Image: 91.png, Loss_G: 3.2393, Loss_D_A: 0.1316, Loss_D_B: 0.0994\n",
            "Epoch 51/60, Batch 4/13, Image: 54.png, Loss_G: 3.3869, Loss_D_A: 0.2019, Loss_D_B: 0.2048\n",
            "Epoch 51/60, Batch 5/13, Image: 32.png, Loss_G: 4.8447, Loss_D_A: 0.1457, Loss_D_B: 0.1440\n",
            "Epoch 51/60, Batch 6/13, Image: 3.png, Loss_G: 3.1016, Loss_D_A: 0.2135, Loss_D_B: 0.1714\n",
            "Epoch 51/60, Batch 7/13, Image: 24.png, Loss_G: 4.2627, Loss_D_A: 0.2351, Loss_D_B: 0.1301\n",
            "Epoch 51/60, Batch 8/13, Image: 84.png, Loss_G: 3.5265, Loss_D_A: 0.1555, Loss_D_B: 0.1290\n",
            "Epoch 51/60, Batch 9/13, Image: 97.png, Loss_G: 3.6078, Loss_D_A: 0.1623, Loss_D_B: 0.1941\n",
            "Epoch 51/60, Batch 10/13, Image: 70.png, Loss_G: 4.7280, Loss_D_A: 0.1443, Loss_D_B: 0.1437\n",
            "Epoch 51/60, Batch 11/13, Image: 52.png, Loss_G: 3.0883, Loss_D_A: 0.1644, Loss_D_B: 0.1206\n",
            "Epoch 51/60, Batch 12/13, Image: 58.png, Loss_G: 3.5301, Loss_D_A: 0.3589, Loss_D_B: 0.2787\n",
            "Epoch 52/60, Batch 0/13, Image: 53.png, Loss_G: 3.3112, Loss_D_A: 0.2178, Loss_D_B: 0.1868\n",
            "Epoch 52/60, Batch 1/13, Image: 62.png, Loss_G: 3.4898, Loss_D_A: 0.1475, Loss_D_B: 0.1686\n",
            "Epoch 52/60, Batch 2/13, Image: 42.png, Loss_G: 3.3357, Loss_D_A: 0.1350, Loss_D_B: 0.1000\n",
            "Epoch 52/60, Batch 3/13, Image: 61.png, Loss_G: 3.4778, Loss_D_A: 0.1443, Loss_D_B: 0.1167\n",
            "Epoch 52/60, Batch 4/13, Image: 100.png, Loss_G: 2.8031, Loss_D_A: 0.2509, Loss_D_B: 0.1887\n",
            "Epoch 52/60, Batch 5/13, Image: 3.png, Loss_G: 2.9880, Loss_D_A: 0.2194, Loss_D_B: 0.1823\n",
            "Epoch 52/60, Batch 6/13, Image: 59.png, Loss_G: 3.3093, Loss_D_A: 0.1537, Loss_D_B: 0.1159\n",
            "Epoch 52/60, Batch 7/13, Image: 51.png, Loss_G: 4.1209, Loss_D_A: 0.1167, Loss_D_B: 0.1314\n",
            "Epoch 52/60, Batch 8/13, Image: 10.png, Loss_G: 3.7161, Loss_D_A: 0.1579, Loss_D_B: 0.1813\n",
            "Epoch 52/60, Batch 9/13, Image: 21.png, Loss_G: 4.2627, Loss_D_A: 0.1805, Loss_D_B: 0.1462\n",
            "Epoch 52/60, Batch 10/13, Image: 65.png, Loss_G: 3.1817, Loss_D_A: 0.1648, Loss_D_B: 0.1349\n",
            "Epoch 52/60, Batch 11/13, Image: 13.png, Loss_G: 3.2960, Loss_D_A: 0.1985, Loss_D_B: 0.1869\n",
            "Epoch 52/60, Batch 12/13, Image: 85.png, Loss_G: 3.7111, Loss_D_A: 0.1922, Loss_D_B: 0.1739\n",
            "Epoch 53/60, Batch 0/13, Image: 26.png, Loss_G: 3.5113, Loss_D_A: 0.1593, Loss_D_B: 0.1653\n",
            "Epoch 53/60, Batch 1/13, Image: 40.png, Loss_G: 3.2444, Loss_D_A: 0.1423, Loss_D_B: 0.1604\n",
            "Epoch 53/60, Batch 2/13, Image: 54.png, Loss_G: 2.9472, Loss_D_A: 0.1536, Loss_D_B: 0.1433\n",
            "Epoch 53/60, Batch 3/13, Image: 21.png, Loss_G: 3.3320, Loss_D_A: 0.1572, Loss_D_B: 0.1369\n",
            "Epoch 53/60, Batch 4/13, Image: 52.png, Loss_G: 3.2977, Loss_D_A: 0.1257, Loss_D_B: 0.1319\n",
            "Epoch 53/60, Batch 5/13, Image: 44.png, Loss_G: 4.1606, Loss_D_A: 0.1381, Loss_D_B: 0.1380\n",
            "Epoch 53/60, Batch 6/13, Image: 36.png, Loss_G: 3.6306, Loss_D_A: 0.1213, Loss_D_B: 0.1435\n",
            "Epoch 53/60, Batch 7/13, Image: 99.png, Loss_G: 3.2406, Loss_D_A: 0.2859, Loss_D_B: 0.2469\n",
            "Epoch 53/60, Batch 8/13, Image: 71.png, Loss_G: 4.0741, Loss_D_A: 0.1282, Loss_D_B: 0.1671\n",
            "Epoch 53/60, Batch 9/13, Image: 20.png, Loss_G: 3.5004, Loss_D_A: 0.1798, Loss_D_B: 0.2327\n",
            "Epoch 53/60, Batch 10/13, Image: 67.png, Loss_G: 3.7295, Loss_D_A: 0.1842, Loss_D_B: 0.1914\n",
            "Epoch 53/60, Batch 11/13, Image: 9.png, Loss_G: 4.2984, Loss_D_A: 0.2072, Loss_D_B: 0.1803\n",
            "Epoch 53/60, Batch 12/13, Image: 100.png, Loss_G: 3.7230, Loss_D_A: 0.1625, Loss_D_B: 0.1453\n",
            "Epoch 54/60, Batch 0/13, Image: 15.png, Loss_G: 3.6554, Loss_D_A: 0.1448, Loss_D_B: 0.1346\n",
            "Epoch 54/60, Batch 1/13, Image: 53.png, Loss_G: 3.6141, Loss_D_A: 0.1005, Loss_D_B: 0.1983\n",
            "Epoch 54/60, Batch 2/13, Image: 85.png, Loss_G: 3.9259, Loss_D_A: 0.1206, Loss_D_B: 0.1305\n",
            "Epoch 54/60, Batch 3/13, Image: 43.png, Loss_G: 3.0733, Loss_D_A: 0.1643, Loss_D_B: 0.1467\n",
            "Epoch 54/60, Batch 4/13, Image: 94.png, Loss_G: 2.6960, Loss_D_A: 0.1985, Loss_D_B: 0.1477\n",
            "Epoch 54/60, Batch 5/13, Image: 79.png, Loss_G: 3.3076, Loss_D_A: 0.1541, Loss_D_B: 0.1599\n",
            "Epoch 54/60, Batch 6/13, Image: 26.png, Loss_G: 3.4312, Loss_D_A: 0.1330, Loss_D_B: 0.1911\n",
            "Epoch 54/60, Batch 7/13, Image: 16.png, Loss_G: 3.5712, Loss_D_A: 0.1574, Loss_D_B: 0.1860\n",
            "Epoch 54/60, Batch 8/13, Image: 50.png, Loss_G: 3.8653, Loss_D_A: 0.1253, Loss_D_B: 0.0979\n",
            "Epoch 54/60, Batch 9/13, Image: 18.png, Loss_G: 3.4673, Loss_D_A: 0.2139, Loss_D_B: 0.2007\n",
            "Epoch 54/60, Batch 10/13, Image: 38.png, Loss_G: 3.4608, Loss_D_A: 0.1295, Loss_D_B: 0.1289\n",
            "Epoch 54/60, Batch 11/13, Image: 89.png, Loss_G: 3.5630, Loss_D_A: 0.1397, Loss_D_B: 0.1380\n",
            "Epoch 54/60, Batch 12/13, Image: 56.png, Loss_G: 3.3924, Loss_D_A: 0.1855, Loss_D_B: 0.1376\n",
            "Epoch 55/60, Batch 0/13, Image: 71.png, Loss_G: 2.9695, Loss_D_A: 0.1674, Loss_D_B: 0.1545\n",
            "Epoch 55/60, Batch 1/13, Image: 23.png, Loss_G: 4.6032, Loss_D_A: 0.1730, Loss_D_B: 0.1599\n",
            "Epoch 55/60, Batch 2/13, Image: 34.png, Loss_G: 3.5880, Loss_D_A: 0.2411, Loss_D_B: 0.2018\n",
            "Epoch 55/60, Batch 3/13, Image: 29.png, Loss_G: 3.6830, Loss_D_A: 0.3063, Loss_D_B: 0.1787\n",
            "Epoch 55/60, Batch 4/13, Image: 51.png, Loss_G: 3.5246, Loss_D_A: 0.1699, Loss_D_B: 0.1149\n",
            "Epoch 55/60, Batch 5/13, Image: 73.png, Loss_G: 3.4718, Loss_D_A: 0.1739, Loss_D_B: 0.1471\n",
            "Epoch 55/60, Batch 6/13, Image: 69.png, Loss_G: 3.5345, Loss_D_A: 0.1489, Loss_D_B: 0.1846\n",
            "Epoch 55/60, Batch 7/13, Image: 25.png, Loss_G: 3.0940, Loss_D_A: 0.1617, Loss_D_B: 0.1251\n",
            "Epoch 55/60, Batch 8/13, Image: 78.png, Loss_G: 3.5913, Loss_D_A: 0.1058, Loss_D_B: 0.1024\n",
            "Epoch 55/60, Batch 9/13, Image: 30.png, Loss_G: 3.9145, Loss_D_A: 0.0916, Loss_D_B: 0.1022\n",
            "Epoch 55/60, Batch 10/13, Image: 79.png, Loss_G: 3.6155, Loss_D_A: 0.2085, Loss_D_B: 0.1572\n",
            "Epoch 55/60, Batch 11/13, Image: 7.png, Loss_G: 3.2580, Loss_D_A: 0.1737, Loss_D_B: 0.1581\n",
            "Epoch 55/60, Batch 12/13, Image: 11.png, Loss_G: 5.5926, Loss_D_A: 0.1187, Loss_D_B: 0.1043\n",
            "Epoch 56/60, Batch 0/13, Image: 2.png, Loss_G: 3.9487, Loss_D_A: 0.1753, Loss_D_B: 0.1572\n",
            "Epoch 56/60, Batch 1/13, Image: 76.png, Loss_G: 3.4883, Loss_D_A: 0.1794, Loss_D_B: 0.1560\n",
            "Epoch 56/60, Batch 2/13, Image: 59.png, Loss_G: 3.4779, Loss_D_A: 0.2080, Loss_D_B: 0.1329\n",
            "Epoch 56/60, Batch 3/13, Image: 47.png, Loss_G: 3.5357, Loss_D_A: 0.2356, Loss_D_B: 0.1579\n",
            "Epoch 56/60, Batch 4/13, Image: 22.png, Loss_G: 3.0989, Loss_D_A: 0.1641, Loss_D_B: 0.1625\n",
            "Epoch 56/60, Batch 5/13, Image: 40.png, Loss_G: 3.1564, Loss_D_A: 0.1808, Loss_D_B: 0.1759\n",
            "Epoch 56/60, Batch 6/13, Image: 46.png, Loss_G: 3.8468, Loss_D_A: 0.1677, Loss_D_B: 0.1147\n",
            "Epoch 56/60, Batch 7/13, Image: 54.png, Loss_G: 4.4834, Loss_D_A: 0.1713, Loss_D_B: 0.1527\n",
            "Epoch 56/60, Batch 8/13, Image: 96.png, Loss_G: 3.1295, Loss_D_A: 0.2200, Loss_D_B: 0.1707\n",
            "Epoch 56/60, Batch 9/13, Image: 16.png, Loss_G: 3.8609, Loss_D_A: 0.1762, Loss_D_B: 0.1613\n",
            "Epoch 56/60, Batch 10/13, Image: 89.png, Loss_G: 3.5395, Loss_D_A: 0.1361, Loss_D_B: 0.1309\n",
            "Epoch 56/60, Batch 11/13, Image: 44.png, Loss_G: 3.8366, Loss_D_A: 0.1424, Loss_D_B: 0.1643\n",
            "Epoch 56/60, Batch 12/13, Image: 70.png, Loss_G: 4.1327, Loss_D_A: 0.2873, Loss_D_B: 0.2576\n",
            "Epoch 57/60, Batch 0/13, Image: 60.png, Loss_G: 3.4682, Loss_D_A: 0.1614, Loss_D_B: 0.1614\n",
            "Epoch 57/60, Batch 1/13, Image: 67.png, Loss_G: 3.6639, Loss_D_A: 0.1724, Loss_D_B: 0.1816\n",
            "Epoch 57/60, Batch 2/13, Image: 78.png, Loss_G: 2.6750, Loss_D_A: 0.1499, Loss_D_B: 0.1643\n",
            "Epoch 57/60, Batch 3/13, Image: 50.png, Loss_G: 2.9678, Loss_D_A: 0.2105, Loss_D_B: 0.1765\n",
            "Epoch 57/60, Batch 4/13, Image: 53.png, Loss_G: 3.3413, Loss_D_A: 0.2253, Loss_D_B: 0.1877\n",
            "Epoch 57/60, Batch 5/13, Image: 20.png, Loss_G: 3.8299, Loss_D_A: 0.1779, Loss_D_B: 0.2084\n",
            "Epoch 57/60, Batch 6/13, Image: 4.png, Loss_G: 3.7469, Loss_D_A: 0.1838, Loss_D_B: 0.2064\n",
            "Epoch 57/60, Batch 7/13, Image: 35.png, Loss_G: 3.5592, Loss_D_A: 0.1577, Loss_D_B: 0.0899\n",
            "Epoch 57/60, Batch 8/13, Image: 86.png, Loss_G: 3.3131, Loss_D_A: 0.2432, Loss_D_B: 0.1257\n",
            "Epoch 57/60, Batch 9/13, Image: 26.png, Loss_G: 4.6181, Loss_D_A: 0.1640, Loss_D_B: 0.1247\n",
            "Epoch 57/60, Batch 10/13, Image: 55.png, Loss_G: 3.5632, Loss_D_A: 0.1791, Loss_D_B: 0.1433\n",
            "Epoch 57/60, Batch 11/13, Image: 23.png, Loss_G: 3.2403, Loss_D_A: 0.1887, Loss_D_B: 0.1364\n",
            "Epoch 57/60, Batch 12/13, Image: 66.png, Loss_G: 3.5382, Loss_D_A: 0.1558, Loss_D_B: 0.1242\n",
            "Epoch 58/60, Batch 0/13, Image: 8.png, Loss_G: 2.9413, Loss_D_A: 0.2229, Loss_D_B: 0.1589\n",
            "Epoch 58/60, Batch 1/13, Image: 25.png, Loss_G: 3.3185, Loss_D_A: 0.2179, Loss_D_B: 0.1694\n",
            "Epoch 58/60, Batch 2/13, Image: 28.png, Loss_G: 3.6558, Loss_D_A: 0.1595, Loss_D_B: 0.1464\n",
            "Epoch 58/60, Batch 3/13, Image: 95.png, Loss_G: 3.6487, Loss_D_A: 0.1124, Loss_D_B: 0.1022\n",
            "Epoch 58/60, Batch 4/13, Image: 27.png, Loss_G: 3.8364, Loss_D_A: 0.1221, Loss_D_B: 0.1527\n",
            "Epoch 58/60, Batch 5/13, Image: 42.png, Loss_G: 4.0273, Loss_D_A: 0.1538, Loss_D_B: 0.1584\n",
            "Epoch 58/60, Batch 6/13, Image: 31.png, Loss_G: 3.7249, Loss_D_A: 0.2360, Loss_D_B: 0.1515\n",
            "Epoch 58/60, Batch 7/13, Image: 14.png, Loss_G: 2.9226, Loss_D_A: 0.1844, Loss_D_B: 0.1666\n",
            "Epoch 58/60, Batch 8/13, Image: 75.png, Loss_G: 4.0179, Loss_D_A: 0.1969, Loss_D_B: 0.1942\n",
            "Epoch 58/60, Batch 9/13, Image: 79.png, Loss_G: 3.2781, Loss_D_A: 0.1351, Loss_D_B: 0.1144\n",
            "Epoch 58/60, Batch 10/13, Image: 26.png, Loss_G: 3.4161, Loss_D_A: 0.2315, Loss_D_B: 0.1620\n",
            "Epoch 58/60, Batch 11/13, Image: 9.png, Loss_G: 3.3819, Loss_D_A: 0.2270, Loss_D_B: 0.2076\n",
            "Epoch 58/60, Batch 12/13, Image: 32.png, Loss_G: 4.4063, Loss_D_A: 0.0923, Loss_D_B: 0.1128\n",
            "Epoch 59/60, Batch 0/13, Image: 69.png, Loss_G: 2.9546, Loss_D_A: 0.1157, Loss_D_B: 0.1639\n",
            "Epoch 59/60, Batch 1/13, Image: 16.png, Loss_G: 3.3836, Loss_D_A: 0.1567, Loss_D_B: 0.1769\n",
            "Epoch 59/60, Batch 2/13, Image: 15.png, Loss_G: 3.7453, Loss_D_A: 0.2037, Loss_D_B: 0.1761\n",
            "Epoch 59/60, Batch 3/13, Image: 96.png, Loss_G: 3.4884, Loss_D_A: 0.1991, Loss_D_B: 0.1538\n",
            "Epoch 59/60, Batch 4/13, Image: 22.png, Loss_G: 4.2480, Loss_D_A: 0.1301, Loss_D_B: 0.0895\n",
            "Epoch 59/60, Batch 5/13, Image: 36.png, Loss_G: 3.0628, Loss_D_A: 0.1264, Loss_D_B: 0.1611\n",
            "Epoch 59/60, Batch 6/13, Image: 56.png, Loss_G: 3.6548, Loss_D_A: 0.1424, Loss_D_B: 0.1550\n",
            "Epoch 59/60, Batch 7/13, Image: 63.png, Loss_G: 3.2060, Loss_D_A: 0.2054, Loss_D_B: 0.1953\n",
            "Epoch 59/60, Batch 8/13, Image: 41.png, Loss_G: 2.9824, Loss_D_A: 0.2638, Loss_D_B: 0.1840\n",
            "Epoch 59/60, Batch 9/13, Image: 75.png, Loss_G: 3.2964, Loss_D_A: 0.2434, Loss_D_B: 0.1790\n",
            "Epoch 59/60, Batch 10/13, Image: 43.png, Loss_G: 4.0353, Loss_D_A: 0.2048, Loss_D_B: 0.2128\n",
            "Epoch 59/60, Batch 11/13, Image: 20.png, Loss_G: 2.9839, Loss_D_A: 0.1048, Loss_D_B: 0.1509\n",
            "Epoch 59/60, Batch 12/13, Image: 7.png, Loss_G: 3.4404, Loss_D_A: 0.1762, Loss_D_B: 0.1686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dataset paths and DataLoader\n",
        "input_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/Split-DID-MDN/rainy\"\n",
        "target_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/Split-DID-MDN/non_rainy\"\n",
        "output_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/Split-DID-MDN/results_6/\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define transformation with normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizing between [-1, 1]\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "train_loader = DataLoader(RainDataset(input_dir, target_dir, transform, sample_size=150), batch_size=8, shuffle=True)\n",
        "\n",
        "# Initialize and train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model = DeRainCycleGAN(input_nc=3, output_nc=3, ngf=64, ndf=64, device=device)\n",
        "\n",
        "# Add learning rate schedulers\n",
        "scheduler_G = torch.optim.lr_scheduler.StepLR(model.optimizer_G, step_size=20, gamma=0.5)\n",
        "scheduler_D = torch.optim.lr_scheduler.StepLR(model.optimizer_D, step_size=20, gamma=0.5)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(60):  # Number of epochs\n",
        "    model.netG_A.train()\n",
        "    model.netG_B.train()\n",
        "    epoch_loss_G, epoch_loss_D_A, epoch_loss_D_B = 0, 0, 0\n",
        "\n",
        "    for i, (real_A, real_B, img_name) in enumerate(train_loader):\n",
        "        real_A, real_B = real_A.to(device), real_B.to(device)\n",
        "\n",
        "        # Forward pass and optimization\n",
        "        loss_G, loss_D_A, loss_D_B = model.optimize_parameters(real_A, real_B)\n",
        "        epoch_loss_G += loss_G.item()\n",
        "        epoch_loss_D_A += loss_D_A.item()\n",
        "        epoch_loss_D_B += loss_D_B.item()\n",
        "\n",
        "        # Prevent runtime disconnection\n",
        "        print(f\"Epoch {epoch}/{60}, Batch {i}/{len(train_loader)}, Image: {img_name[0]}, Loss_G: {loss_G:.4f}, Loss_D_A: {loss_D_A:.4f}, Loss_D_B: {loss_D_B:.4f}\")\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler_G.step()\n",
        "    scheduler_D.step()\n",
        "\n",
        "    # Save generated images every 25 epochs and at the final epoch\n",
        "    if epoch == 59:  # Save images for epochs 0, 30, and the final epoch\n",
        "        model.netG_A.eval()  # Use the Rainy -> Clean generator\n",
        "        with torch.no_grad():\n",
        "            for i, (real_A, _, img_names) in enumerate(train_loader):  # Iterate over all batches\n",
        "                real_A = real_A.to(model.device)\n",
        "                fake_B = model.netG_A(real_A)  # Rainy -> Clean\n",
        "\n",
        "                # Denormalize before saving\n",
        "                fake_B = fake_B * 0.5 + 0.5  # Scale from [-1, 1] back to [0, 1]\n",
        "\n",
        "                # Save each image in the batch\n",
        "                for j in range(real_A.size(0)):  # Loop through images in the current batch\n",
        "                    img_name = img_names[j]  # Name of the image\n",
        "                    save_path = os.path.join(output_dir, f\"epoch_{epoch}_de_rained_{img_name}\")\n",
        "                    save_image(fake_B[j], save_path)  # Save individual images\n",
        "\n",
        "print(\"Training completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W17VaL83UxJ4",
        "outputId": "fe213033-786d-4831-ec14-cf835d0230f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch 0/60, Batch 0/19, Image: rainy_1150.jpg, Loss_G: 12.3574, Loss_D_A: 0.6425, Loss_D_B: 0.5356\n",
            "Epoch 0/60, Batch 1/19, Image: rainy_574.jpg, Loss_G: 11.2411, Loss_D_A: 2.9521, Loss_D_B: 2.8910\n",
            "Epoch 0/60, Batch 2/19, Image: rainy_208.jpg, Loss_G: 9.3204, Loss_D_A: 1.0918, Loss_D_B: 1.3594\n",
            "Epoch 0/60, Batch 3/19, Image: rainy_74.jpg, Loss_G: 9.8790, Loss_D_A: 0.3953, Loss_D_B: 0.6878\n",
            "Epoch 0/60, Batch 4/19, Image: rainy_644.jpg, Loss_G: 8.9314, Loss_D_A: 0.6915, Loss_D_B: 0.6177\n",
            "Epoch 0/60, Batch 5/19, Image: rainy_349.jpg, Loss_G: 8.7904, Loss_D_A: 1.0965, Loss_D_B: 0.3643\n",
            "Epoch 0/60, Batch 6/19, Image: rainy_181.jpg, Loss_G: 6.6188, Loss_D_A: 0.3779, Loss_D_B: 0.3356\n",
            "Epoch 0/60, Batch 7/19, Image: rainy_567.jpg, Loss_G: 6.9580, Loss_D_A: 0.3196, Loss_D_B: 0.2952\n",
            "Epoch 0/60, Batch 8/19, Image: rainy_54.jpg, Loss_G: 6.3864, Loss_D_A: 0.2951, Loss_D_B: 0.3144\n",
            "Epoch 0/60, Batch 9/19, Image: rainy_1171.jpg, Loss_G: 5.9655, Loss_D_A: 0.2937, Loss_D_B: 0.3192\n",
            "Epoch 0/60, Batch 10/19, Image: rainy_340.jpg, Loss_G: 5.1630, Loss_D_A: 0.2852, Loss_D_B: 0.3087\n",
            "Epoch 0/60, Batch 11/19, Image: rainy_324.jpg, Loss_G: 4.9099, Loss_D_A: 0.2780, Loss_D_B: 0.2655\n",
            "Epoch 0/60, Batch 12/19, Image: rainy_599.jpg, Loss_G: 5.5188, Loss_D_A: 0.2916, Loss_D_B: 0.2695\n",
            "Epoch 0/60, Batch 13/19, Image: rainy_689.jpg, Loss_G: 4.9519, Loss_D_A: 0.2729, Loss_D_B: 0.2624\n",
            "Epoch 0/60, Batch 14/19, Image: rainy_1183.jpg, Loss_G: 5.4465, Loss_D_A: 0.2648, Loss_D_B: 0.2606\n",
            "Epoch 0/60, Batch 15/19, Image: rainy_97.jpg, Loss_G: 4.7917, Loss_D_A: 0.2654, Loss_D_B: 0.2656\n",
            "Epoch 0/60, Batch 16/19, Image: rainy_736.jpg, Loss_G: 4.2098, Loss_D_A: 0.2596, Loss_D_B: 0.2450\n",
            "Epoch 0/60, Batch 17/19, Image: rainy_78.jpg, Loss_G: 4.5521, Loss_D_A: 0.2603, Loss_D_B: 0.2648\n",
            "Epoch 0/60, Batch 18/19, Image: rainy_1196.jpg, Loss_G: 5.1246, Loss_D_A: 0.2418, Loss_D_B: 0.2453\n",
            "Epoch 1/60, Batch 0/19, Image: rainy_549.jpg, Loss_G: 5.9078, Loss_D_A: 0.2427, Loss_D_B: 0.2453\n",
            "Epoch 1/60, Batch 1/19, Image: rainy_657.jpg, Loss_G: 4.4350, Loss_D_A: 0.2443, Loss_D_B: 0.2520\n",
            "Epoch 1/60, Batch 2/19, Image: rainy_1160.jpg, Loss_G: 5.6508, Loss_D_A: 0.2383, Loss_D_B: 0.2288\n",
            "Epoch 1/60, Batch 3/19, Image: rainy_1092.jpg, Loss_G: 4.0019, Loss_D_A: 0.2481, Loss_D_B: 0.2355\n",
            "Epoch 1/60, Batch 4/19, Image: rainy_145.jpg, Loss_G: 5.0694, Loss_D_A: 0.2406, Loss_D_B: 0.2523\n",
            "Epoch 1/60, Batch 5/19, Image: rainy_1047.jpg, Loss_G: 3.9576, Loss_D_A: 0.2433, Loss_D_B: 0.2554\n",
            "Epoch 1/60, Batch 6/19, Image: rainy_374.jpg, Loss_G: 5.0857, Loss_D_A: 0.2477, Loss_D_B: 0.3154\n",
            "Epoch 1/60, Batch 7/19, Image: rainy_317.jpg, Loss_G: 4.5282, Loss_D_A: 0.2405, Loss_D_B: 0.3604\n",
            "Epoch 1/60, Batch 8/19, Image: rainy_644.jpg, Loss_G: 4.2744, Loss_D_A: 0.2699, Loss_D_B: 0.3709\n",
            "Epoch 1/60, Batch 9/19, Image: rainy_432.jpg, Loss_G: 5.0076, Loss_D_A: 0.3033, Loss_D_B: 0.3035\n",
            "Epoch 1/60, Batch 10/19, Image: rainy_1086.jpg, Loss_G: 4.5391, Loss_D_A: 0.3829, Loss_D_B: 0.4454\n",
            "Epoch 1/60, Batch 11/19, Image: rainy_654.jpg, Loss_G: 5.0568, Loss_D_A: 0.4242, Loss_D_B: 0.4545\n",
            "Epoch 1/60, Batch 12/19, Image: rainy_934.jpg, Loss_G: 5.5772, Loss_D_A: 0.3175, Loss_D_B: 0.2527\n",
            "Epoch 1/60, Batch 13/19, Image: rainy_780.jpg, Loss_G: 5.4055, Loss_D_A: 0.2553, Loss_D_B: 0.2371\n",
            "Epoch 1/60, Batch 14/19, Image: rainy_463.jpg, Loss_G: 5.4952, Loss_D_A: 0.2708, Loss_D_B: 0.2591\n",
            "Epoch 1/60, Batch 15/19, Image: rainy_235.jpg, Loss_G: 4.4969, Loss_D_A: 0.2425, Loss_D_B: 0.2578\n",
            "Epoch 1/60, Batch 16/19, Image: rainy_167.jpg, Loss_G: 5.4507, Loss_D_A: 0.2470, Loss_D_B: 0.2295\n",
            "Epoch 1/60, Batch 17/19, Image: rainy_1128.jpg, Loss_G: 4.6304, Loss_D_A: 0.2149, Loss_D_B: 0.2090\n",
            "Epoch 1/60, Batch 18/19, Image: rainy_340.jpg, Loss_G: 4.3228, Loss_D_A: 0.2593, Loss_D_B: 0.2684\n",
            "Epoch 2/60, Batch 0/19, Image: rainy_373.jpg, Loss_G: 3.8357, Loss_D_A: 0.2351, Loss_D_B: 0.2331\n",
            "Epoch 2/60, Batch 1/19, Image: rainy_1159.jpg, Loss_G: 5.2573, Loss_D_A: 0.2416, Loss_D_B: 0.2382\n",
            "Epoch 2/60, Batch 2/19, Image: rainy_1117.jpg, Loss_G: 4.5091, Loss_D_A: 0.2510, Loss_D_B: 0.2428\n",
            "Epoch 2/60, Batch 3/19, Image: rainy_708.jpg, Loss_G: 3.9555, Loss_D_A: 0.2219, Loss_D_B: 0.2133\n",
            "Epoch 2/60, Batch 4/19, Image: rainy_148.jpg, Loss_G: 4.6792, Loss_D_A: 0.2500, Loss_D_B: 0.2545\n",
            "Epoch 2/60, Batch 5/19, Image: rainy_463.jpg, Loss_G: 3.7412, Loss_D_A: 0.2460, Loss_D_B: 0.2468\n",
            "Epoch 2/60, Batch 6/19, Image: rainy_164.jpg, Loss_G: 4.1059, Loss_D_A: 0.2276, Loss_D_B: 0.2380\n",
            "Epoch 2/60, Batch 7/19, Image: rainy_951.jpg, Loss_G: 4.9501, Loss_D_A: 0.2415, Loss_D_B: 0.2552\n",
            "Epoch 2/60, Batch 8/19, Image: rainy_1092.jpg, Loss_G: 3.8612, Loss_D_A: 0.2248, Loss_D_B: 0.2307\n",
            "Epoch 2/60, Batch 9/19, Image: rainy_931.jpg, Loss_G: 3.4226, Loss_D_A: 0.2351, Loss_D_B: 0.2190\n",
            "Epoch 2/60, Batch 10/19, Image: rainy_187.jpg, Loss_G: 4.1410, Loss_D_A: 0.2179, Loss_D_B: 0.2015\n",
            "Epoch 2/60, Batch 11/19, Image: rainy_942.jpg, Loss_G: 3.4688, Loss_D_A: 0.2490, Loss_D_B: 0.2249\n",
            "Epoch 2/60, Batch 12/19, Image: rainy_181.jpg, Loss_G: 4.7980, Loss_D_A: 0.2994, Loss_D_B: 0.2599\n",
            "Epoch 2/60, Batch 13/19, Image: rainy_215.jpg, Loss_G: 4.0450, Loss_D_A: 0.2669, Loss_D_B: 0.2385\n",
            "Epoch 2/60, Batch 14/19, Image: rainy_414.jpg, Loss_G: 3.7570, Loss_D_A: 0.2546, Loss_D_B: 0.2308\n",
            "Epoch 2/60, Batch 15/19, Image: rainy_549.jpg, Loss_G: 3.4690, Loss_D_A: 0.2803, Loss_D_B: 0.2878\n",
            "Epoch 2/60, Batch 16/19, Image: rainy_706.jpg, Loss_G: 6.1749, Loss_D_A: 0.2254, Loss_D_B: 0.2594\n",
            "Epoch 2/60, Batch 17/19, Image: rainy_1047.jpg, Loss_G: 3.9491, Loss_D_A: 0.2370, Loss_D_B: 0.2709\n",
            "Epoch 2/60, Batch 18/19, Image: rainy_716.jpg, Loss_G: 4.9642, Loss_D_A: 0.2078, Loss_D_B: 0.2211\n",
            "Epoch 3/60, Batch 0/19, Image: rainy_804.jpg, Loss_G: 3.8081, Loss_D_A: 0.2393, Loss_D_B: 0.2389\n",
            "Epoch 3/60, Batch 1/19, Image: rainy_1100.jpg, Loss_G: 3.4564, Loss_D_A: 0.2248, Loss_D_B: 0.2169\n",
            "Epoch 3/60, Batch 2/19, Image: rainy_1141.jpg, Loss_G: 4.7693, Loss_D_A: 0.1983, Loss_D_B: 0.2104\n",
            "Epoch 3/60, Batch 3/19, Image: rainy_574.jpg, Loss_G: 4.0476, Loss_D_A: 0.2199, Loss_D_B: 0.2277\n",
            "Epoch 3/60, Batch 4/19, Image: rainy_23.jpg, Loss_G: 4.0704, Loss_D_A: 0.1830, Loss_D_B: 0.1957\n",
            "Epoch 3/60, Batch 5/19, Image: rainy_1066.jpg, Loss_G: 5.9593, Loss_D_A: 0.2810, Loss_D_B: 0.2580\n",
            "Epoch 3/60, Batch 6/19, Image: rainy_12.jpg, Loss_G: 3.9871, Loss_D_A: 0.2488, Loss_D_B: 0.2473\n",
            "Epoch 3/60, Batch 7/19, Image: rainy_910.jpg, Loss_G: 4.7521, Loss_D_A: 0.2373, Loss_D_B: 0.2297\n",
            "Epoch 3/60, Batch 8/19, Image: rainy_785.jpg, Loss_G: 4.0923, Loss_D_A: 0.2054, Loss_D_B: 0.2176\n",
            "Epoch 3/60, Batch 9/19, Image: rainy_54.jpg, Loss_G: 4.0481, Loss_D_A: 0.2038, Loss_D_B: 0.1850\n",
            "Epoch 3/60, Batch 10/19, Image: rainy_237.jpg, Loss_G: 3.6722, Loss_D_A: 0.2223, Loss_D_B: 0.2194\n",
            "Epoch 3/60, Batch 11/19, Image: rainy_842.jpg, Loss_G: 4.4713, Loss_D_A: 0.2215, Loss_D_B: 0.2144\n",
            "Epoch 3/60, Batch 12/19, Image: rainy_934.jpg, Loss_G: 5.8483, Loss_D_A: 0.2519, Loss_D_B: 0.2277\n",
            "Epoch 3/60, Batch 13/19, Image: rainy_1190.jpg, Loss_G: 3.9097, Loss_D_A: 0.2340, Loss_D_B: 0.2024\n",
            "Epoch 3/60, Batch 14/19, Image: rainy_968.jpg, Loss_G: 3.5731, Loss_D_A: 0.3286, Loss_D_B: 0.2545\n",
            "Epoch 3/60, Batch 15/19, Image: rainy_958.jpg, Loss_G: 3.7945, Loss_D_A: 0.3881, Loss_D_B: 0.2438\n",
            "Epoch 3/60, Batch 16/19, Image: rainy_75.jpg, Loss_G: 4.4179, Loss_D_A: 0.4567, Loss_D_B: 0.2709\n",
            "Epoch 3/60, Batch 17/19, Image: rainy_611.jpg, Loss_G: 5.0794, Loss_D_A: 0.3384, Loss_D_B: 0.2257\n",
            "Epoch 3/60, Batch 18/19, Image: rainy_1128.jpg, Loss_G: 4.6667, Loss_D_A: 0.2294, Loss_D_B: 0.2411\n",
            "Epoch 4/60, Batch 0/19, Image: rainy_658.jpg, Loss_G: 6.0710, Loss_D_A: 0.2868, Loss_D_B: 0.4033\n",
            "Epoch 4/60, Batch 1/19, Image: rainy_145.jpg, Loss_G: 5.6291, Loss_D_A: 0.2436, Loss_D_B: 0.7139\n",
            "Epoch 4/60, Batch 2/19, Image: rainy_644.jpg, Loss_G: 5.4595, Loss_D_A: 0.2965, Loss_D_B: 0.6666\n",
            "Epoch 4/60, Batch 3/19, Image: rainy_369.jpg, Loss_G: 4.1852, Loss_D_A: 0.2441, Loss_D_B: 0.3108\n",
            "Epoch 4/60, Batch 4/19, Image: rainy_414.jpg, Loss_G: 3.6424, Loss_D_A: 0.2441, Loss_D_B: 0.2572\n",
            "Epoch 4/60, Batch 5/19, Image: rainy_80.jpg, Loss_G: 4.1186, Loss_D_A: 0.2474, Loss_D_B: 0.2666\n",
            "Epoch 4/60, Batch 6/19, Image: rainy_743.jpg, Loss_G: 4.3331, Loss_D_A: 0.2477, Loss_D_B: 0.2541\n",
            "Epoch 4/60, Batch 7/19, Image: rainy_78.jpg, Loss_G: 3.7632, Loss_D_A: 0.2047, Loss_D_B: 0.2336\n",
            "Epoch 4/60, Batch 8/19, Image: rainy_1018.jpg, Loss_G: 3.7058, Loss_D_A: 0.2009, Loss_D_B: 0.2342\n",
            "Epoch 4/60, Batch 9/19, Image: rainy_181.jpg, Loss_G: 3.8550, Loss_D_A: 0.2032, Loss_D_B: 0.2445\n",
            "Epoch 4/60, Batch 10/19, Image: rainy_1058.jpg, Loss_G: 4.1096, Loss_D_A: 0.2557, Loss_D_B: 0.3046\n",
            "Epoch 4/60, Batch 11/19, Image: rainy_1145.jpg, Loss_G: 4.0735, Loss_D_A: 0.1839, Loss_D_B: 0.3259\n",
            "Epoch 4/60, Batch 12/19, Image: rainy_1157.jpg, Loss_G: 3.8662, Loss_D_A: 0.1957, Loss_D_B: 0.3834\n",
            "Epoch 4/60, Batch 13/19, Image: rainy_593.jpg, Loss_G: 3.7261, Loss_D_A: 0.1946, Loss_D_B: 0.2899\n",
            "Epoch 4/60, Batch 14/19, Image: rainy_1006.jpg, Loss_G: 5.0493, Loss_D_A: 0.2239, Loss_D_B: 0.2271\n",
            "Epoch 4/60, Batch 15/19, Image: rainy_1047.jpg, Loss_G: 3.7489, Loss_D_A: 0.2356, Loss_D_B: 0.2498\n",
            "Epoch 4/60, Batch 16/19, Image: rainy_374.jpg, Loss_G: 3.4208, Loss_D_A: 0.2427, Loss_D_B: 0.2365\n",
            "Epoch 4/60, Batch 17/19, Image: rainy_317.jpg, Loss_G: 3.6954, Loss_D_A: 0.2768, Loss_D_B: 0.2613\n",
            "Epoch 4/60, Batch 18/19, Image: rainy_633.jpg, Loss_G: 3.7425, Loss_D_A: 0.1899, Loss_D_B: 0.2151\n",
            "Epoch 5/60, Batch 0/19, Image: rainy_567.jpg, Loss_G: 4.8621, Loss_D_A: 0.1633, Loss_D_B: 0.1975\n",
            "Epoch 5/60, Batch 1/19, Image: rainy_122.jpg, Loss_G: 4.9323, Loss_D_A: 0.1999, Loss_D_B: 0.2252\n",
            "Epoch 5/60, Batch 2/19, Image: rainy_1086.jpg, Loss_G: 3.8605, Loss_D_A: 0.1939, Loss_D_B: 0.2112\n",
            "Epoch 5/60, Batch 3/19, Image: rainy_437.jpg, Loss_G: 3.6117, Loss_D_A: 0.1758, Loss_D_B: 0.2095\n",
            "Epoch 5/60, Batch 4/19, Image: rainy_785.jpg, Loss_G: 5.0426, Loss_D_A: 0.2313, Loss_D_B: 0.2316\n",
            "Epoch 5/60, Batch 5/19, Image: rainy_951.jpg, Loss_G: 4.1966, Loss_D_A: 0.1584, Loss_D_B: 0.1931\n",
            "Epoch 5/60, Batch 6/19, Image: rainy_934.jpg, Loss_G: 3.3613, Loss_D_A: 0.1994, Loss_D_B: 0.2049\n",
            "Epoch 5/60, Batch 7/19, Image: rainy_374.jpg, Loss_G: 4.9037, Loss_D_A: 0.1983, Loss_D_B: 0.2125\n",
            "Epoch 5/60, Batch 8/19, Image: rainy_716.jpg, Loss_G: 3.7196, Loss_D_A: 0.3027, Loss_D_B: 0.2223\n",
            "Epoch 5/60, Batch 9/19, Image: rainy_1141.jpg, Loss_G: 4.9552, Loss_D_A: 0.3769, Loss_D_B: 0.2455\n",
            "Epoch 5/60, Batch 10/19, Image: rainy_549.jpg, Loss_G: 3.6230, Loss_D_A: 0.3865, Loss_D_B: 0.2278\n",
            "Epoch 5/60, Batch 11/19, Image: rainy_922.jpg, Loss_G: 3.7455, Loss_D_A: 0.3432, Loss_D_B: 0.2052\n",
            "Epoch 5/60, Batch 12/19, Image: rainy_816.jpg, Loss_G: 3.6340, Loss_D_A: 0.2959, Loss_D_B: 0.2332\n",
            "Epoch 5/60, Batch 13/19, Image: rainy_907.jpg, Loss_G: 4.5043, Loss_D_A: 0.2341, Loss_D_B: 0.2272\n",
            "Epoch 5/60, Batch 14/19, Image: rainy_78.jpg, Loss_G: 5.1839, Loss_D_A: 0.2759, Loss_D_B: 0.2540\n",
            "Epoch 5/60, Batch 15/19, Image: rainy_138.jpg, Loss_G: 4.1555, Loss_D_A: 0.2227, Loss_D_B: 0.2213\n",
            "Epoch 5/60, Batch 16/19, Image: rainy_1196.jpg, Loss_G: 3.6029, Loss_D_A: 0.1504, Loss_D_B: 0.1597\n",
            "Epoch 5/60, Batch 17/19, Image: rainy_54.jpg, Loss_G: 2.7961, Loss_D_A: 0.2534, Loss_D_B: 0.2483\n",
            "Epoch 5/60, Batch 18/19, Image: rainy_834.jpg, Loss_G: 3.9037, Loss_D_A: 0.1931, Loss_D_B: 0.2188\n",
            "Epoch 6/60, Batch 0/19, Image: rainy_271.jpg, Loss_G: 4.2392, Loss_D_A: 0.1849, Loss_D_B: 0.1916\n",
            "Epoch 6/60, Batch 1/19, Image: rainy_638.jpg, Loss_G: 3.6156, Loss_D_A: 0.1816, Loss_D_B: 0.2043\n",
            "Epoch 6/60, Batch 2/19, Image: rainy_802.jpg, Loss_G: 3.3578, Loss_D_A: 0.1968, Loss_D_B: 0.2201\n",
            "Epoch 6/60, Batch 3/19, Image: rainy_968.jpg, Loss_G: 4.5557, Loss_D_A: 0.1677, Loss_D_B: 0.1897\n",
            "Epoch 6/60, Batch 4/19, Image: rainy_837.jpg, Loss_G: 3.4520, Loss_D_A: 0.2347, Loss_D_B: 0.2229\n",
            "Epoch 6/60, Batch 5/19, Image: rainy_277.jpg, Loss_G: 4.4102, Loss_D_A: 0.2009, Loss_D_B: 0.2484\n",
            "Epoch 6/60, Batch 6/19, Image: rainy_706.jpg, Loss_G: 4.0107, Loss_D_A: 0.1727, Loss_D_B: 0.2497\n",
            "Epoch 6/60, Batch 7/19, Image: rainy_1171.jpg, Loss_G: 4.4007, Loss_D_A: 0.1571, Loss_D_B: 0.2352\n",
            "Epoch 6/60, Batch 8/19, Image: rainy_525.jpg, Loss_G: 3.6380, Loss_D_A: 0.3262, Loss_D_B: 0.3184\n",
            "Epoch 6/60, Batch 9/19, Image: rainy_1118.jpg, Loss_G: 6.2957, Loss_D_A: 0.3710, Loss_D_B: 0.2798\n",
            "Epoch 6/60, Batch 10/19, Image: rainy_369.jpg, Loss_G: 4.2437, Loss_D_A: 0.3091, Loss_D_B: 0.2426\n",
            "Epoch 6/60, Batch 11/19, Image: rainy_237.jpg, Loss_G: 3.4460, Loss_D_A: 0.2587, Loss_D_B: 0.2351\n",
            "Epoch 6/60, Batch 12/19, Image: rainy_1049.jpg, Loss_G: 3.9972, Loss_D_A: 0.2164, Loss_D_B: 0.2079\n",
            "Epoch 6/60, Batch 13/19, Image: rainy_148.jpg, Loss_G: 4.4803, Loss_D_A: 0.2200, Loss_D_B: 0.1917\n",
            "Epoch 6/60, Batch 14/19, Image: rainy_437.jpg, Loss_G: 3.2396, Loss_D_A: 0.2262, Loss_D_B: 0.2086\n",
            "Epoch 6/60, Batch 15/19, Image: rainy_570.jpg, Loss_G: 3.2825, Loss_D_A: 0.2347, Loss_D_B: 0.2345\n",
            "Epoch 6/60, Batch 16/19, Image: rainy_482.jpg, Loss_G: 3.4378, Loss_D_A: 0.1687, Loss_D_B: 0.1731\n",
            "Epoch 6/60, Batch 17/19, Image: rainy_710.jpg, Loss_G: 4.7142, Loss_D_A: 0.1529, Loss_D_B: 0.1660\n",
            "Epoch 6/60, Batch 18/19, Image: rainy_332.jpg, Loss_G: 4.0780, Loss_D_A: 0.1742, Loss_D_B: 0.1982\n",
            "Epoch 7/60, Batch 0/19, Image: rainy_567.jpg, Loss_G: 3.2995, Loss_D_A: 0.2547, Loss_D_B: 0.2292\n",
            "Epoch 7/60, Batch 1/19, Image: rainy_148.jpg, Loss_G: 3.3376, Loss_D_A: 0.2479, Loss_D_B: 0.2454\n",
            "Epoch 7/60, Batch 2/19, Image: rainy_414.jpg, Loss_G: 4.3133, Loss_D_A: 0.2202, Loss_D_B: 0.2246\n",
            "Epoch 7/60, Batch 3/19, Image: rainy_785.jpg, Loss_G: 3.7698, Loss_D_A: 0.1674, Loss_D_B: 0.1739\n",
            "Epoch 7/60, Batch 4/19, Image: rainy_69.jpg, Loss_G: 4.6438, Loss_D_A: 0.2939, Loss_D_B: 0.2803\n",
            "Epoch 7/60, Batch 5/19, Image: rainy_271.jpg, Loss_G: 3.1582, Loss_D_A: 0.1898, Loss_D_B: 0.1817\n",
            "Epoch 7/60, Batch 6/19, Image: rainy_332.jpg, Loss_G: 3.9975, Loss_D_A: 0.1807, Loss_D_B: 0.2058\n",
            "Epoch 7/60, Batch 7/19, Image: rainy_1117.jpg, Loss_G: 3.4017, Loss_D_A: 0.2550, Loss_D_B: 0.2165\n",
            "Epoch 7/60, Batch 8/19, Image: rainy_101.jpg, Loss_G: 3.3901, Loss_D_A: 0.2708, Loss_D_B: 0.2285\n",
            "Epoch 7/60, Batch 9/19, Image: rainy_463.jpg, Loss_G: 3.5402, Loss_D_A: 0.2747, Loss_D_B: 0.2575\n",
            "Epoch 7/60, Batch 10/19, Image: rainy_145.jpg, Loss_G: 4.8369, Loss_D_A: 0.2516, Loss_D_B: 0.2343\n",
            "Epoch 7/60, Batch 11/19, Image: rainy_1092.jpg, Loss_G: 3.8254, Loss_D_A: 0.1898, Loss_D_B: 0.2261\n",
            "Epoch 7/60, Batch 12/19, Image: rainy_744.jpg, Loss_G: 3.3700, Loss_D_A: 0.2022, Loss_D_B: 0.2385\n",
            "Epoch 7/60, Batch 13/19, Image: rainy_708.jpg, Loss_G: 3.0013, Loss_D_A: 0.2383, Loss_D_B: 0.2430\n",
            "Epoch 7/60, Batch 14/19, Image: rainy_208.jpg, Loss_G: 3.3590, Loss_D_A: 0.2781, Loss_D_B: 0.2354\n",
            "Epoch 7/60, Batch 15/19, Image: rainy_1118.jpg, Loss_G: 3.7835, Loss_D_A: 0.1821, Loss_D_B: 0.1779\n",
            "Epoch 7/60, Batch 16/19, Image: rainy_654.jpg, Loss_G: 3.4702, Loss_D_A: 0.2387, Loss_D_B: 0.2406\n",
            "Epoch 7/60, Batch 17/19, Image: rainy_1190.jpg, Loss_G: 3.4016, Loss_D_A: 0.1710, Loss_D_B: 0.1629\n",
            "Epoch 7/60, Batch 18/19, Image: rainy_378.jpg, Loss_G: 3.7655, Loss_D_A: 0.1462, Loss_D_B: 0.1756\n",
            "Epoch 8/60, Batch 0/19, Image: rainy_75.jpg, Loss_G: 3.5722, Loss_D_A: 0.1328, Loss_D_B: 0.1501\n",
            "Epoch 8/60, Batch 1/19, Image: rainy_740.jpg, Loss_G: 3.5561, Loss_D_A: 0.2251, Loss_D_B: 0.2257\n",
            "Epoch 8/60, Batch 2/19, Image: rainy_654.jpg, Loss_G: 3.6144, Loss_D_A: 0.2801, Loss_D_B: 0.2902\n",
            "Epoch 8/60, Batch 3/19, Image: rainy_1128.jpg, Loss_G: 3.7710, Loss_D_A: 0.2549, Loss_D_B: 0.3418\n",
            "Epoch 8/60, Batch 4/19, Image: rainy_53.jpg, Loss_G: 4.3751, Loss_D_A: 0.2000, Loss_D_B: 0.3075\n",
            "Epoch 8/60, Batch 5/19, Image: rainy_319.jpg, Loss_G: 5.0666, Loss_D_A: 0.2755, Loss_D_B: 0.3859\n",
            "Epoch 8/60, Batch 6/19, Image: rainy_968.jpg, Loss_G: 4.3032, Loss_D_A: 0.2559, Loss_D_B: 0.2755\n",
            "Epoch 8/60, Batch 7/19, Image: rainy_930.jpg, Loss_G: 3.9037, Loss_D_A: 0.2089, Loss_D_B: 0.2064\n",
            "Epoch 8/60, Batch 8/19, Image: rainy_671.jpg, Loss_G: 4.4811, Loss_D_A: 0.1503, Loss_D_B: 0.1689\n",
            "Epoch 8/60, Batch 9/19, Image: rainy_694.jpg, Loss_G: 3.3846, Loss_D_A: 0.2258, Loss_D_B: 0.2280\n",
            "Epoch 8/60, Batch 10/19, Image: rainy_804.jpg, Loss_G: 4.7310, Loss_D_A: 0.2158, Loss_D_B: 0.1963\n",
            "Epoch 8/60, Batch 11/19, Image: rainy_657.jpg, Loss_G: 3.4267, Loss_D_A: 0.1711, Loss_D_B: 0.1802\n",
            "Epoch 8/60, Batch 12/19, Image: rainy_1092.jpg, Loss_G: 3.7794, Loss_D_A: 0.2377, Loss_D_B: 0.2065\n",
            "Epoch 8/60, Batch 13/19, Image: rainy_317.jpg, Loss_G: 3.9821, Loss_D_A: 0.1935, Loss_D_B: 0.1849\n",
            "Epoch 8/60, Batch 14/19, Image: rainy_215.jpg, Loss_G: 3.2349, Loss_D_A: 0.2769, Loss_D_B: 0.2572\n",
            "Epoch 8/60, Batch 15/19, Image: rainy_138.jpg, Loss_G: 3.3545, Loss_D_A: 0.1973, Loss_D_B: 0.1966\n",
            "Epoch 8/60, Batch 16/19, Image: rainy_463.jpg, Loss_G: 3.8901, Loss_D_A: 0.1989, Loss_D_B: 0.2109\n",
            "Epoch 8/60, Batch 17/19, Image: rainy_1196.jpg, Loss_G: 3.2218, Loss_D_A: 0.2115, Loss_D_B: 0.2065\n",
            "Epoch 8/60, Batch 18/19, Image: rainy_736.jpg, Loss_G: 5.2374, Loss_D_A: 0.1680, Loss_D_B: 0.1850\n",
            "Epoch 9/60, Batch 0/19, Image: rainy_549.jpg, Loss_G: 3.2591, Loss_D_A: 0.2973, Loss_D_B: 0.2564\n",
            "Epoch 9/60, Batch 1/19, Image: rainy_1058.jpg, Loss_G: 3.3973, Loss_D_A: 0.2275, Loss_D_B: 0.2128\n",
            "Epoch 9/60, Batch 2/19, Image: rainy_708.jpg, Loss_G: 5.9723, Loss_D_A: 0.2691, Loss_D_B: 0.2416\n",
            "Epoch 9/60, Batch 3/19, Image: rainy_157.jpg, Loss_G: 4.4778, Loss_D_A: 0.1606, Loss_D_B: 0.1345\n",
            "Epoch 9/60, Batch 4/19, Image: rainy_1110.jpg, Loss_G: 4.4876, Loss_D_A: 0.2520, Loss_D_B: 0.1818\n",
            "Epoch 9/60, Batch 5/19, Image: rainy_81.jpg, Loss_G: 4.6887, Loss_D_A: 0.2560, Loss_D_B: 0.1584\n",
            "Epoch 9/60, Batch 6/19, Image: rainy_931.jpg, Loss_G: 3.5129, Loss_D_A: 0.2762, Loss_D_B: 0.1975\n",
            "Epoch 9/60, Batch 7/19, Image: rainy_356.jpg, Loss_G: 3.3988, Loss_D_A: 0.2526, Loss_D_B: 0.2240\n",
            "Epoch 9/60, Batch 8/19, Image: rainy_378.jpg, Loss_G: 3.8146, Loss_D_A: 0.2295, Loss_D_B: 0.2143\n",
            "Epoch 9/60, Batch 9/19, Image: rainy_680.jpg, Loss_G: 3.6960, Loss_D_A: 0.2911, Loss_D_B: 0.2669\n",
            "Epoch 9/60, Batch 10/19, Image: rainy_804.jpg, Loss_G: 3.4200, Loss_D_A: 0.2041, Loss_D_B: 0.2030\n",
            "Epoch 9/60, Batch 11/19, Image: rainy_694.jpg, Loss_G: 3.1889, Loss_D_A: 0.2950, Loss_D_B: 0.3248\n",
            "Epoch 9/60, Batch 12/19, Image: rainy_839.jpg, Loss_G: 3.5971, Loss_D_A: 0.1908, Loss_D_B: 0.3190\n",
            "Epoch 9/60, Batch 13/19, Image: rainy_934.jpg, Loss_G: 3.6903, Loss_D_A: 0.2104, Loss_D_B: 0.2940\n",
            "Epoch 9/60, Batch 14/19, Image: rainy_332.jpg, Loss_G: 3.5363, Loss_D_A: 0.2091, Loss_D_B: 0.2656\n",
            "Epoch 9/60, Batch 15/19, Image: rainy_65.jpg, Loss_G: 3.3516, Loss_D_A: 0.1965, Loss_D_B: 0.2740\n",
            "Epoch 9/60, Batch 16/19, Image: rainy_1183.jpg, Loss_G: 3.6668, Loss_D_A: 0.1501, Loss_D_B: 0.1954\n",
            "Epoch 9/60, Batch 17/19, Image: rainy_567.jpg, Loss_G: 3.5019, Loss_D_A: 0.2846, Loss_D_B: 0.2359\n",
            "Epoch 9/60, Batch 18/19, Image: rainy_633.jpg, Loss_G: 3.7394, Loss_D_A: 0.3074, Loss_D_B: 0.2211\n",
            "Epoch 10/60, Batch 0/19, Image: rainy_54.jpg, Loss_G: 3.3858, Loss_D_A: 0.2312, Loss_D_B: 0.2287\n",
            "Epoch 10/60, Batch 1/19, Image: rainy_12.jpg, Loss_G: 3.8629, Loss_D_A: 0.1362, Loss_D_B: 0.1879\n",
            "Epoch 10/60, Batch 2/19, Image: rainy_804.jpg, Loss_G: 3.7986, Loss_D_A: 0.1845, Loss_D_B: 0.1900\n",
            "Epoch 10/60, Batch 3/19, Image: rainy_764.jpg, Loss_G: 3.3725, Loss_D_A: 0.2522, Loss_D_B: 0.2334\n",
            "Epoch 10/60, Batch 4/19, Image: rainy_1052.jpg, Loss_G: 3.2758, Loss_D_A: 0.2165, Loss_D_B: 0.2030\n",
            "Epoch 10/60, Batch 5/19, Image: rainy_69.jpg, Loss_G: 3.5619, Loss_D_A: 0.1772, Loss_D_B: 0.1723\n",
            "Epoch 10/60, Batch 6/19, Image: rainy_1062.jpg, Loss_G: 3.1272, Loss_D_A: 0.1957, Loss_D_B: 0.1958\n",
            "Epoch 10/60, Batch 7/19, Image: rainy_83.jpg, Loss_G: 4.2094, Loss_D_A: 0.2018, Loss_D_B: 0.2030\n",
            "Epoch 10/60, Batch 8/19, Image: rainy_1092.jpg, Loss_G: 3.6413, Loss_D_A: 0.3352, Loss_D_B: 0.2764\n",
            "Epoch 10/60, Batch 9/19, Image: rainy_138.jpg, Loss_G: 3.8798, Loss_D_A: 0.2736, Loss_D_B: 0.2094\n",
            "Epoch 10/60, Batch 10/19, Image: rainy_235.jpg, Loss_G: 3.3243, Loss_D_A: 0.3142, Loss_D_B: 0.2537\n",
            "Epoch 10/60, Batch 11/19, Image: rainy_1117.jpg, Loss_G: 3.5268, Loss_D_A: 0.1601, Loss_D_B: 0.1501\n",
            "Epoch 10/60, Batch 12/19, Image: rainy_1145.jpg, Loss_G: 4.3009, Loss_D_A: 0.2530, Loss_D_B: 0.2030\n",
            "Epoch 10/60, Batch 13/19, Image: rainy_593.jpg, Loss_G: 4.6484, Loss_D_A: 0.3405, Loss_D_B: 0.2809\n",
            "Epoch 10/60, Batch 14/19, Image: rainy_638.jpg, Loss_G: 4.8179, Loss_D_A: 0.3058, Loss_D_B: 0.2605\n",
            "Epoch 10/60, Batch 15/19, Image: rainy_525.jpg, Loss_G: 3.4203, Loss_D_A: 0.3628, Loss_D_B: 0.3090\n",
            "Epoch 10/60, Batch 16/19, Image: rainy_931.jpg, Loss_G: 4.0933, Loss_D_A: 0.3088, Loss_D_B: 0.3162\n",
            "Epoch 10/60, Batch 17/19, Image: rainy_1066.jpg, Loss_G: 3.5792, Loss_D_A: 0.2519, Loss_D_B: 0.2815\n",
            "Epoch 10/60, Batch 18/19, Image: rainy_910.jpg, Loss_G: 3.5750, Loss_D_A: 0.1683, Loss_D_B: 0.1693\n",
            "Epoch 11/60, Batch 0/19, Image: rainy_837.jpg, Loss_G: 3.2907, Loss_D_A: 0.2010, Loss_D_B: 0.2047\n",
            "Epoch 11/60, Batch 1/19, Image: rainy_69.jpg, Loss_G: 3.4385, Loss_D_A: 0.1844, Loss_D_B: 0.2139\n",
            "Epoch 11/60, Batch 2/19, Image: rainy_119.jpg, Loss_G: 2.9718, Loss_D_A: 0.2298, Loss_D_B: 0.2311\n",
            "Epoch 11/60, Batch 3/19, Image: rainy_644.jpg, Loss_G: 3.5933, Loss_D_A: 0.1684, Loss_D_B: 0.1737\n",
            "Epoch 11/60, Batch 4/19, Image: rainy_1183.jpg, Loss_G: 3.6208, Loss_D_A: 0.1602, Loss_D_B: 0.1641\n",
            "Epoch 11/60, Batch 5/19, Image: rainy_589.jpg, Loss_G: 3.1738, Loss_D_A: 0.2603, Loss_D_B: 0.2417\n",
            "Epoch 11/60, Batch 6/19, Image: rainy_404.jpg, Loss_G: 3.1371, Loss_D_A: 0.2561, Loss_D_B: 0.2576\n",
            "Epoch 11/60, Batch 7/19, Image: rainy_145.jpg, Loss_G: 3.4938, Loss_D_A: 0.1661, Loss_D_B: 0.1947\n",
            "Epoch 11/60, Batch 8/19, Image: rainy_816.jpg, Loss_G: 3.1878, Loss_D_A: 0.2521, Loss_D_B: 0.2533\n",
            "Epoch 11/60, Batch 9/19, Image: rainy_744.jpg, Loss_G: 2.9028, Loss_D_A: 0.2055, Loss_D_B: 0.1843\n",
            "Epoch 11/60, Batch 10/19, Image: rainy_716.jpg, Loss_G: 3.5970, Loss_D_A: 0.1603, Loss_D_B: 0.1271\n",
            "Epoch 11/60, Batch 11/19, Image: rainy_74.jpg, Loss_G: 4.2135, Loss_D_A: 0.1684, Loss_D_B: 0.1542\n",
            "Epoch 11/60, Batch 12/19, Image: rainy_694.jpg, Loss_G: 3.1296, Loss_D_A: 0.2189, Loss_D_B: 0.1881\n",
            "Epoch 11/60, Batch 13/19, Image: rainy_680.jpg, Loss_G: 3.3357, Loss_D_A: 0.2374, Loss_D_B: 0.2299\n",
            "Epoch 11/60, Batch 14/19, Image: rainy_958.jpg, Loss_G: 3.4856, Loss_D_A: 0.2593, Loss_D_B: 0.2610\n",
            "Epoch 11/60, Batch 15/19, Image: rainy_215.jpg, Loss_G: 3.4638, Loss_D_A: 0.2759, Loss_D_B: 0.2562\n",
            "Epoch 11/60, Batch 16/19, Image: rainy_65.jpg, Loss_G: 3.3000, Loss_D_A: 0.1889, Loss_D_B: 0.1993\n",
            "Epoch 11/60, Batch 17/19, Image: rainy_756.jpg, Loss_G: 3.8962, Loss_D_A: 0.1936, Loss_D_B: 0.2452\n",
            "Epoch 11/60, Batch 18/19, Image: rainy_785.jpg, Loss_G: 5.7729, Loss_D_A: 0.2326, Loss_D_B: 0.3749\n",
            "Epoch 12/60, Batch 0/19, Image: rainy_74.jpg, Loss_G: 3.5452, Loss_D_A: 0.2688, Loss_D_B: 0.4322\n",
            "Epoch 12/60, Batch 1/19, Image: rainy_764.jpg, Loss_G: 3.9840, Loss_D_A: 0.2803, Loss_D_B: 0.4198\n",
            "Epoch 12/60, Batch 2/19, Image: rainy_12.jpg, Loss_G: 4.2358, Loss_D_A: 0.2879, Loss_D_B: 0.5754\n",
            "Epoch 12/60, Batch 3/19, Image: rainy_1054.jpg, Loss_G: 5.5888, Loss_D_A: 0.3117, Loss_D_B: 0.9510\n",
            "Epoch 12/60, Batch 4/19, Image: rainy_1189.jpg, Loss_G: 3.5387, Loss_D_A: 0.3352, Loss_D_B: 0.6733\n",
            "Epoch 12/60, Batch 5/19, Image: rainy_842.jpg, Loss_G: 3.8644, Loss_D_A: 0.2446, Loss_D_B: 0.2658\n",
            "Epoch 12/60, Batch 6/19, Image: rainy_53.jpg, Loss_G: 4.4463, Loss_D_A: 0.2117, Loss_D_B: 0.3647\n",
            "Epoch 12/60, Batch 7/19, Image: rainy_78.jpg, Loss_G: 5.2076, Loss_D_A: 0.2139, Loss_D_B: 0.3815\n",
            "Epoch 12/60, Batch 8/19, Image: rainy_930.jpg, Loss_G: 3.5463, Loss_D_A: 0.1823, Loss_D_B: 0.3606\n",
            "Epoch 12/60, Batch 9/19, Image: rainy_680.jpg, Loss_G: 3.8256, Loss_D_A: 0.3001, Loss_D_B: 0.3803\n",
            "Epoch 12/60, Batch 10/19, Image: rainy_743.jpg, Loss_G: 3.5189, Loss_D_A: 0.2899, Loss_D_B: 0.2744\n",
            "Epoch 12/60, Batch 11/19, Image: rainy_1006.jpg, Loss_G: 4.2833, Loss_D_A: 0.2827, Loss_D_B: 0.2276\n",
            "Epoch 12/60, Batch 12/19, Image: rainy_277.jpg, Loss_G: 3.8712, Loss_D_A: 0.2448, Loss_D_B: 0.2307\n",
            "Epoch 12/60, Batch 13/19, Image: rainy_574.jpg, Loss_G: 3.3985, Loss_D_A: 0.2370, Loss_D_B: 0.2472\n",
            "Epoch 12/60, Batch 14/19, Image: rainy_907.jpg, Loss_G: 3.1673, Loss_D_A: 0.2269, Loss_D_B: 0.2339\n",
            "Epoch 12/60, Batch 15/19, Image: rainy_92.jpg, Loss_G: 3.5136, Loss_D_A: 0.1681, Loss_D_B: 0.1899\n",
            "Epoch 12/60, Batch 16/19, Image: rainy_23.jpg, Loss_G: 3.3074, Loss_D_A: 0.1824, Loss_D_B: 0.1993\n",
            "Epoch 12/60, Batch 17/19, Image: rainy_1052.jpg, Loss_G: 3.0169, Loss_D_A: 0.2036, Loss_D_B: 0.2026\n",
            "Epoch 12/60, Batch 18/19, Image: rainy_804.jpg, Loss_G: 3.3047, Loss_D_A: 0.2634, Loss_D_B: 0.2618\n",
            "Epoch 13/60, Batch 0/19, Image: rainy_657.jpg, Loss_G: 3.3491, Loss_D_A: 0.1390, Loss_D_B: 0.1682\n",
            "Epoch 13/60, Batch 1/19, Image: rainy_1157.jpg, Loss_G: 3.9452, Loss_D_A: 0.1721, Loss_D_B: 0.2104\n",
            "Epoch 13/60, Batch 2/19, Image: rainy_1018.jpg, Loss_G: 3.6449, Loss_D_A: 0.2218, Loss_D_B: 0.2309\n",
            "Epoch 13/60, Batch 3/19, Image: rainy_470.jpg, Loss_G: 3.0564, Loss_D_A: 0.2902, Loss_D_B: 0.2540\n",
            "Epoch 13/60, Batch 4/19, Image: rainy_75.jpg, Loss_G: 3.9410, Loss_D_A: 0.2093, Loss_D_B: 0.1925\n",
            "Epoch 13/60, Batch 5/19, Image: rainy_764.jpg, Loss_G: 3.5604, Loss_D_A: 0.3081, Loss_D_B: 0.2592\n",
            "Epoch 13/60, Batch 6/19, Image: rainy_1086.jpg, Loss_G: 3.3722, Loss_D_A: 0.2611, Loss_D_B: 0.2251\n",
            "Epoch 13/60, Batch 7/19, Image: rainy_81.jpg, Loss_G: 3.8934, Loss_D_A: 0.1908, Loss_D_B: 0.1788\n",
            "Epoch 13/60, Batch 8/19, Image: rainy_157.jpg, Loss_G: 3.4958, Loss_D_A: 0.2114, Loss_D_B: 0.1935\n",
            "Epoch 13/60, Batch 9/19, Image: rainy_1052.jpg, Loss_G: 2.9818, Loss_D_A: 0.2510, Loss_D_B: 0.2354\n",
            "Epoch 13/60, Batch 10/19, Image: rainy_463.jpg, Loss_G: 3.0775, Loss_D_A: 0.2130, Loss_D_B: 0.1893\n",
            "Epoch 13/60, Batch 11/19, Image: rainy_934.jpg, Loss_G: 5.0130, Loss_D_A: 0.1881, Loss_D_B: 0.1753\n",
            "Epoch 13/60, Batch 12/19, Image: rainy_1171.jpg, Loss_G: 3.3575, Loss_D_A: 0.1623, Loss_D_B: 0.1508\n",
            "Epoch 13/60, Batch 13/19, Image: rainy_1059.jpg, Loss_G: 3.3749, Loss_D_A: 0.2079, Loss_D_B: 0.1935\n",
            "Epoch 13/60, Batch 14/19, Image: rainy_65.jpg, Loss_G: 4.1441, Loss_D_A: 0.2168, Loss_D_B: 0.2023\n",
            "Epoch 13/60, Batch 15/19, Image: rainy_942.jpg, Loss_G: 4.4297, Loss_D_A: 0.2311, Loss_D_B: 0.2173\n",
            "Epoch 13/60, Batch 16/19, Image: rainy_593.jpg, Loss_G: 2.9445, Loss_D_A: 0.2760, Loss_D_B: 0.2540\n",
            "Epoch 13/60, Batch 17/19, Image: rainy_74.jpg, Loss_G: 3.5118, Loss_D_A: 0.1889, Loss_D_B: 0.1822\n",
            "Epoch 13/60, Batch 18/19, Image: rainy_78.jpg, Loss_G: 4.4717, Loss_D_A: 0.2992, Loss_D_B: 0.2751\n",
            "Epoch 14/60, Batch 0/19, Image: rainy_1117.jpg, Loss_G: 4.9382, Loss_D_A: 0.2094, Loss_D_B: 0.1838\n",
            "Epoch 14/60, Batch 1/19, Image: rainy_589.jpg, Loss_G: 3.9475, Loss_D_A: 0.2543, Loss_D_B: 0.2110\n",
            "Epoch 14/60, Batch 2/19, Image: rainy_837.jpg, Loss_G: 3.6819, Loss_D_A: 0.2391, Loss_D_B: 0.2200\n",
            "Epoch 14/60, Batch 3/19, Image: rainy_744.jpg, Loss_G: 3.2914, Loss_D_A: 0.1991, Loss_D_B: 0.1789\n",
            "Epoch 14/60, Batch 4/19, Image: rainy_743.jpg, Loss_G: 3.2993, Loss_D_A: 0.2356, Loss_D_B: 0.2094\n",
            "Epoch 14/60, Batch 5/19, Image: rainy_785.jpg, Loss_G: 3.1817, Loss_D_A: 0.2417, Loss_D_B: 0.2541\n",
            "Epoch 14/60, Batch 6/19, Image: rainy_1118.jpg, Loss_G: 3.7290, Loss_D_A: 0.2545, Loss_D_B: 0.2745\n",
            "Epoch 14/60, Batch 7/19, Image: rainy_235.jpg, Loss_G: 4.9815, Loss_D_A: 0.1915, Loss_D_B: 0.2964\n",
            "Epoch 14/60, Batch 8/19, Image: rainy_741.jpg, Loss_G: 4.0275, Loss_D_A: 0.2728, Loss_D_B: 0.4204\n",
            "Epoch 14/60, Batch 9/19, Image: rainy_756.jpg, Loss_G: 3.6486, Loss_D_A: 0.3125, Loss_D_B: 0.4331\n",
            "Epoch 14/60, Batch 10/19, Image: rainy_332.jpg, Loss_G: 3.9117, Loss_D_A: 0.2913, Loss_D_B: 0.3038\n",
            "Epoch 14/60, Batch 11/19, Image: rainy_262.jpg, Loss_G: 4.0938, Loss_D_A: 0.2140, Loss_D_B: 0.1932\n",
            "Epoch 14/60, Batch 12/19, Image: rainy_1196.jpg, Loss_G: 4.6160, Loss_D_A: 0.2334, Loss_D_B: 0.2123\n",
            "Epoch 14/60, Batch 13/19, Image: rainy_277.jpg, Loss_G: 3.9092, Loss_D_A: 0.2306, Loss_D_B: 0.1821\n",
            "Epoch 14/60, Batch 14/19, Image: rainy_520.jpg, Loss_G: 3.5101, Loss_D_A: 0.1961, Loss_D_B: 0.1861\n",
            "Epoch 14/60, Batch 15/19, Image: rainy_482.jpg, Loss_G: 3.3463, Loss_D_A: 0.2571, Loss_D_B: 0.2383\n",
            "Epoch 14/60, Batch 16/19, Image: rainy_635.jpg, Loss_G: 3.6379, Loss_D_A: 0.2376, Loss_D_B: 0.2163\n",
            "Epoch 14/60, Batch 17/19, Image: rainy_374.jpg, Loss_G: 3.0606, Loss_D_A: 0.2371, Loss_D_B: 0.2069\n",
            "Epoch 14/60, Batch 18/19, Image: rainy_574.jpg, Loss_G: 3.0980, Loss_D_A: 0.3856, Loss_D_B: 0.3106\n",
            "Epoch 15/60, Batch 0/19, Image: rainy_716.jpg, Loss_G: 3.3044, Loss_D_A: 0.2318, Loss_D_B: 0.2348\n",
            "Epoch 15/60, Batch 1/19, Image: rainy_1006.jpg, Loss_G: 3.4588, Loss_D_A: 0.2120, Loss_D_B: 0.2128\n",
            "Epoch 15/60, Batch 2/19, Image: rainy_1100.jpg, Loss_G: 3.8712, Loss_D_A: 0.1928, Loss_D_B: 0.2127\n",
            "Epoch 15/60, Batch 3/19, Image: rainy_1189.jpg, Loss_G: 5.6612, Loss_D_A: 0.2288, Loss_D_B: 0.2002\n",
            "Epoch 15/60, Batch 4/19, Image: rainy_200.jpg, Loss_G: 4.2322, Loss_D_A: 0.2627, Loss_D_B: 0.2427\n",
            "Epoch 15/60, Batch 5/19, Image: rainy_785.jpg, Loss_G: 3.7229, Loss_D_A: 0.1942, Loss_D_B: 0.1926\n",
            "Epoch 15/60, Batch 6/19, Image: rainy_654.jpg, Loss_G: 4.1910, Loss_D_A: 0.1991, Loss_D_B: 0.2207\n",
            "Epoch 15/60, Batch 7/19, Image: rainy_635.jpg, Loss_G: 6.2525, Loss_D_A: 0.2470, Loss_D_B: 0.2382\n",
            "Epoch 15/60, Batch 8/19, Image: rainy_340.jpg, Loss_G: 3.8649, Loss_D_A: 0.2186, Loss_D_B: 0.2118\n",
            "Epoch 15/60, Batch 9/19, Image: rainy_942.jpg, Loss_G: 4.6867, Loss_D_A: 0.2119, Loss_D_B: 0.1958\n",
            "Epoch 15/60, Batch 10/19, Image: rainy_74.jpg, Loss_G: 4.8253, Loss_D_A: 0.2092, Loss_D_B: 0.1737\n",
            "Epoch 15/60, Batch 11/19, Image: rainy_356.jpg, Loss_G: 3.8750, Loss_D_A: 0.1865, Loss_D_B: 0.1522\n",
            "Epoch 15/60, Batch 12/19, Image: rainy_1052.jpg, Loss_G: 3.6092, Loss_D_A: 0.2457, Loss_D_B: 0.2026\n",
            "Epoch 15/60, Batch 13/19, Image: rainy_837.jpg, Loss_G: 3.5618, Loss_D_A: 0.2357, Loss_D_B: 0.2134\n",
            "Epoch 15/60, Batch 14/19, Image: rainy_694.jpg, Loss_G: 4.0784, Loss_D_A: 0.1368, Loss_D_B: 0.1548\n",
            "Epoch 15/60, Batch 15/19, Image: rainy_97.jpg, Loss_G: 3.1291, Loss_D_A: 0.2194, Loss_D_B: 0.2384\n",
            "Epoch 15/60, Batch 16/19, Image: rainy_1128.jpg, Loss_G: 3.2139, Loss_D_A: 0.1852, Loss_D_B: 0.1876\n",
            "Epoch 15/60, Batch 17/19, Image: rainy_710.jpg, Loss_G: 5.1421, Loss_D_A: 0.2797, Loss_D_B: 0.2274\n",
            "Epoch 15/60, Batch 18/19, Image: rainy_277.jpg, Loss_G: 3.4652, Loss_D_A: 0.2390, Loss_D_B: 0.1903\n",
            "Epoch 16/60, Batch 0/19, Image: rainy_1159.jpg, Loss_G: 3.4619, Loss_D_A: 0.3255, Loss_D_B: 0.2462\n",
            "Epoch 16/60, Batch 1/19, Image: rainy_187.jpg, Loss_G: 5.1107, Loss_D_A: 0.2272, Loss_D_B: 0.1800\n",
            "Epoch 16/60, Batch 2/19, Image: rainy_549.jpg, Loss_G: 3.7293, Loss_D_A: 0.2570, Loss_D_B: 0.2193\n",
            "Epoch 16/60, Batch 3/19, Image: rainy_1049.jpg, Loss_G: 3.6458, Loss_D_A: 0.2083, Loss_D_B: 0.2073\n",
            "Epoch 16/60, Batch 4/19, Image: rainy_741.jpg, Loss_G: 2.9746, Loss_D_A: 0.2519, Loss_D_B: 0.2515\n",
            "Epoch 16/60, Batch 5/19, Image: rainy_942.jpg, Loss_G: 3.9289, Loss_D_A: 0.2481, Loss_D_B: 0.2770\n",
            "Epoch 16/60, Batch 6/19, Image: rainy_1196.jpg, Loss_G: 5.5105, Loss_D_A: 0.2536, Loss_D_B: 0.3087\n",
            "Epoch 16/60, Batch 7/19, Image: rainy_376.jpg, Loss_G: 3.0493, Loss_D_A: 0.3454, Loss_D_B: 0.2699\n",
            "Epoch 16/60, Batch 8/19, Image: rainy_654.jpg, Loss_G: 3.3200, Loss_D_A: 0.2262, Loss_D_B: 0.2058\n",
            "Epoch 16/60, Batch 9/19, Image: rainy_744.jpg, Loss_G: 3.0860, Loss_D_A: 0.2072, Loss_D_B: 0.1674\n",
            "Epoch 16/60, Batch 10/19, Image: rainy_574.jpg, Loss_G: 3.0972, Loss_D_A: 0.2647, Loss_D_B: 0.2194\n",
            "Epoch 16/60, Batch 11/19, Image: rainy_1066.jpg, Loss_G: 4.0110, Loss_D_A: 0.2042, Loss_D_B: 0.1710\n",
            "Epoch 16/60, Batch 12/19, Image: rainy_910.jpg, Loss_G: 3.6542, Loss_D_A: 0.2159, Loss_D_B: 0.2144\n",
            "Epoch 16/60, Batch 13/19, Image: rainy_53.jpg, Loss_G: 3.6447, Loss_D_A: 0.1798, Loss_D_B: 0.1908\n",
            "Epoch 16/60, Batch 14/19, Image: rainy_1128.jpg, Loss_G: 4.1183, Loss_D_A: 0.1665, Loss_D_B: 0.2039\n",
            "Epoch 16/60, Batch 15/19, Image: rainy_75.jpg, Loss_G: 3.4481, Loss_D_A: 0.2116, Loss_D_B: 0.2300\n",
            "Epoch 16/60, Batch 16/19, Image: rainy_704.jpg, Loss_G: 2.7924, Loss_D_A: 0.2005, Loss_D_B: 0.1972\n",
            "Epoch 16/60, Batch 17/19, Image: rainy_237.jpg, Loss_G: 3.7656, Loss_D_A: 0.2116, Loss_D_B: 0.2307\n",
            "Epoch 16/60, Batch 18/19, Image: rainy_145.jpg, Loss_G: 3.6503, Loss_D_A: 0.1768, Loss_D_B: 0.1705\n",
            "Epoch 17/60, Batch 0/19, Image: rainy_868.jpg, Loss_G: 4.3552, Loss_D_A: 0.2151, Loss_D_B: 0.1915\n",
            "Epoch 17/60, Batch 1/19, Image: rainy_319.jpg, Loss_G: 3.3506, Loss_D_A: 0.1976, Loss_D_B: 0.1738\n",
            "Epoch 17/60, Batch 2/19, Image: rainy_1190.jpg, Loss_G: 5.1307, Loss_D_A: 0.2033, Loss_D_B: 0.2085\n",
            "Epoch 17/60, Batch 3/19, Image: rainy_164.jpg, Loss_G: 3.4354, Loss_D_A: 0.2124, Loss_D_B: 0.2056\n",
            "Epoch 17/60, Batch 4/19, Image: rainy_525.jpg, Loss_G: 3.5912, Loss_D_A: 0.2084, Loss_D_B: 0.2147\n",
            "Epoch 17/60, Batch 5/19, Image: rainy_951.jpg, Loss_G: 3.3559, Loss_D_A: 0.1748, Loss_D_B: 0.2025\n",
            "Epoch 17/60, Batch 6/19, Image: rainy_374.jpg, Loss_G: 2.9808, Loss_D_A: 0.2211, Loss_D_B: 0.2444\n",
            "Epoch 17/60, Batch 7/19, Image: rainy_1066.jpg, Loss_G: 3.1796, Loss_D_A: 0.2010, Loss_D_B: 0.2194\n",
            "Epoch 17/60, Batch 8/19, Image: rainy_1062.jpg, Loss_G: 3.1666, Loss_D_A: 0.1517, Loss_D_B: 0.1573\n",
            "Epoch 17/60, Batch 9/19, Image: rainy_78.jpg, Loss_G: 3.0139, Loss_D_A: 0.2606, Loss_D_B: 0.2713\n",
            "Epoch 17/60, Batch 10/19, Image: rainy_208.jpg, Loss_G: 3.4589, Loss_D_A: 0.3416, Loss_D_B: 0.3034\n",
            "Epoch 17/60, Batch 11/19, Image: rainy_148.jpg, Loss_G: 3.8295, Loss_D_A: 0.4810, Loss_D_B: 0.3369\n",
            "Epoch 17/60, Batch 12/19, Image: rainy_482.jpg, Loss_G: 3.9269, Loss_D_A: 0.5797, Loss_D_B: 0.2564\n",
            "Epoch 17/60, Batch 13/19, Image: rainy_1006.jpg, Loss_G: 4.4045, Loss_D_A: 0.5415, Loss_D_B: 0.2452\n",
            "Epoch 17/60, Batch 14/19, Image: rainy_1189.jpg, Loss_G: 3.6932, Loss_D_A: 1.1661, Loss_D_B: 0.2998\n",
            "Epoch 17/60, Batch 15/19, Image: rainy_1086.jpg, Loss_G: 4.0033, Loss_D_A: 1.2875, Loss_D_B: 0.2083\n",
            "Epoch 17/60, Batch 16/19, Image: rainy_736.jpg, Loss_G: 5.0135, Loss_D_A: 1.7308, Loss_D_B: 0.2406\n",
            "Epoch 17/60, Batch 17/19, Image: rainy_356.jpg, Loss_G: 6.3985, Loss_D_A: 1.1758, Loss_D_B: 0.1994\n",
            "Epoch 17/60, Batch 18/19, Image: rainy_81.jpg, Loss_G: 3.4303, Loss_D_A: 0.3428, Loss_D_B: 0.2550\n",
            "Epoch 18/60, Batch 0/19, Image: rainy_1150.jpg, Loss_G: 3.7179, Loss_D_A: 0.3642, Loss_D_B: 0.2068\n",
            "Epoch 18/60, Batch 1/19, Image: rainy_1196.jpg, Loss_G: 3.6938, Loss_D_A: 0.3215, Loss_D_B: 0.2008\n",
            "Epoch 18/60, Batch 2/19, Image: rainy_851.jpg, Loss_G: 3.1034, Loss_D_A: 0.2657, Loss_D_B: 0.2571\n",
            "Epoch 18/60, Batch 3/19, Image: rainy_1055.jpg, Loss_G: 3.8115, Loss_D_A: 0.2778, Loss_D_B: 0.2800\n",
            "Epoch 18/60, Batch 4/19, Image: rainy_374.jpg, Loss_G: 2.9394, Loss_D_A: 0.2537, Loss_D_B: 0.2241\n",
            "Epoch 18/60, Batch 5/19, Image: rainy_69.jpg, Loss_G: 4.0948, Loss_D_A: 0.2322, Loss_D_B: 0.1583\n",
            "Epoch 18/60, Batch 6/19, Image: rainy_931.jpg, Loss_G: 3.2805, Loss_D_A: 0.2441, Loss_D_B: 0.2274\n",
            "Epoch 18/60, Batch 7/19, Image: rainy_1058.jpg, Loss_G: 3.0223, Loss_D_A: 0.2479, Loss_D_B: 0.1542\n",
            "Epoch 18/60, Batch 8/19, Image: rainy_468.jpg, Loss_G: 3.3028, Loss_D_A: 0.2173, Loss_D_B: 0.1969\n",
            "Epoch 18/60, Batch 9/19, Image: rainy_780.jpg, Loss_G: 4.0839, Loss_D_A: 0.2501, Loss_D_B: 0.1997\n",
            "Epoch 18/60, Batch 10/19, Image: rainy_1157.jpg, Loss_G: 3.6410, Loss_D_A: 0.2471, Loss_D_B: 0.1795\n",
            "Epoch 18/60, Batch 11/19, Image: rainy_567.jpg, Loss_G: 3.5371, Loss_D_A: 0.2337, Loss_D_B: 0.1809\n",
            "Epoch 18/60, Batch 12/19, Image: rainy_148.jpg, Loss_G: 3.8824, Loss_D_A: 0.2772, Loss_D_B: 0.2540\n",
            "Epoch 18/60, Batch 13/19, Image: rainy_570.jpg, Loss_G: 3.1265, Loss_D_A: 0.2193, Loss_D_B: 0.1791\n",
            "Epoch 18/60, Batch 14/19, Image: rainy_1052.jpg, Loss_G: 3.7428, Loss_D_A: 0.2300, Loss_D_B: 0.1818\n",
            "Epoch 18/60, Batch 15/19, Image: rainy_373.jpg, Loss_G: 3.3883, Loss_D_A: 0.2907, Loss_D_B: 0.2247\n",
            "Epoch 18/60, Batch 16/19, Image: rainy_574.jpg, Loss_G: 4.8078, Loss_D_A: 0.2580, Loss_D_B: 0.2048\n",
            "Epoch 18/60, Batch 17/19, Image: rainy_167.jpg, Loss_G: 3.2069, Loss_D_A: 0.2265, Loss_D_B: 0.1766\n",
            "Epoch 18/60, Batch 18/19, Image: rainy_1118.jpg, Loss_G: 3.6839, Loss_D_A: 0.2491, Loss_D_B: 0.2370\n",
            "Epoch 19/60, Batch 0/19, Image: rainy_704.jpg, Loss_G: 3.5272, Loss_D_A: 0.2421, Loss_D_B: 0.2298\n",
            "Epoch 19/60, Batch 1/19, Image: rainy_1189.jpg, Loss_G: 4.6573, Loss_D_A: 0.2431, Loss_D_B: 0.2926\n",
            "Epoch 19/60, Batch 2/19, Image: rainy_480.jpg, Loss_G: 3.4138, Loss_D_A: 0.2277, Loss_D_B: 0.2951\n",
            "Epoch 19/60, Batch 3/19, Image: rainy_764.jpg, Loss_G: 3.0955, Loss_D_A: 0.2252, Loss_D_B: 0.3116\n",
            "Epoch 19/60, Batch 4/19, Image: rainy_1117.jpg, Loss_G: 5.6889, Loss_D_A: 0.2157, Loss_D_B: 0.2988\n",
            "Epoch 19/60, Batch 5/19, Image: rainy_549.jpg, Loss_G: 4.2313, Loss_D_A: 0.2340, Loss_D_B: 0.2438\n",
            "Epoch 19/60, Batch 6/19, Image: rainy_567.jpg, Loss_G: 3.5617, Loss_D_A: 0.1953, Loss_D_B: 0.1674\n",
            "Epoch 19/60, Batch 7/19, Image: rainy_373.jpg, Loss_G: 5.2032, Loss_D_A: 0.2750, Loss_D_B: 0.3118\n",
            "Epoch 19/60, Batch 8/19, Image: rainy_1159.jpg, Loss_G: 4.2653, Loss_D_A: 0.2371, Loss_D_B: 0.2642\n",
            "Epoch 19/60, Batch 9/19, Image: rainy_742.jpg, Loss_G: 3.1638, Loss_D_A: 0.2494, Loss_D_B: 0.2801\n",
            "Epoch 19/60, Batch 10/19, Image: rainy_1141.jpg, Loss_G: 3.2996, Loss_D_A: 0.2048, Loss_D_B: 0.2130\n",
            "Epoch 19/60, Batch 11/19, Image: rainy_74.jpg, Loss_G: 2.6903, Loss_D_A: 0.2541, Loss_D_B: 0.2272\n",
            "Epoch 19/60, Batch 12/19, Image: rainy_934.jpg, Loss_G: 3.8940, Loss_D_A: 0.2603, Loss_D_B: 0.2015\n",
            "Epoch 19/60, Batch 13/19, Image: rainy_324.jpg, Loss_G: 2.9285, Loss_D_A: 0.2542, Loss_D_B: 0.1992\n",
            "Epoch 19/60, Batch 14/19, Image: rainy_80.jpg, Loss_G: 4.6246, Loss_D_A: 0.2836, Loss_D_B: 0.1849\n",
            "Epoch 19/60, Batch 15/19, Image: rainy_638.jpg, Loss_G: 4.0030, Loss_D_A: 0.3013, Loss_D_B: 0.2189\n",
            "Epoch 19/60, Batch 16/19, Image: rainy_706.jpg, Loss_G: 3.1976, Loss_D_A: 0.2355, Loss_D_B: 0.1867\n",
            "Epoch 19/60, Batch 17/19, Image: rainy_533.jpg, Loss_G: 3.2405, Loss_D_A: 0.2118, Loss_D_B: 0.1629\n",
            "Epoch 19/60, Batch 18/19, Image: rainy_1160.jpg, Loss_G: 3.2024, Loss_D_A: 0.2561, Loss_D_B: 0.2182\n",
            "Epoch 20/60, Batch 0/19, Image: rainy_432.jpg, Loss_G: 3.7341, Loss_D_A: 0.2448, Loss_D_B: 0.2609\n",
            "Epoch 20/60, Batch 1/19, Image: rainy_65.jpg, Loss_G: 3.4606, Loss_D_A: 0.1738, Loss_D_B: 0.1101\n",
            "Epoch 20/60, Batch 2/19, Image: rainy_1118.jpg, Loss_G: 3.3335, Loss_D_A: 0.1949, Loss_D_B: 0.1644\n",
            "Epoch 20/60, Batch 3/19, Image: rainy_574.jpg, Loss_G: 3.5264, Loss_D_A: 0.1971, Loss_D_B: 0.1487\n",
            "Epoch 20/60, Batch 4/19, Image: rainy_1157.jpg, Loss_G: 5.4406, Loss_D_A: 0.1877, Loss_D_B: 0.1284\n",
            "Epoch 20/60, Batch 5/19, Image: rainy_1054.jpg, Loss_G: 2.7420, Loss_D_A: 0.2113, Loss_D_B: 0.2413\n",
            "Epoch 20/60, Batch 6/19, Image: rainy_654.jpg, Loss_G: 2.7511, Loss_D_A: 0.2050, Loss_D_B: 0.2146\n",
            "Epoch 20/60, Batch 7/19, Image: rainy_374.jpg, Loss_G: 2.5205, Loss_D_A: 0.2073, Loss_D_B: 0.2408\n",
            "Epoch 20/60, Batch 8/19, Image: rainy_145.jpg, Loss_G: 2.6420, Loss_D_A: 0.1837, Loss_D_B: 0.1777\n",
            "Epoch 20/60, Batch 9/19, Image: rainy_148.jpg, Loss_G: 3.0108, Loss_D_A: 0.1772, Loss_D_B: 0.1593\n",
            "Epoch 20/60, Batch 10/19, Image: rainy_657.jpg, Loss_G: 2.9961, Loss_D_A: 0.1600, Loss_D_B: 0.1452\n",
            "Epoch 20/60, Batch 11/19, Image: rainy_92.jpg, Loss_G: 4.6275, Loss_D_A: 0.1991, Loss_D_B: 0.1618\n",
            "Epoch 20/60, Batch 12/19, Image: rainy_589.jpg, Loss_G: 3.4468, Loss_D_A: 0.2555, Loss_D_B: 0.2041\n",
            "Epoch 20/60, Batch 13/19, Image: rainy_404.jpg, Loss_G: 3.9467, Loss_D_A: 0.2201, Loss_D_B: 0.2336\n",
            "Epoch 20/60, Batch 14/19, Image: rainy_468.jpg, Loss_G: 3.0506, Loss_D_A: 0.1942, Loss_D_B: 0.1778\n",
            "Epoch 20/60, Batch 15/19, Image: rainy_704.jpg, Loss_G: 3.3549, Loss_D_A: 0.1916, Loss_D_B: 0.1512\n",
            "Epoch 20/60, Batch 16/19, Image: rainy_53.jpg, Loss_G: 3.1109, Loss_D_A: 0.1979, Loss_D_B: 0.1499\n",
            "Epoch 20/60, Batch 17/19, Image: rainy_570.jpg, Loss_G: 3.0022, Loss_D_A: 0.1979, Loss_D_B: 0.2004\n",
            "Epoch 20/60, Batch 18/19, Image: rainy_356.jpg, Loss_G: 3.1439, Loss_D_A: 0.1629, Loss_D_B: 0.1587\n",
            "Epoch 21/60, Batch 0/19, Image: rainy_907.jpg, Loss_G: 3.1264, Loss_D_A: 0.1768, Loss_D_B: 0.1897\n",
            "Epoch 21/60, Batch 1/19, Image: rainy_958.jpg, Loss_G: 2.9002, Loss_D_A: 0.1704, Loss_D_B: 0.1531\n",
            "Epoch 21/60, Batch 2/19, Image: rainy_533.jpg, Loss_G: 2.7096, Loss_D_A: 0.2037, Loss_D_B: 0.2197\n",
            "Epoch 21/60, Batch 3/19, Image: rainy_710.jpg, Loss_G: 2.7306, Loss_D_A: 0.1694, Loss_D_B: 0.1691\n",
            "Epoch 21/60, Batch 4/19, Image: rainy_319.jpg, Loss_G: 2.4113, Loss_D_A: 0.2449, Loss_D_B: 0.3075\n",
            "Epoch 21/60, Batch 5/19, Image: rainy_208.jpg, Loss_G: 2.8016, Loss_D_A: 0.1843, Loss_D_B: 0.2129\n",
            "Epoch 21/60, Batch 6/19, Image: rainy_122.jpg, Loss_G: 3.4619, Loss_D_A: 0.1926, Loss_D_B: 0.2007\n",
            "Epoch 21/60, Batch 7/19, Image: rainy_736.jpg, Loss_G: 4.5185, Loss_D_A: 0.2179, Loss_D_B: 0.2293\n",
            "Epoch 21/60, Batch 8/19, Image: rainy_480.jpg, Loss_G: 3.5140, Loss_D_A: 0.1687, Loss_D_B: 0.2176\n",
            "Epoch 21/60, Batch 9/19, Image: rainy_1055.jpg, Loss_G: 2.6782, Loss_D_A: 0.1871, Loss_D_B: 0.2319\n",
            "Epoch 21/60, Batch 10/19, Image: rainy_468.jpg, Loss_G: 4.5362, Loss_D_A: 0.2056, Loss_D_B: 0.2174\n",
            "Epoch 21/60, Batch 11/19, Image: rainy_1047.jpg, Loss_G: 2.9324, Loss_D_A: 0.1854, Loss_D_B: 0.1842\n",
            "Epoch 21/60, Batch 12/19, Image: rainy_181.jpg, Loss_G: 3.1200, Loss_D_A: 0.2058, Loss_D_B: 0.2232\n",
            "Epoch 21/60, Batch 13/19, Image: rainy_1052.jpg, Loss_G: 2.8751, Loss_D_A: 0.1784, Loss_D_B: 0.1947\n",
            "Epoch 21/60, Batch 14/19, Image: rainy_215.jpg, Loss_G: 2.9322, Loss_D_A: 0.1867, Loss_D_B: 0.1775\n",
            "Epoch 21/60, Batch 15/19, Image: rainy_1062.jpg, Loss_G: 3.4935, Loss_D_A: 0.1730, Loss_D_B: 0.2282\n",
            "Epoch 21/60, Batch 16/19, Image: rainy_463.jpg, Loss_G: 3.0789, Loss_D_A: 0.1559, Loss_D_B: 0.1693\n",
            "Epoch 21/60, Batch 17/19, Image: rainy_633.jpg, Loss_G: 2.6858, Loss_D_A: 0.2139, Loss_D_B: 0.2734\n",
            "Epoch 21/60, Batch 18/19, Image: rainy_75.jpg, Loss_G: 2.6869, Loss_D_A: 0.1318, Loss_D_B: 0.1723\n",
            "Epoch 22/60, Batch 0/19, Image: rainy_78.jpg, Loss_G: 2.9213, Loss_D_A: 0.1446, Loss_D_B: 0.1997\n",
            "Epoch 22/60, Batch 1/19, Image: rainy_533.jpg, Loss_G: 4.3876, Loss_D_A: 0.1199, Loss_D_B: 0.2014\n",
            "Epoch 22/60, Batch 2/19, Image: rainy_689.jpg, Loss_G: 3.6408, Loss_D_A: 0.1339, Loss_D_B: 0.2067\n",
            "Epoch 22/60, Batch 3/19, Image: rainy_349.jpg, Loss_G: 2.7982, Loss_D_A: 0.1550, Loss_D_B: 0.1953\n",
            "Epoch 22/60, Batch 4/19, Image: rainy_785.jpg, Loss_G: 4.0000, Loss_D_A: 0.1201, Loss_D_B: 0.2046\n",
            "Epoch 22/60, Batch 5/19, Image: rainy_549.jpg, Loss_G: 3.0971, Loss_D_A: 0.1154, Loss_D_B: 0.2275\n",
            "Epoch 22/60, Batch 6/19, Image: rainy_75.jpg, Loss_G: 3.2229, Loss_D_A: 0.0921, Loss_D_B: 0.1560\n",
            "Epoch 22/60, Batch 7/19, Image: rainy_1062.jpg, Loss_G: 2.9049, Loss_D_A: 0.1374, Loss_D_B: 0.1754\n",
            "Epoch 22/60, Batch 8/19, Image: rainy_1110.jpg, Loss_G: 2.8506, Loss_D_A: 0.1629, Loss_D_B: 0.2113\n",
            "Epoch 22/60, Batch 9/19, Image: rainy_324.jpg, Loss_G: 2.8169, Loss_D_A: 0.1924, Loss_D_B: 0.1542\n",
            "Epoch 22/60, Batch 10/19, Image: rainy_1066.jpg, Loss_G: 3.3890, Loss_D_A: 0.2702, Loss_D_B: 0.3262\n",
            "Epoch 22/60, Batch 11/19, Image: rainy_710.jpg, Loss_G: 3.0382, Loss_D_A: 0.1707, Loss_D_B: 0.2183\n",
            "Epoch 22/60, Batch 12/19, Image: rainy_259.jpg, Loss_G: 3.2108, Loss_D_A: 0.1938, Loss_D_B: 0.2589\n",
            "Epoch 22/60, Batch 13/19, Image: rainy_1190.jpg, Loss_G: 3.0280, Loss_D_A: 0.1589, Loss_D_B: 0.2162\n",
            "Epoch 22/60, Batch 14/19, Image: rainy_319.jpg, Loss_G: 2.8813, Loss_D_A: 0.1624, Loss_D_B: 0.2144\n",
            "Epoch 22/60, Batch 15/19, Image: rainy_138.jpg, Loss_G: 3.5389, Loss_D_A: 0.1037, Loss_D_B: 0.1702\n",
            "Epoch 22/60, Batch 16/19, Image: rainy_764.jpg, Loss_G: 2.6802, Loss_D_A: 0.1664, Loss_D_B: 0.2433\n",
            "Epoch 22/60, Batch 17/19, Image: rainy_958.jpg, Loss_G: 3.0908, Loss_D_A: 0.2123, Loss_D_B: 0.3190\n",
            "Epoch 22/60, Batch 18/19, Image: rainy_463.jpg, Loss_G: 2.6595, Loss_D_A: 0.1243, Loss_D_B: 0.2182\n",
            "Epoch 23/60, Batch 0/19, Image: rainy_907.jpg, Loss_G: 4.0102, Loss_D_A: 0.1756, Loss_D_B: 0.1959\n",
            "Epoch 23/60, Batch 1/19, Image: rainy_744.jpg, Loss_G: 4.0155, Loss_D_A: 0.3024, Loss_D_B: 0.2384\n",
            "Epoch 23/60, Batch 2/19, Image: rainy_654.jpg, Loss_G: 3.6551, Loss_D_A: 0.5110, Loss_D_B: 0.2492\n",
            "Epoch 23/60, Batch 3/19, Image: rainy_868.jpg, Loss_G: 4.0023, Loss_D_A: 0.2536, Loss_D_B: 0.1357\n",
            "Epoch 23/60, Batch 4/19, Image: rainy_1159.jpg, Loss_G: 2.8412, Loss_D_A: 0.2761, Loss_D_B: 0.2439\n",
            "Epoch 23/60, Batch 5/19, Image: rainy_480.jpg, Loss_G: 3.6108, Loss_D_A: 0.2566, Loss_D_B: 0.2402\n",
            "Epoch 23/60, Batch 6/19, Image: rainy_1110.jpg, Loss_G: 4.1092, Loss_D_A: 0.2410, Loss_D_B: 0.2028\n",
            "Epoch 23/60, Batch 7/19, Image: rainy_1100.jpg, Loss_G: 2.9665, Loss_D_A: 0.2325, Loss_D_B: 0.1599\n",
            "Epoch 23/60, Batch 8/19, Image: rainy_470.jpg, Loss_G: 2.6687, Loss_D_A: 0.2538, Loss_D_B: 0.1984\n",
            "Epoch 23/60, Batch 9/19, Image: rainy_237.jpg, Loss_G: 3.5289, Loss_D_A: 0.2509, Loss_D_B: 0.2101\n",
            "Epoch 23/60, Batch 10/19, Image: rainy_1018.jpg, Loss_G: 3.3314, Loss_D_A: 0.2267, Loss_D_B: 0.1704\n",
            "Epoch 23/60, Batch 11/19, Image: rainy_922.jpg, Loss_G: 3.1869, Loss_D_A: 0.2208, Loss_D_B: 0.1800\n",
            "Epoch 23/60, Batch 12/19, Image: rainy_468.jpg, Loss_G: 2.7068, Loss_D_A: 0.2098, Loss_D_B: 0.1854\n",
            "Epoch 23/60, Batch 13/19, Image: rainy_570.jpg, Loss_G: 2.9993, Loss_D_A: 0.2425, Loss_D_B: 0.2251\n",
            "Epoch 23/60, Batch 14/19, Image: rainy_1062.jpg, Loss_G: 2.9987, Loss_D_A: 0.2282, Loss_D_B: 0.2153\n",
            "Epoch 23/60, Batch 15/19, Image: rainy_463.jpg, Loss_G: 2.9283, Loss_D_A: 0.2663, Loss_D_B: 0.1916\n",
            "Epoch 23/60, Batch 16/19, Image: rainy_119.jpg, Loss_G: 2.8981, Loss_D_A: 0.2364, Loss_D_B: 0.2033\n",
            "Epoch 23/60, Batch 17/19, Image: rainy_931.jpg, Loss_G: 2.9398, Loss_D_A: 0.2451, Loss_D_B: 0.1925\n",
            "Epoch 23/60, Batch 18/19, Image: rainy_373.jpg, Loss_G: 3.9340, Loss_D_A: 0.2189, Loss_D_B: 0.1694\n",
            "Epoch 24/60, Batch 0/19, Image: rainy_92.jpg, Loss_G: 3.0204, Loss_D_A: 0.2396, Loss_D_B: 0.1924\n",
            "Epoch 24/60, Batch 1/19, Image: rainy_744.jpg, Loss_G: 3.5006, Loss_D_A: 0.2336, Loss_D_B: 0.1880\n",
            "Epoch 24/60, Batch 2/19, Image: rainy_1141.jpg, Loss_G: 2.6782, Loss_D_A: 0.2491, Loss_D_B: 0.2212\n",
            "Epoch 24/60, Batch 3/19, Image: rainy_463.jpg, Loss_G: 2.6410, Loss_D_A: 0.2707, Loss_D_B: 0.1852\n",
            "Epoch 24/60, Batch 4/19, Image: rainy_1058.jpg, Loss_G: 3.0022, Loss_D_A: 0.2341, Loss_D_B: 0.1719\n",
            "Epoch 24/60, Batch 5/19, Image: rainy_654.jpg, Loss_G: 2.5477, Loss_D_A: 0.2328, Loss_D_B: 0.1653\n",
            "Epoch 24/60, Batch 6/19, Image: rainy_181.jpg, Loss_G: 4.9610, Loss_D_A: 0.2550, Loss_D_B: 0.2618\n",
            "Epoch 24/60, Batch 7/19, Image: rainy_65.jpg, Loss_G: 2.6966, Loss_D_A: 0.2529, Loss_D_B: 0.2402\n",
            "Epoch 24/60, Batch 8/19, Image: rainy_549.jpg, Loss_G: 4.2983, Loss_D_A: 0.2352, Loss_D_B: 0.1729\n",
            "Epoch 24/60, Batch 9/19, Image: rainy_785.jpg, Loss_G: 2.6901, Loss_D_A: 0.2082, Loss_D_B: 0.1586\n",
            "Epoch 24/60, Batch 10/19, Image: rainy_96.jpg, Loss_G: 3.3587, Loss_D_A: 0.2365, Loss_D_B: 0.2078\n",
            "Epoch 24/60, Batch 11/19, Image: rainy_277.jpg, Loss_G: 2.7686, Loss_D_A: 0.2354, Loss_D_B: 0.2293\n",
            "Epoch 24/60, Batch 12/19, Image: rainy_215.jpg, Loss_G: 3.3881, Loss_D_A: 0.2034, Loss_D_B: 0.1975\n",
            "Epoch 24/60, Batch 13/19, Image: rainy_922.jpg, Loss_G: 2.6244, Loss_D_A: 0.2630, Loss_D_B: 0.2328\n",
            "Epoch 24/60, Batch 14/19, Image: rainy_340.jpg, Loss_G: 2.7897, Loss_D_A: 0.2386, Loss_D_B: 0.1789\n",
            "Epoch 24/60, Batch 15/19, Image: rainy_237.jpg, Loss_G: 3.2303, Loss_D_A: 0.2143, Loss_D_B: 0.1887\n",
            "Epoch 24/60, Batch 16/19, Image: rainy_12.jpg, Loss_G: 3.8153, Loss_D_A: 0.2260, Loss_D_B: 0.2194\n",
            "Epoch 24/60, Batch 17/19, Image: rainy_741.jpg, Loss_G: 3.3510, Loss_D_A: 0.2368, Loss_D_B: 0.2241\n",
            "Epoch 24/60, Batch 18/19, Image: rainy_373.jpg, Loss_G: 3.7969, Loss_D_A: 0.2750, Loss_D_B: 0.2589\n",
            "Epoch 25/60, Batch 0/19, Image: rainy_1183.jpg, Loss_G: 2.9377, Loss_D_A: 0.1716, Loss_D_B: 0.1246\n",
            "Epoch 25/60, Batch 1/19, Image: rainy_1049.jpg, Loss_G: 3.1608, Loss_D_A: 0.2476, Loss_D_B: 0.2176\n",
            "Epoch 25/60, Batch 2/19, Image: rainy_633.jpg, Loss_G: 2.6450, Loss_D_A: 0.2481, Loss_D_B: 0.2410\n",
            "Epoch 25/60, Batch 3/19, Image: rainy_1118.jpg, Loss_G: 3.6722, Loss_D_A: 0.2317, Loss_D_B: 0.1971\n",
            "Epoch 25/60, Batch 4/19, Image: rainy_97.jpg, Loss_G: 2.4809, Loss_D_A: 0.2537, Loss_D_B: 0.2386\n",
            "Epoch 25/60, Batch 5/19, Image: rainy_468.jpg, Loss_G: 5.6982, Loss_D_A: 0.2387, Loss_D_B: 0.2093\n",
            "Epoch 25/60, Batch 6/19, Image: rainy_237.jpg, Loss_G: 3.6018, Loss_D_A: 0.2832, Loss_D_B: 0.2665\n",
            "Epoch 25/60, Batch 7/19, Image: rainy_593.jpg, Loss_G: 2.9204, Loss_D_A: 0.2356, Loss_D_B: 0.2023\n",
            "Epoch 25/60, Batch 8/19, Image: rainy_922.jpg, Loss_G: 3.0388, Loss_D_A: 0.2155, Loss_D_B: 0.1832\n",
            "Epoch 25/60, Batch 9/19, Image: rainy_215.jpg, Loss_G: 3.5144, Loss_D_A: 0.2226, Loss_D_B: 0.2094\n",
            "Epoch 25/60, Batch 10/19, Image: rainy_968.jpg, Loss_G: 2.7458, Loss_D_A: 0.1814, Loss_D_B: 0.1467\n",
            "Epoch 25/60, Batch 11/19, Image: rainy_549.jpg, Loss_G: 3.0654, Loss_D_A: 0.2106, Loss_D_B: 0.1653\n",
            "Epoch 25/60, Batch 12/19, Image: rainy_122.jpg, Loss_G: 3.4752, Loss_D_A: 0.1903, Loss_D_B: 0.1398\n",
            "Epoch 25/60, Batch 13/19, Image: rainy_1066.jpg, Loss_G: 2.5664, Loss_D_A: 0.2302, Loss_D_B: 0.1780\n",
            "Epoch 25/60, Batch 14/19, Image: rainy_470.jpg, Loss_G: 2.6359, Loss_D_A: 0.2517, Loss_D_B: 0.2015\n",
            "Epoch 25/60, Batch 15/19, Image: rainy_376.jpg, Loss_G: 2.5065, Loss_D_A: 0.2371, Loss_D_B: 0.1891\n",
            "Epoch 25/60, Batch 16/19, Image: rainy_311.jpg, Loss_G: 2.9894, Loss_D_A: 0.2705, Loss_D_B: 0.3060\n",
            "Epoch 25/60, Batch 17/19, Image: rainy_181.jpg, Loss_G: 3.7314, Loss_D_A: 0.2427, Loss_D_B: 0.2459\n",
            "Epoch 25/60, Batch 18/19, Image: rainy_378.jpg, Loss_G: 3.3836, Loss_D_A: 0.2267, Loss_D_B: 0.2177\n",
            "Epoch 26/60, Batch 0/19, Image: rainy_1150.jpg, Loss_G: 2.7163, Loss_D_A: 0.2161, Loss_D_B: 0.2038\n",
            "Epoch 26/60, Batch 1/19, Image: rainy_271.jpg, Loss_G: 2.8836, Loss_D_A: 0.2120, Loss_D_B: 0.1886\n",
            "Epoch 26/60, Batch 2/19, Image: rainy_654.jpg, Loss_G: 2.9021, Loss_D_A: 0.2031, Loss_D_B: 0.1522\n",
            "Epoch 26/60, Batch 3/19, Image: rainy_907.jpg, Loss_G: 2.9694, Loss_D_A: 0.2667, Loss_D_B: 0.2512\n",
            "Epoch 26/60, Batch 4/19, Image: rainy_736.jpg, Loss_G: 2.4667, Loss_D_A: 0.2351, Loss_D_B: 0.2136\n",
            "Epoch 26/60, Batch 5/19, Image: rainy_968.jpg, Loss_G: 2.7472, Loss_D_A: 0.1974, Loss_D_B: 0.1373\n",
            "Epoch 26/60, Batch 6/19, Image: rainy_187.jpg, Loss_G: 2.9293, Loss_D_A: 0.2678, Loss_D_B: 0.2391\n",
            "Epoch 26/60, Batch 7/19, Image: rainy_1117.jpg, Loss_G: 3.9409, Loss_D_A: 0.2752, Loss_D_B: 0.2501\n",
            "Epoch 26/60, Batch 8/19, Image: rainy_374.jpg, Loss_G: 3.7344, Loss_D_A: 0.2113, Loss_D_B: 0.1678\n",
            "Epoch 26/60, Batch 9/19, Image: rainy_951.jpg, Loss_G: 2.5385, Loss_D_A: 0.2418, Loss_D_B: 0.2205\n",
            "Epoch 26/60, Batch 10/19, Image: rainy_549.jpg, Loss_G: 2.9774, Loss_D_A: 0.2035, Loss_D_B: 0.1719\n",
            "Epoch 26/60, Batch 11/19, Image: rainy_839.jpg, Loss_G: 3.9153, Loss_D_A: 0.2247, Loss_D_B: 0.2297\n",
            "Epoch 26/60, Batch 12/19, Image: rainy_437.jpg, Loss_G: 2.4470, Loss_D_A: 0.2634, Loss_D_B: 0.2457\n",
            "Epoch 26/60, Batch 13/19, Image: rainy_167.jpg, Loss_G: 2.6735, Loss_D_A: 0.2167, Loss_D_B: 0.1769\n",
            "Epoch 26/60, Batch 14/19, Image: rainy_1110.jpg, Loss_G: 2.9759, Loss_D_A: 0.2040, Loss_D_B: 0.1871\n",
            "Epoch 26/60, Batch 15/19, Image: rainy_1118.jpg, Loss_G: 2.4128, Loss_D_A: 0.2762, Loss_D_B: 0.2446\n",
            "Epoch 26/60, Batch 16/19, Image: rainy_1141.jpg, Loss_G: 2.4993, Loss_D_A: 0.1865, Loss_D_B: 0.1605\n",
            "Epoch 26/60, Batch 17/19, Image: rainy_704.jpg, Loss_G: 2.8706, Loss_D_A: 0.2060, Loss_D_B: 0.1747\n",
            "Epoch 26/60, Batch 18/19, Image: rainy_349.jpg, Loss_G: 2.7072, Loss_D_A: 0.2356, Loss_D_B: 0.2186\n",
            "Epoch 27/60, Batch 0/19, Image: rainy_951.jpg, Loss_G: 2.8733, Loss_D_A: 0.2555, Loss_D_B: 0.2127\n",
            "Epoch 27/60, Batch 1/19, Image: rainy_1047.jpg, Loss_G: 3.0380, Loss_D_A: 0.2301, Loss_D_B: 0.2158\n",
            "Epoch 27/60, Batch 2/19, Image: rainy_1059.jpg, Loss_G: 3.3418, Loss_D_A: 0.2299, Loss_D_B: 0.2531\n",
            "Epoch 27/60, Batch 3/19, Image: rainy_317.jpg, Loss_G: 2.7549, Loss_D_A: 0.1995, Loss_D_B: 0.1998\n",
            "Epoch 27/60, Batch 4/19, Image: rainy_1033.jpg, Loss_G: 2.5166, Loss_D_A: 0.2607, Loss_D_B: 0.3000\n",
            "Epoch 27/60, Batch 5/19, Image: rainy_123.jpg, Loss_G: 2.7857, Loss_D_A: 0.2208, Loss_D_B: 0.2339\n",
            "Epoch 27/60, Batch 6/19, Image: rainy_53.jpg, Loss_G: 2.4554, Loss_D_A: 0.1788, Loss_D_B: 0.1645\n",
            "Epoch 27/60, Batch 7/19, Image: rainy_567.jpg, Loss_G: 3.6017, Loss_D_A: 0.2122, Loss_D_B: 0.1635\n",
            "Epoch 27/60, Batch 8/19, Image: rainy_369.jpg, Loss_G: 3.9849, Loss_D_A: 0.2867, Loss_D_B: 0.2681\n",
            "Epoch 27/60, Batch 9/19, Image: rainy_378.jpg, Loss_G: 4.0965, Loss_D_A: 0.2143, Loss_D_B: 0.1817\n",
            "Epoch 27/60, Batch 10/19, Image: rainy_635.jpg, Loss_G: 2.5031, Loss_D_A: 0.2574, Loss_D_B: 0.2589\n",
            "Epoch 27/60, Batch 11/19, Image: rainy_1160.jpg, Loss_G: 3.8389, Loss_D_A: 0.2450, Loss_D_B: 0.2395\n",
            "Epoch 27/60, Batch 12/19, Image: rainy_148.jpg, Loss_G: 2.9125, Loss_D_A: 0.2148, Loss_D_B: 0.2286\n",
            "Epoch 27/60, Batch 13/19, Image: rainy_942.jpg, Loss_G: 3.9845, Loss_D_A: 0.2087, Loss_D_B: 0.1896\n",
            "Epoch 27/60, Batch 14/19, Image: rainy_740.jpg, Loss_G: 2.8237, Loss_D_A: 0.2411, Loss_D_B: 0.2094\n",
            "Epoch 27/60, Batch 15/19, Image: rainy_1141.jpg, Loss_G: 3.6683, Loss_D_A: 0.2108, Loss_D_B: 0.1719\n",
            "Epoch 27/60, Batch 16/19, Image: rainy_536.jpg, Loss_G: 3.6741, Loss_D_A: 0.2418, Loss_D_B: 0.2187\n",
            "Epoch 27/60, Batch 17/19, Image: rainy_75.jpg, Loss_G: 3.0630, Loss_D_A: 0.2011, Loss_D_B: 0.1747\n",
            "Epoch 27/60, Batch 18/19, Image: rainy_1055.jpg, Loss_G: 3.4570, Loss_D_A: 0.2008, Loss_D_B: 0.1874\n",
            "Epoch 28/60, Batch 0/19, Image: rainy_92.jpg, Loss_G: 3.3875, Loss_D_A: 0.2289, Loss_D_B: 0.2104\n",
            "Epoch 28/60, Batch 1/19, Image: rainy_157.jpg, Loss_G: 2.8532, Loss_D_A: 0.2596, Loss_D_B: 0.2603\n",
            "Epoch 28/60, Batch 2/19, Image: rainy_237.jpg, Loss_G: 2.9402, Loss_D_A: 0.2168, Loss_D_B: 0.1980\n",
            "Epoch 28/60, Batch 3/19, Image: rainy_743.jpg, Loss_G: 4.6063, Loss_D_A: 0.2343, Loss_D_B: 0.1899\n",
            "Epoch 28/60, Batch 4/19, Image: rainy_1117.jpg, Loss_G: 2.9607, Loss_D_A: 0.2017, Loss_D_B: 0.1711\n",
            "Epoch 28/60, Batch 5/19, Image: rainy_744.jpg, Loss_G: 3.2331, Loss_D_A: 0.2086, Loss_D_B: 0.1681\n",
            "Epoch 28/60, Batch 6/19, Image: rainy_741.jpg, Loss_G: 2.4935, Loss_D_A: 0.2440, Loss_D_B: 0.2610\n",
            "Epoch 28/60, Batch 7/19, Image: rainy_851.jpg, Loss_G: 2.8059, Loss_D_A: 0.1732, Loss_D_B: 0.1226\n",
            "Epoch 28/60, Batch 8/19, Image: rainy_1054.jpg, Loss_G: 2.9524, Loss_D_A: 0.2360, Loss_D_B: 0.2200\n",
            "Epoch 28/60, Batch 9/19, Image: rainy_1100.jpg, Loss_G: 2.6452, Loss_D_A: 0.1964, Loss_D_B: 0.1667\n",
            "Epoch 28/60, Batch 10/19, Image: rainy_75.jpg, Loss_G: 2.9332, Loss_D_A: 0.2119, Loss_D_B: 0.1811\n",
            "Epoch 28/60, Batch 11/19, Image: rainy_81.jpg, Loss_G: 3.7170, Loss_D_A: 0.2041, Loss_D_B: 0.1719\n",
            "Epoch 28/60, Batch 12/19, Image: rainy_842.jpg, Loss_G: 2.9182, Loss_D_A: 0.2454, Loss_D_B: 0.2481\n",
            "Epoch 28/60, Batch 13/19, Image: rainy_570.jpg, Loss_G: 2.9439, Loss_D_A: 0.2092, Loss_D_B: 0.1754\n",
            "Epoch 28/60, Batch 14/19, Image: rainy_708.jpg, Loss_G: 2.8314, Loss_D_A: 0.1787, Loss_D_B: 0.1409\n",
            "Epoch 28/60, Batch 15/19, Image: rainy_74.jpg, Loss_G: 2.6277, Loss_D_A: 0.2534, Loss_D_B: 0.2470\n",
            "Epoch 28/60, Batch 16/19, Image: rainy_1006.jpg, Loss_G: 3.0143, Loss_D_A: 0.1986, Loss_D_B: 0.1726\n",
            "Epoch 28/60, Batch 17/19, Image: rainy_1066.jpg, Loss_G: 3.3600, Loss_D_A: 0.2326, Loss_D_B: 0.2127\n",
            "Epoch 28/60, Batch 18/19, Image: rainy_101.jpg, Loss_G: 3.6704, Loss_D_A: 0.1713, Loss_D_B: 0.1461\n",
            "Epoch 29/60, Batch 0/19, Image: rainy_654.jpg, Loss_G: 2.7873, Loss_D_A: 0.2774, Loss_D_B: 0.2629\n",
            "Epoch 29/60, Batch 1/19, Image: rainy_311.jpg, Loss_G: 3.0563, Loss_D_A: 0.2133, Loss_D_B: 0.1831\n",
            "Epoch 29/60, Batch 2/19, Image: rainy_1054.jpg, Loss_G: 2.6075, Loss_D_A: 0.2564, Loss_D_B: 0.2097\n",
            "Epoch 29/60, Batch 3/19, Image: rainy_657.jpg, Loss_G: 3.1748, Loss_D_A: 0.2391, Loss_D_B: 0.2292\n",
            "Epoch 29/60, Batch 4/19, Image: rainy_706.jpg, Loss_G: 3.0610, Loss_D_A: 0.1957, Loss_D_B: 0.1658\n",
            "Epoch 29/60, Batch 5/19, Image: rainy_708.jpg, Loss_G: 2.3790, Loss_D_A: 0.2555, Loss_D_B: 0.2547\n",
            "Epoch 29/60, Batch 6/19, Image: rainy_374.jpg, Loss_G: 5.6887, Loss_D_A: 0.2427, Loss_D_B: 0.2373\n",
            "Epoch 29/60, Batch 7/19, Image: rainy_145.jpg, Loss_G: 3.1800, Loss_D_A: 0.1809, Loss_D_B: 0.1633\n",
            "Epoch 29/60, Batch 8/19, Image: rainy_237.jpg, Loss_G: 2.6960, Loss_D_A: 0.2152, Loss_D_B: 0.1845\n",
            "Epoch 29/60, Batch 9/19, Image: rainy_1157.jpg, Loss_G: 2.9134, Loss_D_A: 0.1997, Loss_D_B: 0.1628\n",
            "Epoch 29/60, Batch 10/19, Image: rainy_480.jpg, Loss_G: 3.1579, Loss_D_A: 0.1945, Loss_D_B: 0.1800\n",
            "Epoch 29/60, Batch 11/19, Image: rainy_671.jpg, Loss_G: 2.7210, Loss_D_A: 0.1944, Loss_D_B: 0.1421\n",
            "Epoch 29/60, Batch 12/19, Image: rainy_1189.jpg, Loss_G: 3.3945, Loss_D_A: 0.2355, Loss_D_B: 0.1751\n",
            "Epoch 29/60, Batch 13/19, Image: rainy_414.jpg, Loss_G: 3.0541, Loss_D_A: 0.1900, Loss_D_B: 0.1387\n",
            "Epoch 29/60, Batch 14/19, Image: rainy_235.jpg, Loss_G: 4.0288, Loss_D_A: 0.2651, Loss_D_B: 0.2302\n",
            "Epoch 29/60, Batch 15/19, Image: rainy_635.jpg, Loss_G: 3.6006, Loss_D_A: 0.2151, Loss_D_B: 0.2158\n",
            "Epoch 29/60, Batch 16/19, Image: rainy_764.jpg, Loss_G: 4.4752, Loss_D_A: 0.2124, Loss_D_B: 0.3105\n",
            "Epoch 29/60, Batch 17/19, Image: rainy_1006.jpg, Loss_G: 3.4223, Loss_D_A: 0.2004, Loss_D_B: 0.3083\n",
            "Epoch 29/60, Batch 18/19, Image: rainy_785.jpg, Loss_G: 2.5827, Loss_D_A: 0.2660, Loss_D_B: 0.3394\n",
            "Epoch 30/60, Batch 0/19, Image: rainy_593.jpg, Loss_G: 2.8569, Loss_D_A: 0.3055, Loss_D_B: 0.3056\n",
            "Epoch 30/60, Batch 1/19, Image: rainy_644.jpg, Loss_G: 4.1951, Loss_D_A: 0.2558, Loss_D_B: 0.2292\n",
            "Epoch 30/60, Batch 2/19, Image: rainy_1018.jpg, Loss_G: 3.1089, Loss_D_A: 0.1963, Loss_D_B: 0.1669\n",
            "Epoch 30/60, Batch 3/19, Image: rainy_837.jpg, Loss_G: 3.0968, Loss_D_A: 0.2312, Loss_D_B: 0.1873\n",
            "Epoch 30/60, Batch 4/19, Image: rainy_181.jpg, Loss_G: 3.3042, Loss_D_A: 0.2016, Loss_D_B: 0.1927\n",
            "Epoch 30/60, Batch 5/19, Image: rainy_468.jpg, Loss_G: 3.5878, Loss_D_A: 0.2282, Loss_D_B: 0.2087\n",
            "Epoch 30/60, Batch 6/19, Image: rainy_742.jpg, Loss_G: 2.6539, Loss_D_A: 0.2640, Loss_D_B: 0.2599\n",
            "Epoch 30/60, Batch 7/19, Image: rainy_706.jpg, Loss_G: 3.7126, Loss_D_A: 0.1790, Loss_D_B: 0.1609\n",
            "Epoch 30/60, Batch 8/19, Image: rainy_81.jpg, Loss_G: 2.6421, Loss_D_A: 0.1705, Loss_D_B: 0.1322\n",
            "Epoch 30/60, Batch 9/19, Image: rainy_65.jpg, Loss_G: 2.8953, Loss_D_A: 0.2039, Loss_D_B: 0.2076\n",
            "Epoch 30/60, Batch 10/19, Image: rainy_1118.jpg, Loss_G: 3.6488, Loss_D_A: 0.1967, Loss_D_B: 0.1736\n",
            "Epoch 30/60, Batch 11/19, Image: rainy_802.jpg, Loss_G: 2.7824, Loss_D_A: 0.1986, Loss_D_B: 0.1699\n",
            "Epoch 30/60, Batch 12/19, Image: rainy_1145.jpg, Loss_G: 3.0143, Loss_D_A: 0.2094, Loss_D_B: 0.1666\n",
            "Epoch 30/60, Batch 13/19, Image: rainy_910.jpg, Loss_G: 3.2559, Loss_D_A: 0.1790, Loss_D_B: 0.1195\n",
            "Epoch 30/60, Batch 14/19, Image: rainy_12.jpg, Loss_G: 3.3327, Loss_D_A: 0.2272, Loss_D_B: 0.2058\n",
            "Epoch 30/60, Batch 15/19, Image: rainy_839.jpg, Loss_G: 3.9918, Loss_D_A: 0.3003, Loss_D_B: 0.2808\n",
            "Epoch 30/60, Batch 16/19, Image: rainy_1006.jpg, Loss_G: 2.7611, Loss_D_A: 0.2805, Loss_D_B: 0.2737\n",
            "Epoch 30/60, Batch 17/19, Image: rainy_671.jpg, Loss_G: 2.8658, Loss_D_A: 0.2516, Loss_D_B: 0.2203\n",
            "Epoch 30/60, Batch 18/19, Image: rainy_63.jpg, Loss_G: 4.4019, Loss_D_A: 0.2286, Loss_D_B: 0.2025\n",
            "Epoch 31/60, Batch 0/19, Image: rainy_324.jpg, Loss_G: 3.2208, Loss_D_A: 0.2350, Loss_D_B: 0.1784\n",
            "Epoch 31/60, Batch 1/19, Image: rainy_635.jpg, Loss_G: 2.4236, Loss_D_A: 0.2339, Loss_D_B: 0.2091\n",
            "Epoch 31/60, Batch 2/19, Image: rainy_81.jpg, Loss_G: 4.1252, Loss_D_A: 0.1745, Loss_D_B: 0.1571\n",
            "Epoch 31/60, Batch 3/19, Image: rainy_743.jpg, Loss_G: 3.9096, Loss_D_A: 0.2307, Loss_D_B: 0.2168\n",
            "Epoch 31/60, Batch 4/19, Image: rainy_931.jpg, Loss_G: 3.1034, Loss_D_A: 0.2147, Loss_D_B: 0.1704\n",
            "Epoch 31/60, Batch 5/19, Image: rainy_259.jpg, Loss_G: 3.2145, Loss_D_A: 0.1689, Loss_D_B: 0.1468\n",
            "Epoch 31/60, Batch 6/19, Image: rainy_1196.jpg, Loss_G: 2.9706, Loss_D_A: 0.1921, Loss_D_B: 0.1813\n",
            "Epoch 31/60, Batch 7/19, Image: rainy_378.jpg, Loss_G: 3.9327, Loss_D_A: 0.1847, Loss_D_B: 0.1877\n",
            "Epoch 31/60, Batch 8/19, Image: rainy_837.jpg, Loss_G: 2.6451, Loss_D_A: 0.2048, Loss_D_B: 0.1384\n",
            "Epoch 31/60, Batch 9/19, Image: rainy_262.jpg, Loss_G: 3.1073, Loss_D_A: 0.2176, Loss_D_B: 0.1560\n",
            "Epoch 31/60, Batch 10/19, Image: rainy_716.jpg, Loss_G: 3.5884, Loss_D_A: 0.2338, Loss_D_B: 0.1717\n",
            "Epoch 31/60, Batch 11/19, Image: rainy_1086.jpg, Loss_G: 2.5417, Loss_D_A: 0.2236, Loss_D_B: 0.1613\n",
            "Epoch 31/60, Batch 12/19, Image: rainy_802.jpg, Loss_G: 2.7477, Loss_D_A: 0.2349, Loss_D_B: 0.2371\n",
            "Epoch 31/60, Batch 13/19, Image: rainy_356.jpg, Loss_G: 2.6599, Loss_D_A: 0.1871, Loss_D_B: 0.1645\n",
            "Epoch 31/60, Batch 14/19, Image: rainy_1160.jpg, Loss_G: 2.9142, Loss_D_A: 0.2066, Loss_D_B: 0.1473\n",
            "Epoch 31/60, Batch 15/19, Image: rainy_736.jpg, Loss_G: 2.8681, Loss_D_A: 0.2418, Loss_D_B: 0.2238\n",
            "Epoch 31/60, Batch 16/19, Image: rainy_706.jpg, Loss_G: 3.2456, Loss_D_A: 0.2108, Loss_D_B: 0.1907\n",
            "Epoch 31/60, Batch 17/19, Image: rainy_1062.jpg, Loss_G: 3.2812, Loss_D_A: 0.1574, Loss_D_B: 0.1536\n",
            "Epoch 31/60, Batch 18/19, Image: rainy_741.jpg, Loss_G: 3.0440, Loss_D_A: 0.3677, Loss_D_B: 0.4231\n",
            "Epoch 32/60, Batch 0/19, Image: rainy_432.jpg, Loss_G: 2.9637, Loss_D_A: 0.2330, Loss_D_B: 0.2037\n",
            "Epoch 32/60, Batch 1/19, Image: rainy_785.jpg, Loss_G: 2.6580, Loss_D_A: 0.2090, Loss_D_B: 0.2192\n",
            "Epoch 32/60, Batch 2/19, Image: rainy_97.jpg, Loss_G: 4.2040, Loss_D_A: 0.2545, Loss_D_B: 0.2092\n",
            "Epoch 32/60, Batch 3/19, Image: rainy_414.jpg, Loss_G: 3.2147, Loss_D_A: 0.2024, Loss_D_B: 0.1715\n",
            "Epoch 32/60, Batch 4/19, Image: rainy_671.jpg, Loss_G: 3.1296, Loss_D_A: 0.1657, Loss_D_B: 0.1682\n",
            "Epoch 32/60, Batch 5/19, Image: rainy_868.jpg, Loss_G: 2.9830, Loss_D_A: 0.1822, Loss_D_B: 0.2021\n",
            "Epoch 32/60, Batch 6/19, Image: rainy_1006.jpg, Loss_G: 3.0957, Loss_D_A: 0.1520, Loss_D_B: 0.1968\n",
            "Epoch 32/60, Batch 7/19, Image: rainy_1110.jpg, Loss_G: 2.8276, Loss_D_A: 0.2339, Loss_D_B: 0.2801\n",
            "Epoch 32/60, Batch 8/19, Image: rainy_657.jpg, Loss_G: 2.6663, Loss_D_A: 0.2251, Loss_D_B: 0.2210\n",
            "Epoch 32/60, Batch 9/19, Image: rainy_744.jpg, Loss_G: 3.7896, Loss_D_A: 0.2094, Loss_D_B: 0.1929\n",
            "Epoch 32/60, Batch 10/19, Image: rainy_167.jpg, Loss_G: 3.5324, Loss_D_A: 0.2325, Loss_D_B: 0.2141\n",
            "Epoch 32/60, Batch 11/19, Image: rainy_1117.jpg, Loss_G: 3.1039, Loss_D_A: 0.2261, Loss_D_B: 0.1936\n",
            "Epoch 32/60, Batch 12/19, Image: rainy_319.jpg, Loss_G: 3.8255, Loss_D_A: 0.2829, Loss_D_B: 0.2988\n",
            "Epoch 32/60, Batch 13/19, Image: rainy_1118.jpg, Loss_G: 3.8388, Loss_D_A: 0.2206, Loss_D_B: 0.1895\n",
            "Epoch 32/60, Batch 14/19, Image: rainy_1058.jpg, Loss_G: 3.9463, Loss_D_A: 0.1716, Loss_D_B: 0.1193\n",
            "Epoch 32/60, Batch 15/19, Image: rainy_214.jpg, Loss_G: 3.0957, Loss_D_A: 0.2535, Loss_D_B: 0.2164\n",
            "Epoch 32/60, Batch 16/19, Image: rainy_756.jpg, Loss_G: 3.1422, Loss_D_A: 0.2505, Loss_D_B: 0.2552\n",
            "Epoch 32/60, Batch 17/19, Image: rainy_482.jpg, Loss_G: 2.9814, Loss_D_A: 0.1874, Loss_D_B: 0.1892\n",
            "Epoch 32/60, Batch 18/19, Image: rainy_237.jpg, Loss_G: 3.5183, Loss_D_A: 0.1749, Loss_D_B: 0.1746\n",
            "Epoch 33/60, Batch 0/19, Image: rainy_706.jpg, Loss_G: 2.7149, Loss_D_A: 0.1964, Loss_D_B: 0.1702\n",
            "Epoch 33/60, Batch 1/19, Image: rainy_910.jpg, Loss_G: 2.5915, Loss_D_A: 0.1885, Loss_D_B: 0.1552\n",
            "Epoch 33/60, Batch 2/19, Image: rainy_122.jpg, Loss_G: 4.0561, Loss_D_A: 0.2020, Loss_D_B: 0.1828\n",
            "Epoch 33/60, Batch 3/19, Image: rainy_271.jpg, Loss_G: 2.5170, Loss_D_A: 0.2097, Loss_D_B: 0.1954\n",
            "Epoch 33/60, Batch 4/19, Image: rainy_1157.jpg, Loss_G: 2.9046, Loss_D_A: 0.1799, Loss_D_B: 0.1487\n",
            "Epoch 33/60, Batch 5/19, Image: rainy_463.jpg, Loss_G: 2.5095, Loss_D_A: 0.2571, Loss_D_B: 0.2420\n",
            "Epoch 33/60, Batch 6/19, Image: rainy_633.jpg, Loss_G: 4.5509, Loss_D_A: 0.2136, Loss_D_B: 0.1748\n",
            "Epoch 33/60, Batch 7/19, Image: rainy_215.jpg, Loss_G: 3.2378, Loss_D_A: 0.2122, Loss_D_B: 0.1907\n",
            "Epoch 33/60, Batch 8/19, Image: rainy_355.jpg, Loss_G: 3.6525, Loss_D_A: 0.1973, Loss_D_B: 0.1834\n",
            "Epoch 33/60, Batch 9/19, Image: rainy_785.jpg, Loss_G: 2.7580, Loss_D_A: 0.2055, Loss_D_B: 0.1964\n",
            "Epoch 33/60, Batch 10/19, Image: rainy_951.jpg, Loss_G: 2.7674, Loss_D_A: 0.1625, Loss_D_B: 0.1451\n",
            "Epoch 33/60, Batch 11/19, Image: rainy_74.jpg, Loss_G: 2.7934, Loss_D_A: 0.1865, Loss_D_B: 0.2101\n",
            "Epoch 33/60, Batch 12/19, Image: rainy_1058.jpg, Loss_G: 2.6448, Loss_D_A: 0.1860, Loss_D_B: 0.1731\n",
            "Epoch 33/60, Batch 13/19, Image: rainy_780.jpg, Loss_G: 2.3832, Loss_D_A: 0.1984, Loss_D_B: 0.1888\n",
            "Epoch 33/60, Batch 14/19, Image: rainy_868.jpg, Loss_G: 3.9321, Loss_D_A: 0.2066, Loss_D_B: 0.1771\n",
            "Epoch 33/60, Batch 15/19, Image: rainy_1006.jpg, Loss_G: 2.8969, Loss_D_A: 0.2529, Loss_D_B: 0.2170\n",
            "Epoch 33/60, Batch 16/19, Image: rainy_851.jpg, Loss_G: 3.1914, Loss_D_A: 0.2532, Loss_D_B: 0.2237\n",
            "Epoch 33/60, Batch 17/19, Image: rainy_119.jpg, Loss_G: 3.7108, Loss_D_A: 0.2991, Loss_D_B: 0.2856\n",
            "Epoch 33/60, Batch 18/19, Image: rainy_69.jpg, Loss_G: 3.0209, Loss_D_A: 0.1624, Loss_D_B: 0.1248\n",
            "Epoch 34/60, Batch 0/19, Image: rainy_1047.jpg, Loss_G: 3.0938, Loss_D_A: 0.2614, Loss_D_B: 0.2308\n",
            "Epoch 34/60, Batch 1/19, Image: rainy_907.jpg, Loss_G: 3.2324, Loss_D_A: 0.2678, Loss_D_B: 0.2382\n",
            "Epoch 34/60, Batch 2/19, Image: rainy_167.jpg, Loss_G: 2.9487, Loss_D_A: 0.1601, Loss_D_B: 0.1036\n",
            "Epoch 34/60, Batch 3/19, Image: rainy_119.jpg, Loss_G: 2.6474, Loss_D_A: 0.2459, Loss_D_B: 0.2238\n",
            "Epoch 34/60, Batch 4/19, Image: rainy_671.jpg, Loss_G: 3.2627, Loss_D_A: 0.2205, Loss_D_B: 0.2056\n",
            "Epoch 34/60, Batch 5/19, Image: rainy_706.jpg, Loss_G: 2.7734, Loss_D_A: 0.1801, Loss_D_B: 0.1618\n",
            "Epoch 34/60, Batch 6/19, Image: rainy_164.jpg, Loss_G: 2.9960, Loss_D_A: 0.2076, Loss_D_B: 0.1821\n",
            "Epoch 34/60, Batch 7/19, Image: rainy_404.jpg, Loss_G: 2.2636, Loss_D_A: 0.2090, Loss_D_B: 0.1994\n",
            "Epoch 34/60, Batch 8/19, Image: rainy_804.jpg, Loss_G: 3.3568, Loss_D_A: 0.2034, Loss_D_B: 0.1755\n",
            "Epoch 34/60, Batch 9/19, Image: rainy_716.jpg, Loss_G: 3.6663, Loss_D_A: 0.1514, Loss_D_B: 0.1885\n",
            "Epoch 34/60, Batch 10/19, Image: rainy_1145.jpg, Loss_G: 3.3548, Loss_D_A: 0.1447, Loss_D_B: 0.1979\n",
            "Epoch 34/60, Batch 11/19, Image: rainy_567.jpg, Loss_G: 2.6412, Loss_D_A: 0.1930, Loss_D_B: 0.1847\n",
            "Epoch 34/60, Batch 12/19, Image: rainy_1118.jpg, Loss_G: 3.4588, Loss_D_A: 0.1799, Loss_D_B: 0.1434\n",
            "Epoch 34/60, Batch 13/19, Image: rainy_968.jpg, Loss_G: 2.7301, Loss_D_A: 0.1947, Loss_D_B: 0.1990\n",
            "Epoch 34/60, Batch 14/19, Image: rainy_65.jpg, Loss_G: 2.4450, Loss_D_A: 0.2608, Loss_D_B: 0.2435\n",
            "Epoch 34/60, Batch 15/19, Image: rainy_54.jpg, Loss_G: 2.6587, Loss_D_A: 0.1776, Loss_D_B: 0.1561\n",
            "Epoch 34/60, Batch 16/19, Image: rainy_934.jpg, Loss_G: 2.6281, Loss_D_A: 0.2362, Loss_D_B: 0.2164\n",
            "Epoch 34/60, Batch 17/19, Image: rainy_1059.jpg, Loss_G: 2.9450, Loss_D_A: 0.2670, Loss_D_B: 0.2451\n",
            "Epoch 34/60, Batch 18/19, Image: rainy_349.jpg, Loss_G: 3.3929, Loss_D_A: 0.1559, Loss_D_B: 0.1385\n",
            "Epoch 35/60, Batch 0/19, Image: rainy_804.jpg, Loss_G: 3.3153, Loss_D_A: 0.2420, Loss_D_B: 0.1894\n",
            "Epoch 35/60, Batch 1/19, Image: rainy_689.jpg, Loss_G: 2.9936, Loss_D_A: 0.1433, Loss_D_B: 0.1660\n",
            "Epoch 35/60, Batch 2/19, Image: rainy_1171.jpg, Loss_G: 3.4499, Loss_D_A: 0.2291, Loss_D_B: 0.2686\n",
            "Epoch 35/60, Batch 3/19, Image: rainy_780.jpg, Loss_G: 2.5013, Loss_D_A: 0.2468, Loss_D_B: 0.2494\n",
            "Epoch 35/60, Batch 4/19, Image: rainy_638.jpg, Loss_G: 2.5813, Loss_D_A: 0.2391, Loss_D_B: 0.1995\n",
            "Epoch 35/60, Batch 5/19, Image: rainy_324.jpg, Loss_G: 3.3282, Loss_D_A: 0.1898, Loss_D_B: 0.1273\n",
            "Epoch 35/60, Batch 6/19, Image: rainy_1054.jpg, Loss_G: 2.6017, Loss_D_A: 0.2380, Loss_D_B: 0.2013\n",
            "Epoch 35/60, Batch 7/19, Image: rainy_756.jpg, Loss_G: 3.1925, Loss_D_A: 0.2401, Loss_D_B: 0.2232\n",
            "Epoch 35/60, Batch 8/19, Image: rainy_138.jpg, Loss_G: 3.4674, Loss_D_A: 0.1702, Loss_D_B: 0.1536\n",
            "Epoch 35/60, Batch 9/19, Image: rainy_567.jpg, Loss_G: 2.5387, Loss_D_A: 0.1827, Loss_D_B: 0.1543\n",
            "Epoch 35/60, Batch 10/19, Image: rainy_593.jpg, Loss_G: 2.5712, Loss_D_A: 0.2297, Loss_D_B: 0.2411\n",
            "Epoch 35/60, Batch 11/19, Image: rainy_633.jpg, Loss_G: 2.4395, Loss_D_A: 0.2355, Loss_D_B: 0.2105\n",
            "Epoch 35/60, Batch 12/19, Image: rainy_680.jpg, Loss_G: 2.9273, Loss_D_A: 0.2108, Loss_D_B: 0.1797\n",
            "Epoch 35/60, Batch 13/19, Image: rainy_536.jpg, Loss_G: 3.1716, Loss_D_A: 0.1588, Loss_D_B: 0.1381\n",
            "Epoch 35/60, Batch 14/19, Image: rainy_271.jpg, Loss_G: 3.1760, Loss_D_A: 0.2057, Loss_D_B: 0.1806\n",
            "Epoch 35/60, Batch 15/19, Image: rainy_1190.jpg, Loss_G: 2.6857, Loss_D_A: 0.2371, Loss_D_B: 0.1914\n",
            "Epoch 35/60, Batch 16/19, Image: rainy_145.jpg, Loss_G: 4.6740, Loss_D_A: 0.2256, Loss_D_B: 0.2149\n",
            "Epoch 35/60, Batch 17/19, Image: rainy_744.jpg, Loss_G: 3.2065, Loss_D_A: 0.1888, Loss_D_B: 0.1544\n",
            "Epoch 35/60, Batch 18/19, Image: rainy_181.jpg, Loss_G: 5.4160, Loss_D_A: 0.2596, Loss_D_B: 0.2708\n",
            "Epoch 36/60, Batch 0/19, Image: rainy_689.jpg, Loss_G: 3.6730, Loss_D_A: 0.2350, Loss_D_B: 0.2399\n",
            "Epoch 36/60, Batch 1/19, Image: rainy_374.jpg, Loss_G: 3.0606, Loss_D_A: 0.1868, Loss_D_B: 0.1620\n",
            "Epoch 36/60, Batch 2/19, Image: rainy_680.jpg, Loss_G: 2.9451, Loss_D_A: 0.1833, Loss_D_B: 0.1676\n",
            "Epoch 36/60, Batch 3/19, Image: rainy_468.jpg, Loss_G: 3.8025, Loss_D_A: 0.2131, Loss_D_B: 0.1839\n",
            "Epoch 36/60, Batch 4/19, Image: rainy_432.jpg, Loss_G: 3.5720, Loss_D_A: 0.2872, Loss_D_B: 0.2256\n",
            "Epoch 36/60, Batch 5/19, Image: rainy_277.jpg, Loss_G: 3.4010, Loss_D_A: 0.2265, Loss_D_B: 0.1913\n",
            "Epoch 36/60, Batch 6/19, Image: rainy_785.jpg, Loss_G: 2.9491, Loss_D_A: 0.2149, Loss_D_B: 0.2008\n",
            "Epoch 36/60, Batch 7/19, Image: rainy_520.jpg, Loss_G: 3.8696, Loss_D_A: 0.1873, Loss_D_B: 0.1793\n",
            "Epoch 36/60, Batch 8/19, Image: rainy_742.jpg, Loss_G: 2.9244, Loss_D_A: 0.1997, Loss_D_B: 0.1586\n",
            "Epoch 36/60, Batch 9/19, Image: rainy_743.jpg, Loss_G: 2.8937, Loss_D_A: 0.1614, Loss_D_B: 0.1230\n",
            "Epoch 36/60, Batch 10/19, Image: rainy_164.jpg, Loss_G: 2.4599, Loss_D_A: 0.2321, Loss_D_B: 0.1948\n",
            "Epoch 36/60, Batch 11/19, Image: rainy_237.jpg, Loss_G: 3.1824, Loss_D_A: 0.1781, Loss_D_B: 0.1390\n",
            "Epoch 36/60, Batch 12/19, Image: rainy_1059.jpg, Loss_G: 3.2322, Loss_D_A: 0.1261, Loss_D_B: 0.1430\n",
            "Epoch 36/60, Batch 13/19, Image: rainy_1092.jpg, Loss_G: 4.0089, Loss_D_A: 0.1088, Loss_D_B: 0.1522\n",
            "Epoch 36/60, Batch 14/19, Image: rainy_54.jpg, Loss_G: 3.5911, Loss_D_A: 0.1074, Loss_D_B: 0.1657\n",
            "Epoch 36/60, Batch 15/19, Image: rainy_599.jpg, Loss_G: 2.7673, Loss_D_A: 0.1845, Loss_D_B: 0.2409\n",
            "Epoch 36/60, Batch 16/19, Image: rainy_706.jpg, Loss_G: 2.8495, Loss_D_A: 0.1041, Loss_D_B: 0.0903\n",
            "Epoch 36/60, Batch 17/19, Image: rainy_1066.jpg, Loss_G: 2.6142, Loss_D_A: 0.2318, Loss_D_B: 0.1913\n",
            "Epoch 36/60, Batch 18/19, Image: rainy_611.jpg, Loss_G: 4.1384, Loss_D_A: 0.2213, Loss_D_B: 0.1544\n",
            "Epoch 37/60, Batch 0/19, Image: rainy_1110.jpg, Loss_G: 3.3297, Loss_D_A: 0.2391, Loss_D_B: 0.1437\n",
            "Epoch 37/60, Batch 1/19, Image: rainy_644.jpg, Loss_G: 2.8980, Loss_D_A: 0.3399, Loss_D_B: 0.1692\n",
            "Epoch 37/60, Batch 2/19, Image: rainy_706.jpg, Loss_G: 2.7604, Loss_D_A: 0.2166, Loss_D_B: 0.1463\n",
            "Epoch 37/60, Batch 3/19, Image: rainy_1189.jpg, Loss_G: 3.5289, Loss_D_A: 0.2166, Loss_D_B: 0.1732\n",
            "Epoch 37/60, Batch 4/19, Image: rainy_785.jpg, Loss_G: 3.0705, Loss_D_A: 0.1498, Loss_D_B: 0.1008\n",
            "Epoch 37/60, Batch 5/19, Image: rainy_319.jpg, Loss_G: 2.9820, Loss_D_A: 0.2426, Loss_D_B: 0.2941\n",
            "Epoch 37/60, Batch 6/19, Image: rainy_80.jpg, Loss_G: 3.1441, Loss_D_A: 0.2115, Loss_D_B: 0.2073\n",
            "Epoch 37/60, Batch 7/19, Image: rainy_951.jpg, Loss_G: 2.8539, Loss_D_A: 0.1576, Loss_D_B: 0.1644\n",
            "Epoch 37/60, Batch 8/19, Image: rainy_1183.jpg, Loss_G: 3.0497, Loss_D_A: 0.1353, Loss_D_B: 0.1205\n",
            "Epoch 37/60, Batch 9/19, Image: rainy_181.jpg, Loss_G: 3.4102, Loss_D_A: 0.1899, Loss_D_B: 0.1956\n",
            "Epoch 37/60, Batch 10/19, Image: rainy_1171.jpg, Loss_G: 2.7539, Loss_D_A: 0.1773, Loss_D_B: 0.1640\n",
            "Epoch 37/60, Batch 11/19, Image: rainy_694.jpg, Loss_G: 3.0959, Loss_D_A: 0.2154, Loss_D_B: 0.1993\n",
            "Epoch 37/60, Batch 12/19, Image: rainy_708.jpg, Loss_G: 2.5558, Loss_D_A: 0.3169, Loss_D_B: 0.3250\n",
            "Epoch 37/60, Batch 13/19, Image: rainy_54.jpg, Loss_G: 3.5030, Loss_D_A: 0.1558, Loss_D_B: 0.2021\n",
            "Epoch 37/60, Batch 14/19, Image: rainy_75.jpg, Loss_G: 2.9210, Loss_D_A: 0.1664, Loss_D_B: 0.2163\n",
            "Epoch 37/60, Batch 15/19, Image: rainy_907.jpg, Loss_G: 4.1591, Loss_D_A: 0.2125, Loss_D_B: 0.3079\n",
            "Epoch 37/60, Batch 16/19, Image: rainy_101.jpg, Loss_G: 3.7684, Loss_D_A: 0.2061, Loss_D_B: 0.3623\n",
            "Epoch 37/60, Batch 17/19, Image: rainy_123.jpg, Loss_G: 2.7966, Loss_D_A: 0.2327, Loss_D_B: 0.2888\n",
            "Epoch 37/60, Batch 18/19, Image: rainy_536.jpg, Loss_G: 4.0423, Loss_D_A: 0.1726, Loss_D_B: 0.1709\n",
            "Epoch 38/60, Batch 0/19, Image: rainy_101.jpg, Loss_G: 3.0857, Loss_D_A: 0.1450, Loss_D_B: 0.1508\n",
            "Epoch 38/60, Batch 1/19, Image: rainy_378.jpg, Loss_G: 2.8758, Loss_D_A: 0.1664, Loss_D_B: 0.1743\n",
            "Epoch 38/60, Batch 2/19, Image: rainy_145.jpg, Loss_G: 2.9551, Loss_D_A: 0.1980, Loss_D_B: 0.1986\n",
            "Epoch 38/60, Batch 3/19, Image: rainy_148.jpg, Loss_G: 4.3342, Loss_D_A: 0.1707, Loss_D_B: 0.1448\n",
            "Epoch 38/60, Batch 4/19, Image: rainy_432.jpg, Loss_G: 2.9340, Loss_D_A: 0.2771, Loss_D_B: 0.2665\n",
            "Epoch 38/60, Batch 5/19, Image: rainy_671.jpg, Loss_G: 3.3655, Loss_D_A: 0.1660, Loss_D_B: 0.1660\n",
            "Epoch 38/60, Batch 6/19, Image: rainy_122.jpg, Loss_G: 2.6162, Loss_D_A: 0.2038, Loss_D_B: 0.1857\n",
            "Epoch 38/60, Batch 7/19, Image: rainy_930.jpg, Loss_G: 3.1445, Loss_D_A: 0.1710, Loss_D_B: 0.1476\n",
            "Epoch 38/60, Batch 8/19, Image: rainy_942.jpg, Loss_G: 3.1397, Loss_D_A: 0.1950, Loss_D_B: 0.1798\n",
            "Epoch 38/60, Batch 9/19, Image: rainy_74.jpg, Loss_G: 2.9199, Loss_D_A: 0.2287, Loss_D_B: 0.1847\n",
            "Epoch 38/60, Batch 10/19, Image: rainy_638.jpg, Loss_G: 2.6760, Loss_D_A: 0.2054, Loss_D_B: 0.1478\n",
            "Epoch 38/60, Batch 11/19, Image: rainy_1141.jpg, Loss_G: 3.0057, Loss_D_A: 0.2186, Loss_D_B: 0.1494\n",
            "Epoch 38/60, Batch 12/19, Image: rainy_214.jpg, Loss_G: 3.2356, Loss_D_A: 0.1927, Loss_D_B: 0.1385\n",
            "Epoch 38/60, Batch 13/19, Image: rainy_277.jpg, Loss_G: 2.5167, Loss_D_A: 0.1953, Loss_D_B: 0.1707\n",
            "Epoch 38/60, Batch 14/19, Image: rainy_78.jpg, Loss_G: 2.7679, Loss_D_A: 0.2035, Loss_D_B: 0.2356\n",
            "Epoch 38/60, Batch 15/19, Image: rainy_804.jpg, Loss_G: 2.7729, Loss_D_A: 0.1586, Loss_D_B: 0.1461\n",
            "Epoch 38/60, Batch 16/19, Image: rainy_1033.jpg, Loss_G: 3.8286, Loss_D_A: 0.2270, Loss_D_B: 0.2257\n",
            "Epoch 38/60, Batch 17/19, Image: rainy_1117.jpg, Loss_G: 3.2148, Loss_D_A: 0.1845, Loss_D_B: 0.1778\n",
            "Epoch 38/60, Batch 18/19, Image: rainy_1055.jpg, Loss_G: 3.3348, Loss_D_A: 0.1501, Loss_D_B: 0.1662\n",
            "Epoch 39/60, Batch 0/19, Image: rainy_271.jpg, Loss_G: 4.1409, Loss_D_A: 0.2063, Loss_D_B: 0.1946\n",
            "Epoch 39/60, Batch 1/19, Image: rainy_1047.jpg, Loss_G: 4.1940, Loss_D_A: 0.1689, Loss_D_B: 0.2176\n",
            "Epoch 39/60, Batch 2/19, Image: rainy_83.jpg, Loss_G: 3.5013, Loss_D_A: 0.1676, Loss_D_B: 0.1512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "class AutoencoderWithSkipConnections(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(AutoencoderWithSkipConnections, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder1 = nn.Sequential(\n",
        "            nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.encoder2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.encoder3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.decoder2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256 + 256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.decoder3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128 + 128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.decoder4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64 + 64, input_nc, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        b = self.bottleneck(e3)\n",
        "        d1 = self.decoder1(b)\n",
        "        d2 = self.decoder2(torch.cat([d1, e3], dim=1))\n",
        "        d3 = self.decoder3(torch.cat([d2, e2], dim=1))\n",
        "        d4 = self.decoder4(torch.cat([d3, e1], dim=1))\n",
        "        return d4\n",
        "\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        vgg19 = models.vgg19(pretrained=True).features[:16].eval()\n",
        "        for param in vgg19.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.vgg19 = vgg19\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x_features = self.vgg19(x)\n",
        "        y_features = self.vgg19(y)\n",
        "        return self.criterion(x_features, y_features)\n",
        "\n",
        "# Initialize Autoencoder\n",
        "input_channels = 3\n",
        "autoencoder = AutoencoderWithSkipConnections(input_channels).cuda()\n",
        "\n",
        "# Define Loss and Optimizer\n",
        "mse_loss = nn.MSELoss()\n",
        "perceptual_loss = PerceptualLoss().cuda()\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0002)\n",
        "\n",
        "# Load GAN-generated images\n",
        "gan_output_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/Split-DID-MDN/results_6\"\n",
        "rainy_images = [f for f in os.listdir(gan_output_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "def load_images(image_list, root_path):\n",
        "    images = []\n",
        "    filenames = []\n",
        "    for img_name in image_list:\n",
        "        img_path = os.path.join(root_path, img_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img = transforms.ToTensor()(img)\n",
        "        images.append(img)\n",
        "        filenames.append(img_name)\n",
        "    return torch.stack(images), filenames\n",
        "\n",
        "train_data, train_filenames = load_images(rainy_images, gan_output_path)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "\n",
        "# Train the autoencoder\n",
        "epochs = 60\n",
        "final_epoch_reconstructions = {}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i, images in enumerate(train_loader):\n",
        "        images = images.cuda()\n",
        "        reconstructed = autoencoder(images)\n",
        "        mse_loss_value = mse_loss(reconstructed, images)\n",
        "        perceptual_loss_value = perceptual_loss(reconstructed, images)\n",
        "        total_loss = mse_loss_value + 0.01 * perceptual_loss_value\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch == epochs - 1:\n",
        "            batch_filenames = train_filenames[i * 16:(i + 1) * 16]\n",
        "            for j, filename in enumerate(batch_filenames):\n",
        "                final_epoch_reconstructions[filename] = reconstructed[j].unsqueeze(0)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], MSE Loss: {mse_loss_value.item()}, Perceptual Loss: {perceptual_loss_value.item()}\")\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/reconstructed_autoencoder_8\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for filename, reconstructed_image in final_epoch_reconstructions.items():\n",
        "    save_path = os.path.join(output_dir, f\"{filename.split('.')[0]}_refined.png\")\n",
        "    save_image(reconstructed_image, save_path)\n",
        "    # print(f\"Saved: {save_path}\")\n",
        "\n",
        "print(\"Autoencoder training completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1zt2fj3gM2Q",
        "outputId": "acaa4210-2fb2-42d2-c9d6-1816220afed8",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/60], MSE Loss: 0.20659932494163513, Perceptual Loss: 4.693155765533447\n",
            "Epoch [2/60], MSE Loss: 0.13648764789104462, Perceptual Loss: 2.8803763389587402\n",
            "Epoch [3/60], MSE Loss: 0.055457036942243576, Perceptual Loss: 3.4117679595947266\n",
            "Epoch [4/60], MSE Loss: 0.03448586165904999, Perceptual Loss: 2.597916841506958\n",
            "Epoch [5/60], MSE Loss: 0.019618110731244087, Perceptual Loss: 2.0173041820526123\n",
            "Epoch [6/60], MSE Loss: 0.018136020749807358, Perceptual Loss: 1.9500073194503784\n",
            "Epoch [7/60], MSE Loss: 0.017502862960100174, Perceptual Loss: 2.065246343612671\n",
            "Epoch [8/60], MSE Loss: 0.012627768330276012, Perceptual Loss: 1.7568596601486206\n",
            "Epoch [9/60], MSE Loss: 0.015493995510041714, Perceptual Loss: 1.8104727268218994\n",
            "Epoch [10/60], MSE Loss: 0.009665400721132755, Perceptual Loss: 1.7112977504730225\n",
            "Epoch [11/60], MSE Loss: 0.01640314981341362, Perceptual Loss: 1.7680519819259644\n",
            "Epoch [12/60], MSE Loss: 0.009533348493278027, Perceptual Loss: 1.5512104034423828\n",
            "Epoch [13/60], MSE Loss: 0.005541055463254452, Perceptual Loss: 0.8820416331291199\n",
            "Epoch [14/60], MSE Loss: 0.0055077034048736095, Perceptual Loss: 0.7968869805335999\n",
            "Epoch [15/60], MSE Loss: 0.004622092470526695, Perceptual Loss: 0.759538471698761\n",
            "Epoch [16/60], MSE Loss: 0.0038308892399072647, Perceptual Loss: 0.6292638778686523\n",
            "Epoch [17/60], MSE Loss: 0.0037139817140996456, Perceptual Loss: 0.5902756452560425\n",
            "Epoch [18/60], MSE Loss: 0.0029342479538172483, Perceptual Loss: 0.45370107889175415\n",
            "Epoch [19/60], MSE Loss: 0.005013981834053993, Perceptual Loss: 0.5413772463798523\n",
            "Epoch [20/60], MSE Loss: 0.004439244046807289, Perceptual Loss: 0.5431703329086304\n",
            "Epoch [21/60], MSE Loss: 0.00273955799639225, Perceptual Loss: 0.3937968611717224\n",
            "Epoch [22/60], MSE Loss: 0.003814912401139736, Perceptual Loss: 0.47905880212783813\n",
            "Epoch [23/60], MSE Loss: 0.004132146015763283, Perceptual Loss: 0.4747270941734314\n",
            "Epoch [24/60], MSE Loss: 0.002236640080809593, Perceptual Loss: 0.25027143955230713\n",
            "Epoch [25/60], MSE Loss: 0.002851975616067648, Perceptual Loss: 0.454629123210907\n",
            "Epoch [26/60], MSE Loss: 0.003297109855338931, Perceptual Loss: 0.36281442642211914\n",
            "Epoch [27/60], MSE Loss: 0.002578472951427102, Perceptual Loss: 0.4391448497772217\n",
            "Epoch [28/60], MSE Loss: 0.002859153551980853, Perceptual Loss: 0.3869593143463135\n",
            "Epoch [29/60], MSE Loss: 0.00118316023144871, Perceptual Loss: 0.22110667824745178\n",
            "Epoch [30/60], MSE Loss: 0.0033460427075624466, Perceptual Loss: 0.4911496639251709\n",
            "Epoch [31/60], MSE Loss: 0.0018893703818321228, Perceptual Loss: 0.32124626636505127\n",
            "Epoch [32/60], MSE Loss: 0.0019247474847361445, Perceptual Loss: 0.3062567114830017\n",
            "Epoch [33/60], MSE Loss: 0.0015052406815811992, Perceptual Loss: 0.28698837757110596\n",
            "Epoch [34/60], MSE Loss: 0.0025431730318814516, Perceptual Loss: 0.3338863253593445\n",
            "Epoch [35/60], MSE Loss: 0.0016384597402065992, Perceptual Loss: 0.2832149565219879\n",
            "Epoch [36/60], MSE Loss: 0.0017536850646138191, Perceptual Loss: 0.24379503726959229\n",
            "Epoch [37/60], MSE Loss: 0.003454318270087242, Perceptual Loss: 0.41995108127593994\n",
            "Epoch [38/60], MSE Loss: 0.0018560810713097453, Perceptual Loss: 0.285010427236557\n",
            "Epoch [39/60], MSE Loss: 0.0017514058854430914, Perceptual Loss: 0.2832863926887512\n",
            "Epoch [40/60], MSE Loss: 0.0019001639448106289, Perceptual Loss: 0.28256672620773315\n",
            "Epoch [41/60], MSE Loss: 0.0014614638639613986, Perceptual Loss: 0.22794413566589355\n",
            "Epoch [42/60], MSE Loss: 0.0013234536163508892, Perceptual Loss: 0.23501545190811157\n",
            "Epoch [43/60], MSE Loss: 0.0013528948184102774, Perceptual Loss: 0.18943946063518524\n",
            "Epoch [44/60], MSE Loss: 0.0008074257057160139, Perceptual Loss: 0.19035369157791138\n",
            "Epoch [45/60], MSE Loss: 0.0008402959210798144, Perceptual Loss: 0.159245103597641\n",
            "Epoch [46/60], MSE Loss: 0.0010546629782766104, Perceptual Loss: 0.22574442625045776\n",
            "Epoch [47/60], MSE Loss: 0.0027680406346917152, Perceptual Loss: 0.3165283799171448\n",
            "Epoch [48/60], MSE Loss: 0.001119640888646245, Perceptual Loss: 0.2072097659111023\n",
            "Epoch [49/60], MSE Loss: 0.002034649020060897, Perceptual Loss: 0.26019391417503357\n",
            "Epoch [50/60], MSE Loss: 0.0007398693705908954, Perceptual Loss: 0.15640151500701904\n",
            "Epoch [51/60], MSE Loss: 0.0008769318228587508, Perceptual Loss: 0.16544824838638306\n",
            "Epoch [52/60], MSE Loss: 0.0014057498192414641, Perceptual Loss: 0.22651073336601257\n",
            "Epoch [53/60], MSE Loss: 0.0017097200034186244, Perceptual Loss: 0.24588200449943542\n",
            "Epoch [54/60], MSE Loss: 0.0012288469588384032, Perceptual Loss: 0.207509845495224\n",
            "Epoch [55/60], MSE Loss: 0.0010296443942934275, Perceptual Loss: 0.19393953680992126\n",
            "Epoch [56/60], MSE Loss: 0.0009782937122508883, Perceptual Loss: 0.19040121138095856\n",
            "Epoch [57/60], MSE Loss: 0.0007700698333792388, Perceptual Loss: 0.1506158709526062\n",
            "Epoch [58/60], MSE Loss: 0.0012606572126969695, Perceptual Loss: 0.18608978390693665\n",
            "Epoch [59/60], MSE Loss: 0.0010409040842205286, Perceptual Loss: 0.19235458970069885\n",
            "Epoch [60/60], MSE Loss: 0.0008364042732864618, Perceptual Loss: 0.1620998978614807\n",
            "Autoencoder training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Reconstruction Loss Function\n",
        "class ReconstructionLoss(nn.Module):\n",
        "    def __init__(self, autoencoder, criterion=nn.MSELoss()):\n",
        "        super(ReconstructionLoss, self).__init__()\n",
        "        self.autoencoder = autoencoder\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def forward(self, input_image, target_image):\n",
        "        \"\"\"\n",
        "        Compute the reconstruction loss between the autoencoder output and target image.\n",
        "\n",
        "        Args:\n",
        "        input_image (torch.Tensor): The image generated by the GAN.\n",
        "        target_image (torch.Tensor): The original clean image.\n",
        "\n",
        "        Returns:\n",
        "        loss (torch.Tensor): The reconstruction loss value.\n",
        "        \"\"\"\n",
        "        refined_image = self.autoencoder(input_image)\n",
        "        loss = self.criterion(refined_image, target_image)\n",
        "        return loss, refined_image\n",
        "\n",
        "# Example Usage\n",
        "# Assuming `autoencoder`, `gan_output`, and `clean_target` are available\n",
        "reconstruction_loss_fn = ReconstructionLoss(autoencoder=autoencoder)\n",
        "loss_reconstruction, refined_image = reconstruction_loss_fn(gan_output, clean_target)\n",
        "\n",
        "print(f\"Reconstruction Loss: {loss_reconstruction.item()}\")\n"
      ],
      "metadata": {
        "id": "89mTwfsno6rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg19\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        self.vgg = vgg19(pretrained=True).features[:16].eval().cuda()\n",
        "        for param in self.vgg.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        return nn.MSELoss()(self.vgg(x), self.vgg(y))\n"
      ],
      "metadata": {
        "id": "PIL6hK1YksaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# If a GPU is available, you can also check its details\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
        "    print(f\"GPU Memory Cached: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n"
      ],
      "metadata": {
        "id": "WnkEcQLrpxfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29dd6f59-6f60-49d3-fc29-e796b4b32f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory Allocated: 0.00 GB\n",
            "GPU Memory Cached: 0.00 GB\n"
          ]
        }
      ]
    }
  ]
}