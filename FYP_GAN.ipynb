{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdulSheffa/IRP/blob/main/FYP_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB52lxgkTjB7",
        "outputId": "3d4d4c09-1d7a-439c-fab8-cdb9ef3cf92b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo2OYl_B4LvW",
        "outputId": "8a22d623-ba16-455c-bb16-781c53e64c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2516, done.\u001b[K\n",
            "remote: Total 2516 (delta 0), reused 0 (delta 0), pack-reused 2516 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2516/2516), 8.20 MiB | 21.70 MiB/s, done.\n",
            "Resolving deltas: 100% (1575/1575), done.\n",
            "/content/pytorch-CycleGAN-and-pix2pix\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git\n",
        "%cd pytorch-CycleGAN-and-pix2pix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zkTHg53q4cgW",
        "outputId": "554d2b5b-a798-4efd-b327-af4b43f75d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu124)\n",
            "Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.19.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.33)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 5)) (75.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 5)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408196 sha256=39fb86b99f19fb786799bd678b15717f962a8be4fe0846c76b66b8a2761babbe\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/a4/bb/2be445c295d88a74f9c0a4232f04860ca489a5c7c57eb959d9\n",
            "Successfully built visdom\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dominate, visdom, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dominate-2.9.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 visdom-0.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t4aaBymOOZ5P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "from models.networks import ResnetGenerator, NLayerDiscriminator\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Dataset with Self-Supervised Learning & Masking\n",
        "# ------------------------------\n",
        "class RainDatasetSSL(Dataset):\n",
        "    def __init__(self, dataset_name, input_dir, target_dir, transform=None, sample_size=None, output_dir=None, save_masked=False, epoch=0):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.input_dir = input_dir\n",
        "        self.target_dir = target_dir\n",
        "        self.transform = transform\n",
        "        self.output_dir = output_dir\n",
        "        self.save_masked = save_masked\n",
        "        self.epoch = epoch\n",
        "\n",
        "        self.input_images = sorted(os.listdir(input_dir))\n",
        "        self.target_images = sorted(os.listdir(target_dir))\n",
        "\n",
        "        if sample_size:\n",
        "            indices = random.sample(range(len(self.input_images)), sample_size)\n",
        "            self.input_images = [self.input_images[i] for i in indices]\n",
        "            self.target_images = [self.target_images[i] for i in indices]\n",
        "\n",
        "        if save_masked and output_dir:\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "            self.masked_images_to_save = random.sample(self.input_images, min(10, len(self.input_images)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_images)\n",
        "\n",
        "    def mask_image(self, img_tensor, img_name):\n",
        "        \"\"\"Apply dynamic masking for self-supervised learning & save masked image if required.\"\"\"\n",
        "        if img_tensor.dim() == 4:  # If batch, process each image separately\n",
        "            return torch.stack([self.mask_image(single_img, img_name) for single_img in img_tensor])\n",
        "\n",
        "        if img_tensor.dim() != 3:\n",
        "            raise ValueError(f\"Unexpected tensor shape {img_tensor.shape}, expected (C, H, W)\")\n",
        "\n",
        "        _, h, w = img_tensor.shape\n",
        "        mask_size = (random.randint(h // 6, h // 4), random.randint(w // 6, w // 4))\n",
        "        x, y = random.randint(0, h - mask_size[0]), random.randint(0, w - mask_size[1])\n",
        "\n",
        "        masked_tensor = img_tensor.clone()\n",
        "        masked_tensor[:, x:x + mask_size[0], y:y + mask_size[1]] = -1\n",
        "\n",
        "        # ✅ Ensure the output directory exists before saving\n",
        "        if self.save_masked and self.output_dir:\n",
        "            os.makedirs(self.output_dir, exist_ok=True)  # ✅ Ensure the directory exists\n",
        "\n",
        "            save_path = os.path.join(self.output_dir, f\"masked_{self.dataset_name}_epoch_{self.epoch}_{img_name}\")\n",
        "            save_image((masked_tensor + 1) / 2, save_path)  # Denormalizing before saving\n",
        "            # print(f\"✅ Saved masked image: {save_path}\")\n",
        "\n",
        "        return masked_tensor\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_img_path = os.path.join(self.input_dir, self.input_images[idx])\n",
        "        target_img_path = os.path.join(self.target_dir, self.target_images[idx])\n",
        "\n",
        "        input_image = Image.open(input_img_path).convert(\"RGB\")\n",
        "        target_image = Image.open(target_img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            input_image = self.transform(input_image)\n",
        "            target_image = self.transform(target_image)\n",
        "\n",
        "        masked_image = self.mask_image(input_image.clone(), self.input_images[idx])\n",
        "        return masked_image, input_image, target_image, self.input_images[idx]  # ✅ Ensure 4 elements\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Masked GAN-Based DeRain CycleGAN (Without Self-Attention)\n",
        "# ------------------------------\n",
        "class DeRainCycleGANSSL:\n",
        "    def __init__(self, input_nc, output_nc, ngf, ndf, device):\n",
        "        self.device = device\n",
        "        self.netG_A = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=nn.InstanceNorm2d ,n_blocks=9).to(device)\n",
        "        self.netG_B = ResnetGenerator(output_nc, input_nc, ngf).to(device)\n",
        "        self.netD_A = NLayerDiscriminator(output_nc, ndf).to(device)\n",
        "        self.netD_B = NLayerDiscriminator(input_nc, ndf).to(device)\n",
        "\n",
        "        self.criterionGAN = nn.MSELoss()\n",
        "        self.criterionCycle = nn.L1Loss()\n",
        "        self.criterionPerceptual = nn.MSELoss()\n",
        "\n",
        "        self.vgg19 = models.vgg19(pretrained=True).features[:36].eval().to(device)\n",
        "        for param in self.vgg19.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.optimizer_G = torch.optim.Adam(\n",
        "            list(self.netG_A.parameters()) + list(self.netG_B.parameters()), lr=0.00005, betas=(0.5, 0.999)\n",
        "        )\n",
        "        self.optimizer_D = torch.optim.Adam(\n",
        "            list(self.netD_A.parameters()) + list(self.netD_B.parameters()), lr=0.00001, betas=(0.5, 0.999)\n",
        "        )\n",
        "\n",
        "    def perceptual_loss(self, x, y):\n",
        "        return self.criterionPerceptual(self.vgg19(x), self.vgg19(y))\n",
        "\n",
        "    def forward(self, real_A, real_B):\n",
        "        fake_B = self.netG_A(real_A)\n",
        "        rec_A = self.netG_B(fake_B)\n",
        "        fake_A = self.netG_B(real_B)\n",
        "        rec_B = self.netG_A(fake_A)\n",
        "        return fake_B, rec_A, fake_A, rec_B\n",
        "\n",
        "    def optimize_parameters(self, real_A, real_B, scaler):\n",
        "        \"\"\"Optimizes generator and discriminator parameters for one iteration.\"\"\"\n",
        "\n",
        "        self.optimizer_G.zero_grad()\n",
        "        with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "            real_A, real_B = real_A.half(), real_B.half()\n",
        "            fake_B, rec_A, fake_A, rec_B = self.forward(real_A, real_B)\n",
        "            loss_G_A = self.criterionGAN(self.netD_A(fake_B), torch.ones_like(self.netD_A(fake_B)))\n",
        "            loss_G_B = self.criterionGAN(self.netD_B(fake_A), torch.ones_like(self.netD_B(fake_A)))\n",
        "            loss_cycle_A = self.criterionCycle(rec_A, real_A) * 10.0\n",
        "            loss_cycle_B = self.criterionCycle(rec_B, real_B) * 10.0\n",
        "            loss_perceptual = self.perceptual_loss(fake_B, real_B) * 0.2  # Reduced from 0.4\n",
        "            loss_L1 = self.criterionCycle(fake_B, real_B) * 10.0  # Introduced L1 loss\n",
        "            loss_G = 2.0 * loss_G_A + 2.0 * loss_G_B + 4.0 * loss_cycle_A + 4.0 * loss_cycle_B + 0.5 * loss_perceptual + loss_L1\n",
        "\n",
        "        scaler.scale(loss_G).backward()\n",
        "        scaler.step(self.optimizer_G)\n",
        "        scaler.update()\n",
        "\n",
        "        self.optimizer_D.zero_grad()\n",
        "        with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "            loss_D_A = self.criterionGAN(self.netD_A(real_B.half()), torch.ones_like(self.netD_A(real_B.half())))\n",
        "            loss_D_B = self.criterionGAN(self.netD_B(real_A.half()), torch.ones_like(self.netD_B(real_A.half())))\n",
        "            loss_D = (loss_D_A + loss_D_B) * 0.3\n",
        "\n",
        "        scaler.scale(loss_D).backward()\n",
        "        scaler.step(self.optimizer_D)\n",
        "        scaler.update()\n",
        "\n",
        "        return loss_G.detach(), loss_D_A.detach(), loss_D_B.detach()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xylk1Uau0MJZ",
        "outputId": "946f57fe-b073-4f7f-fa82-a4ebc1d266fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-1127d71797bc>:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:03<00:00, 168MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 Loading model from /content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint/checkpoint_epoch_79.pth...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-1127d71797bc>:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model Loaded Successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.cuda.amp as amp  # ✅ Import amp explicitly\n",
        "from torchvision import transforms\n",
        "\n",
        "# ✅ Initialize Mixed Precision Training\n",
        "scaler = amp.GradScaler()\n",
        "\n",
        "# ✅ Initialize Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ✅ Define Checkpoint Directory\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint/\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)  # Ensure checkpoint folder exists\n",
        "\n",
        "# ✅ Initialize Model BEFORE Loading Checkpoint\n",
        "model = DeRainCycleGANSSL(input_nc=3, output_nc=3, ngf=128, ndf=256, device=device)\n",
        "\n",
        "# ✅ Function to Load the Model from Checkpoint\n",
        "def load_model_only(model, checkpoint_dir):\n",
        "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth\")]\n",
        "    if not checkpoints:\n",
        "        print(\"⚠️ No checkpoint found. Model will remain uninitialized.\")\n",
        "        return None\n",
        "\n",
        "    # ✅ Load the latest checkpoint\n",
        "    latest_checkpoint = sorted(checkpoints, key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))[-1]\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
        "\n",
        "    print(f\"🔄 Loading model from {checkpoint_path}...\")\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.netG_A.load_state_dict(checkpoint['model_G_A_state_dict'])\n",
        "    model.netG_B.load_state_dict(checkpoint['model_G_B_state_dict'])\n",
        "    model.netD_A.load_state_dict(checkpoint['model_D_A_state_dict'])\n",
        "    model.netD_B.load_state_dict(checkpoint['model_D_B_state_dict'])\n",
        "\n",
        "    print(\"✅ Model Loaded Successfully!\")\n",
        "\n",
        "# ✅ Load the Model from Checkpoint (Without Training)\n",
        "load_model_only(model, checkpoint_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N4LL6lD6BNF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "def load_latest_checkpoint(model, optimizer_G, optimizer_D, scheduler_G, scheduler_D, scaler, checkpoint_dir, device):\n",
        "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith(\".pth\")]\n",
        "    if not checkpoints:\n",
        "        print(\"⚠️ No checkpoint found, starting from scratch.\")\n",
        "        return 0  # Start from epoch 0\n",
        "\n",
        "    # Sort and get the latest checkpoint\n",
        "    latest_checkpoint = sorted(checkpoints, key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))[-1]\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
        "\n",
        "    print(f\"🔄 Resuming training from {checkpoint_path}\")\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.netG_A.load_state_dict(checkpoint['model_G_A_state_dict'])\n",
        "    model.netG_B.load_state_dict(checkpoint['model_G_B_state_dict'])\n",
        "    model.netD_A.load_state_dict(checkpoint['model_D_A_state_dict'])\n",
        "    model.netD_B.load_state_dict(checkpoint['model_D_B_state_dict'])\n",
        "    optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
        "    optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n",
        "    scheduler_G.load_state_dict(checkpoint['scheduler_G_state_dict'])\n",
        "    scheduler_D.load_state_dict(checkpoint['scheduler_D_state_dict'])\n",
        "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
        "\n",
        "    return checkpoint['epoch'] + 1  # Resume from the next epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUX1yheK7O3l",
        "outputId": "db8726f3-682c-41fa-c7e1-b0a781ce4807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Training will start from epoch 0\n",
            "\n",
            "🔹 Training on DID-MDN-Heavy dataset...\n",
            "Epoch 0/70, Batch 0/25, Image: rainy_1733.jpg, Loss_G: 48.6769, Loss_D_A: 1.0063, Loss_D_B: 1.1324\n",
            "Epoch 0/70, Batch 1/25, Image: rainy_1591.jpg, Loss_G: 49.2385, Loss_D_A: 9.0522, Loss_D_B: 3.8404\n",
            "Epoch 0/70, Batch 2/25, Image: rainy_1426.jpg, Loss_G: 46.0179, Loss_D_A: 0.5221, Loss_D_B: 1.5276\n",
            "Epoch 0/70, Batch 3/25, Image: rainy_1771.jpg, Loss_G: 46.3460, Loss_D_A: 1.4291, Loss_D_B: 0.8378\n",
            "Epoch 0/70, Batch 4/25, Image: rainy_2453.jpg, Loss_G: 46.3683, Loss_D_A: 0.4513, Loss_D_B: 0.4582\n",
            "Epoch 0/70, Batch 5/25, Image: rainy_335.jpg, Loss_G: 45.1559, Loss_D_A: 0.4000, Loss_D_B: 0.3325\n",
            "Epoch 0/70, Batch 6/25, Image: rainy_1269.jpg, Loss_G: 37.9159, Loss_D_A: 0.2223, Loss_D_B: 0.1181\n",
            "Epoch 0/70, Batch 7/25, Image: rainy_104.jpg, Loss_G: 38.0816, Loss_D_A: 0.1191, Loss_D_B: 0.0893\n",
            "Epoch 0/70, Batch 8/25, Image: rainy_3014.jpg, Loss_G: 32.5191, Loss_D_A: 0.1418, Loss_D_B: 0.1170\n",
            "Epoch 0/70, Batch 9/25, Image: rainy_1966.jpg, Loss_G: 31.1951, Loss_D_A: 0.0828, Loss_D_B: 0.1258\n",
            "Epoch 0/70, Batch 10/25, Image: rainy_1456.jpg, Loss_G: 27.8454, Loss_D_A: 0.0651, Loss_D_B: 0.0751\n",
            "Epoch 0/70, Batch 11/25, Image: rainy_1286.jpg, Loss_G: 26.2471, Loss_D_A: 0.0612, Loss_D_B: 0.0559\n",
            "Epoch 0/70, Batch 12/25, Image: rainy_2857.jpg, Loss_G: 23.0854, Loss_D_A: 0.0689, Loss_D_B: 0.0567\n",
            "Epoch 0/70, Batch 13/25, Image: rainy_3795.jpg, Loss_G: 23.0601, Loss_D_A: 0.0582, Loss_D_B: 0.0542\n",
            "Epoch 0/70, Batch 14/25, Image: rainy_1167.jpg, Loss_G: 26.3283, Loss_D_A: 0.0528, Loss_D_B: 0.0485\n",
            "Epoch 0/70, Batch 15/25, Image: rainy_865.jpg, Loss_G: 25.6594, Loss_D_A: 0.0604, Loss_D_B: 0.0572\n",
            "Epoch 0/70, Batch 16/25, Image: rainy_398.jpg, Loss_G: 25.5405, Loss_D_A: 0.0526, Loss_D_B: 0.0428\n",
            "Epoch 0/70, Batch 17/25, Image: rainy_332.jpg, Loss_G: 21.7785, Loss_D_A: 0.0573, Loss_D_B: 0.0504\n",
            "Epoch 0/70, Batch 18/25, Image: rainy_1899.jpg, Loss_G: 23.3946, Loss_D_A: 0.0565, Loss_D_B: 0.0413\n",
            "Epoch 0/70, Batch 19/25, Image: rainy_3363.jpg, Loss_G: 23.8462, Loss_D_A: 0.0722, Loss_D_B: 0.0460\n",
            "Epoch 0/70, Batch 20/25, Image: rainy_3428.jpg, Loss_G: 26.7848, Loss_D_A: 0.0708, Loss_D_B: 0.0512\n",
            "Epoch 0/70, Batch 21/25, Image: rainy_2513.jpg, Loss_G: 20.1876, Loss_D_A: 0.0695, Loss_D_B: 0.0493\n",
            "Epoch 0/70, Batch 22/25, Image: rainy_328.jpg, Loss_G: 21.0371, Loss_D_A: 0.0494, Loss_D_B: 0.0421\n",
            "Epoch 0/70, Batch 23/25, Image: rainy_537.jpg, Loss_G: 24.7912, Loss_D_A: 0.0390, Loss_D_B: 0.0401\n",
            "Epoch 0/70, Batch 24/25, Image: rainy_1346.jpg, Loss_G: 22.6340, Loss_D_A: 0.0431, Loss_D_B: 0.0369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Checkpoint saved at epoch 0\n",
            "Epoch 1/70, Batch 0/25, Image: rainy_1656.jpg, Loss_G: 17.0067, Loss_D_A: 0.0450, Loss_D_B: 0.0404\n",
            "Epoch 1/70, Batch 1/25, Image: rainy_3193.jpg, Loss_G: 19.2944, Loss_D_A: 0.0502, Loss_D_B: 0.0453\n",
            "Epoch 1/70, Batch 2/25, Image: rainy_2492.jpg, Loss_G: 20.8307, Loss_D_A: 0.0481, Loss_D_B: 0.0548\n",
            "Epoch 1/70, Batch 3/25, Image: rainy_3164.jpg, Loss_G: 19.7460, Loss_D_A: 0.0354, Loss_D_B: 0.0565\n",
            "Epoch 1/70, Batch 4/25, Image: rainy_773.jpg, Loss_G: 19.7659, Loss_D_A: 0.0428, Loss_D_B: 0.0540\n",
            "Epoch 1/70, Batch 5/25, Image: rainy_662.jpg, Loss_G: 21.5215, Loss_D_A: 0.0427, Loss_D_B: 0.0586\n",
            "Epoch 1/70, Batch 6/25, Image: rainy_1957.jpg, Loss_G: 22.8705, Loss_D_A: 0.0509, Loss_D_B: 0.0623\n",
            "Epoch 1/70, Batch 7/25, Image: rainy_447.jpg, Loss_G: 21.8180, Loss_D_A: 0.0453, Loss_D_B: 0.0470\n",
            "Epoch 1/70, Batch 8/25, Image: rainy_1901.jpg, Loss_G: 26.5928, Loss_D_A: 0.0687, Loss_D_B: 0.0386\n",
            "Epoch 1/70, Batch 9/25, Image: rainy_3336.jpg, Loss_G: 20.4415, Loss_D_A: 0.0704, Loss_D_B: 0.0406\n",
            "Epoch 1/70, Batch 10/25, Image: rainy_1861.jpg, Loss_G: 17.8686, Loss_D_A: 0.0600, Loss_D_B: 0.0742\n",
            "Epoch 1/70, Batch 11/25, Image: rainy_328.jpg, Loss_G: 20.4942, Loss_D_A: 0.0426, Loss_D_B: 0.1196\n",
            "Epoch 1/70, Batch 12/25, Image: rainy_1591.jpg, Loss_G: 17.5620, Loss_D_A: 0.0463, Loss_D_B: 0.2028\n",
            "Epoch 1/70, Batch 13/25, Image: rainy_3821.jpg, Loss_G: 18.3874, Loss_D_A: 0.0428, Loss_D_B: 0.2066\n",
            "Epoch 1/70, Batch 14/25, Image: rainy_3213.jpg, Loss_G: 18.0173, Loss_D_A: 0.0532, Loss_D_B: 0.1759\n",
            "Epoch 1/70, Batch 15/25, Image: rainy_1690.jpg, Loss_G: 24.4957, Loss_D_A: 0.0524, Loss_D_B: 0.0891\n",
            "Epoch 1/70, Batch 16/25, Image: rainy_2628.jpg, Loss_G: 22.0716, Loss_D_A: 0.0891, Loss_D_B: 0.0580\n",
            "Epoch 1/70, Batch 17/25, Image: rainy_1733.jpg, Loss_G: 20.7567, Loss_D_A: 0.1450, Loss_D_B: 0.0832\n",
            "Epoch 1/70, Batch 18/25, Image: rainy_1269.jpg, Loss_G: 18.2052, Loss_D_A: 0.0841, Loss_D_B: 0.0755\n",
            "Epoch 1/70, Batch 19/25, Image: rainy_1568.jpg, Loss_G: 21.2497, Loss_D_A: 0.0424, Loss_D_B: 0.0402\n",
            "Epoch 1/70, Batch 20/25, Image: rainy_3001.jpg, Loss_G: 18.4946, Loss_D_A: 0.0625, Loss_D_B: 0.0356\n",
            "Epoch 1/70, Batch 21/25, Image: rainy_413.jpg, Loss_G: 20.7338, Loss_D_A: 0.0368, Loss_D_B: 0.0518\n",
            "Epoch 1/70, Batch 22/25, Image: rainy_79.jpg, Loss_G: 20.1916, Loss_D_A: 0.0398, Loss_D_B: 0.1366\n",
            "Epoch 1/70, Batch 23/25, Image: rainy_2977.jpg, Loss_G: 18.7881, Loss_D_A: 0.0394, Loss_D_B: 0.1967\n",
            "Epoch 1/70, Batch 24/25, Image: rainy_1771.jpg, Loss_G: 17.9916, Loss_D_A: 0.0292, Loss_D_B: 0.1344\n",
            "Epoch 2/70, Batch 0/25, Image: rainy_814.jpg, Loss_G: 18.0322, Loss_D_A: 0.0305, Loss_D_B: 0.0310\n",
            "Epoch 2/70, Batch 1/25, Image: rainy_2275.jpg, Loss_G: 18.7899, Loss_D_A: 0.0278, Loss_D_B: 0.0573\n",
            "Epoch 2/70, Batch 2/25, Image: rainy_3020.jpg, Loss_G: 15.6127, Loss_D_A: 0.0355, Loss_D_B: 0.0667\n",
            "Epoch 2/70, Batch 3/25, Image: rainy_2513.jpg, Loss_G: 18.0138, Loss_D_A: 0.0418, Loss_D_B: 0.0551\n",
            "Epoch 2/70, Batch 4/25, Image: rainy_536.jpg, Loss_G: 17.5621, Loss_D_A: 0.0368, Loss_D_B: 0.0262\n",
            "Epoch 2/70, Batch 5/25, Image: rainy_1456.jpg, Loss_G: 20.0027, Loss_D_A: 0.0403, Loss_D_B: 0.0278\n",
            "Epoch 2/70, Batch 6/25, Image: rainy_2836.jpg, Loss_G: 17.5510, Loss_D_A: 0.0536, Loss_D_B: 0.0474\n",
            "Epoch 2/70, Batch 7/25, Image: rainy_3355.jpg, Loss_G: 17.1602, Loss_D_A: 0.0385, Loss_D_B: 0.0353\n",
            "Epoch 2/70, Batch 8/25, Image: rainy_1530.jpg, Loss_G: 23.7922, Loss_D_A: 0.0427, Loss_D_B: 0.0424\n",
            "Epoch 2/70, Batch 9/25, Image: rainy_3014.jpg, Loss_G: 20.1689, Loss_D_A: 0.0403, Loss_D_B: 0.0876\n",
            "Epoch 2/70, Batch 10/25, Image: rainy_1269.jpg, Loss_G: 19.5469, Loss_D_A: 0.0597, Loss_D_B: 0.0691\n",
            "Epoch 2/70, Batch 11/25, Image: rainy_752.jpg, Loss_G: 15.0867, Loss_D_A: 0.0411, Loss_D_B: 0.0271\n",
            "Epoch 2/70, Batch 12/25, Image: rainy_3509.jpg, Loss_G: 22.8465, Loss_D_A: 0.0451, Loss_D_B: 0.0305\n",
            "Epoch 2/70, Batch 13/25, Image: rainy_2620.jpg, Loss_G: 20.9787, Loss_D_A: 0.0348, Loss_D_B: 0.0399\n",
            "Epoch 2/70, Batch 14/25, Image: rainy_119.jpg, Loss_G: 20.2867, Loss_D_A: 0.0428, Loss_D_B: 0.0404\n",
            "Epoch 2/70, Batch 15/25, Image: rainy_3063.jpg, Loss_G: 18.3001, Loss_D_A: 0.0390, Loss_D_B: 0.0281\n",
            "Epoch 2/70, Batch 16/25, Image: rainy_1599.jpg, Loss_G: 19.6328, Loss_D_A: 0.0372, Loss_D_B: 0.0312\n",
            "Epoch 2/70, Batch 17/25, Image: rainy_3001.jpg, Loss_G: 18.7694, Loss_D_A: 0.0536, Loss_D_B: 0.0316\n",
            "Epoch 2/70, Batch 18/25, Image: rainy_904.jpg, Loss_G: 16.2602, Loss_D_A: 0.0674, Loss_D_B: 0.0250\n",
            "Epoch 2/70, Batch 19/25, Image: rainy_2928.jpg, Loss_G: 16.9347, Loss_D_A: 0.0405, Loss_D_B: 0.0513\n",
            "Epoch 2/70, Batch 20/25, Image: rainy_166.jpg, Loss_G: 16.4529, Loss_D_A: 0.0415, Loss_D_B: 0.0648\n",
            "Epoch 2/70, Batch 21/25, Image: rainy_2977.jpg, Loss_G: 15.5978, Loss_D_A: 0.0263, Loss_D_B: 0.0332\n",
            "Epoch 2/70, Batch 22/25, Image: rainy_2544.jpg, Loss_G: 18.7308, Loss_D_A: 0.0322, Loss_D_B: 0.0259\n",
            "Epoch 2/70, Batch 23/25, Image: rainy_1346.jpg, Loss_G: 15.6910, Loss_D_A: 0.0245, Loss_D_B: 0.0335\n",
            "Epoch 2/70, Batch 24/25, Image: rainy_3385.jpg, Loss_G: 18.6357, Loss_D_A: 0.0886, Loss_D_B: 0.0215\n",
            "Epoch 3/70, Batch 0/25, Image: rainy_2943.jpg, Loss_G: 18.1016, Loss_D_A: 0.2243, Loss_D_B: 0.0278\n",
            "Epoch 3/70, Batch 1/25, Image: rainy_2570.jpg, Loss_G: 18.0576, Loss_D_A: 0.2013, Loss_D_B: 0.0226\n",
            "Epoch 3/70, Batch 2/25, Image: rainy_429.jpg, Loss_G: 17.5965, Loss_D_A: 0.1005, Loss_D_B: 0.0170\n",
            "Epoch 3/70, Batch 3/25, Image: rainy_1346.jpg, Loss_G: 18.9459, Loss_D_A: 0.0530, Loss_D_B: 0.0212\n",
            "Epoch 3/70, Batch 4/25, Image: rainy_1674.jpg, Loss_G: 16.5608, Loss_D_A: 0.0610, Loss_D_B: 0.0239\n",
            "Epoch 3/70, Batch 5/25, Image: rainy_748.jpg, Loss_G: 17.9729, Loss_D_A: 0.1197, Loss_D_B: 0.0987\n",
            "Epoch 3/70, Batch 6/25, Image: rainy_3355.jpg, Loss_G: 17.3643, Loss_D_A: 0.0461, Loss_D_B: 0.1521\n",
            "Epoch 3/70, Batch 7/25, Image: rainy_3010.jpg, Loss_G: 19.8214, Loss_D_A: 0.0436, Loss_D_B: 0.1296\n",
            "Epoch 3/70, Batch 8/25, Image: rainy_2838.jpg, Loss_G: 16.4592, Loss_D_A: 0.0542, Loss_D_B: 0.0464\n",
            "Epoch 3/70, Batch 9/25, Image: rainy_2628.jpg, Loss_G: 19.5359, Loss_D_A: 0.0394, Loss_D_B: 0.0837\n",
            "Epoch 3/70, Batch 10/25, Image: rainy_2460.jpg, Loss_G: 15.4279, Loss_D_A: 0.0317, Loss_D_B: 0.2565\n",
            "Epoch 3/70, Batch 11/25, Image: rainy_328.jpg, Loss_G: 15.2035, Loss_D_A: 0.0306, Loss_D_B: 0.1837\n",
            "Epoch 3/70, Batch 12/25, Image: rainy_773.jpg, Loss_G: 15.2425, Loss_D_A: 0.0378, Loss_D_B: 0.0520\n",
            "Epoch 3/70, Batch 13/25, Image: rainy_2492.jpg, Loss_G: 15.5400, Loss_D_A: 0.0284, Loss_D_B: 0.0325\n",
            "Epoch 3/70, Batch 14/25, Image: rainy_2787.jpg, Loss_G: 15.7726, Loss_D_A: 0.0475, Loss_D_B: 0.0376\n",
            "Epoch 3/70, Batch 15/25, Image: rainy_1761.jpg, Loss_G: 16.2183, Loss_D_A: 0.0891, Loss_D_B: 0.0673\n",
            "Epoch 3/70, Batch 16/25, Image: rainy_3019.jpg, Loss_G: 14.9750, Loss_D_A: 0.0827, Loss_D_B: 0.0608\n",
            "Epoch 3/70, Batch 17/25, Image: rainy_2619.jpg, Loss_G: 20.9828, Loss_D_A: 0.0430, Loss_D_B: 0.0212\n",
            "Epoch 3/70, Batch 18/25, Image: rainy_537.jpg, Loss_G: 18.0615, Loss_D_A: 0.0428, Loss_D_B: 0.0519\n",
            "Epoch 3/70, Batch 19/25, Image: rainy_904.jpg, Loss_G: 17.7451, Loss_D_A: 0.0317, Loss_D_B: 0.0348\n",
            "Epoch 3/70, Batch 20/25, Image: rainy_3136.jpg, Loss_G: 15.6046, Loss_D_A: 0.0239, Loss_D_B: 0.0258\n",
            "Epoch 3/70, Batch 21/25, Image: rainy_3573.jpg, Loss_G: 20.5614, Loss_D_A: 0.0753, Loss_D_B: 0.0618\n",
            "Epoch 3/70, Batch 22/25, Image: rainy_2857.jpg, Loss_G: 16.0201, Loss_D_A: 0.1743, Loss_D_B: 0.1020\n",
            "Epoch 3/70, Batch 23/25, Image: rainy_3511.jpg, Loss_G: 16.2316, Loss_D_A: 0.1357, Loss_D_B: 0.0480\n",
            "Epoch 3/70, Batch 24/25, Image: rainy_382.jpg, Loss_G: 14.9669, Loss_D_A: 0.1022, Loss_D_B: 0.0229\n",
            "Epoch 4/70, Batch 0/25, Image: rainy_536.jpg, Loss_G: 20.0427, Loss_D_A: 0.0289, Loss_D_B: 0.0240\n",
            "Epoch 4/70, Batch 1/25, Image: rainy_1083.jpg, Loss_G: 14.5584, Loss_D_A: 0.0431, Loss_D_B: 0.0222\n",
            "Epoch 4/70, Batch 2/25, Image: rainy_1471.jpg, Loss_G: 17.6745, Loss_D_A: 0.0396, Loss_D_B: 0.0188\n",
            "Epoch 4/70, Batch 3/25, Image: rainy_1690.jpg, Loss_G: 15.8412, Loss_D_A: 0.0438, Loss_D_B: 0.0263\n",
            "Epoch 4/70, Batch 4/25, Image: rainy_1530.jpg, Loss_G: 15.5876, Loss_D_A: 0.0274, Loss_D_B: 0.0175\n",
            "Epoch 4/70, Batch 5/25, Image: rainy_1674.jpg, Loss_G: 15.8542, Loss_D_A: 0.0245, Loss_D_B: 0.0247\n",
            "Epoch 4/70, Batch 6/25, Image: rainy_795.jpg, Loss_G: 18.2856, Loss_D_A: 0.0390, Loss_D_B: 0.0315\n",
            "Epoch 4/70, Batch 7/25, Image: rainy_3661.jpg, Loss_G: 14.3428, Loss_D_A: 0.0467, Loss_D_B: 0.0327\n",
            "Epoch 4/70, Batch 8/25, Image: rainy_865.jpg, Loss_G: 15.0087, Loss_D_A: 0.0298, Loss_D_B: 0.0230\n",
            "Epoch 4/70, Batch 9/25, Image: rainy_1568.jpg, Loss_G: 14.7498, Loss_D_A: 0.0177, Loss_D_B: 0.0164\n",
            "Epoch 4/70, Batch 10/25, Image: rainy_2160.jpg, Loss_G: 17.3704, Loss_D_A: 0.0264, Loss_D_B: 0.0358\n",
            "Epoch 4/70, Batch 11/25, Image: rainy_3951.jpg, Loss_G: 15.3781, Loss_D_A: 0.0236, Loss_D_B: 0.0264\n",
            "Epoch 4/70, Batch 12/25, Image: rainy_3509.jpg, Loss_G: 16.2329, Loss_D_A: 0.0240, Loss_D_B: 0.0172\n",
            "Epoch 4/70, Batch 13/25, Image: rainy_3859.jpg, Loss_G: 16.5765, Loss_D_A: 0.0264, Loss_D_B: 0.0198\n",
            "Epoch 4/70, Batch 14/25, Image: rainy_3019.jpg, Loss_G: 15.2216, Loss_D_A: 0.0202, Loss_D_B: 0.0214\n",
            "Epoch 4/70, Batch 15/25, Image: rainy_748.jpg, Loss_G: 17.4585, Loss_D_A: 0.0158, Loss_D_B: 0.0211\n",
            "Epoch 4/70, Batch 16/25, Image: rainy_3371.jpg, Loss_G: 18.7646, Loss_D_A: 0.0331, Loss_D_B: 0.0167\n",
            "Epoch 4/70, Batch 17/25, Image: rainy_1381.jpg, Loss_G: 20.5949, Loss_D_A: 0.0961, Loss_D_B: 0.0230\n",
            "Epoch 4/70, Batch 18/25, Image: rainy_2714.jpg, Loss_G: 18.0354, Loss_D_A: 0.0727, Loss_D_B: 0.0401\n",
            "Epoch 4/70, Batch 19/25, Image: rainy_558.jpg, Loss_G: 14.2083, Loss_D_A: 0.0412, Loss_D_B: 0.0288\n",
            "Epoch 4/70, Batch 20/25, Image: rainy_537.jpg, Loss_G: 13.8479, Loss_D_A: 0.0379, Loss_D_B: 0.0151\n",
            "Epoch 4/70, Batch 21/25, Image: rainy_382.jpg, Loss_G: 14.4613, Loss_D_A: 0.0473, Loss_D_B: 0.0161\n",
            "Epoch 4/70, Batch 22/25, Image: rainy_912.jpg, Loss_G: 17.7354, Loss_D_A: 0.0201, Loss_D_B: 0.0161\n",
            "Epoch 4/70, Batch 23/25, Image: rainy_3156.jpg, Loss_G: 16.6495, Loss_D_A: 0.0201, Loss_D_B: 0.0183\n",
            "Epoch 4/70, Batch 24/25, Image: rainy_1059.jpg, Loss_G: 16.1636, Loss_D_A: 0.0325, Loss_D_B: 0.0196\n",
            "Epoch 5/70, Batch 0/25, Image: rainy_2544.jpg, Loss_G: 16.2905, Loss_D_A: 0.0286, Loss_D_B: 0.0132\n",
            "Epoch 5/70, Batch 1/25, Image: rainy_3606.jpg, Loss_G: 15.5807, Loss_D_A: 0.0475, Loss_D_B: 0.0159\n",
            "Epoch 5/70, Batch 2/25, Image: rainy_1083.jpg, Loss_G: 17.9822, Loss_D_A: 0.0263, Loss_D_B: 0.0220\n",
            "Epoch 5/70, Batch 3/25, Image: rainy_328.jpg, Loss_G: 14.7421, Loss_D_A: 0.0279, Loss_D_B: 0.0340\n",
            "Epoch 5/70, Batch 4/25, Image: rainy_2977.jpg, Loss_G: 15.6021, Loss_D_A: 0.0255, Loss_D_B: 0.0179\n",
            "Epoch 5/70, Batch 5/25, Image: rainy_3710.jpg, Loss_G: 14.9308, Loss_D_A: 0.0257, Loss_D_B: 0.0188\n",
            "Epoch 5/70, Batch 6/25, Image: rainy_993.jpg, Loss_G: 22.8140, Loss_D_A: 0.0410, Loss_D_B: 0.0282\n",
            "Epoch 5/70, Batch 7/25, Image: rainy_2513.jpg, Loss_G: 15.6701, Loss_D_A: 0.0492, Loss_D_B: 0.0159\n",
            "Epoch 5/70, Batch 8/25, Image: rainy_904.jpg, Loss_G: 14.0792, Loss_D_A: 0.0315, Loss_D_B: 0.0134\n",
            "Epoch 5/70, Batch 9/25, Image: rainy_398.jpg, Loss_G: 15.5497, Loss_D_A: 0.0155, Loss_D_B: 0.0121\n",
            "Epoch 5/70, Batch 10/25, Image: rainy_104.jpg, Loss_G: 15.4001, Loss_D_A: 0.0386, Loss_D_B: 0.0160\n",
            "Epoch 5/70, Batch 11/25, Image: rainy_2620.jpg, Loss_G: 15.1497, Loss_D_A: 0.0877, Loss_D_B: 0.0218\n",
            "Epoch 5/70, Batch 12/25, Image: rainy_1091.jpg, Loss_G: 15.2943, Loss_D_A: 0.0554, Loss_D_B: 0.0141\n",
            "Epoch 5/70, Batch 13/25, Image: rainy_1826.jpg, Loss_G: 15.0325, Loss_D_A: 0.0277, Loss_D_B: 0.0120\n",
            "Epoch 5/70, Batch 14/25, Image: rainy_3385.jpg, Loss_G: 14.0907, Loss_D_A: 0.0435, Loss_D_B: 0.0199\n",
            "Epoch 5/70, Batch 15/25, Image: rainy_3398.jpg, Loss_G: 15.8968, Loss_D_A: 0.0497, Loss_D_B: 0.0170\n",
            "Epoch 5/70, Batch 16/25, Image: rainy_184.jpg, Loss_G: 12.9898, Loss_D_A: 0.0236, Loss_D_B: 0.0121\n",
            "Epoch 5/70, Batch 17/25, Image: rainy_2836.jpg, Loss_G: 16.4856, Loss_D_A: 0.0323, Loss_D_B: 0.0235\n",
            "Epoch 5/70, Batch 18/25, Image: rainy_244.jpg, Loss_G: 14.2610, Loss_D_A: 0.0215, Loss_D_B: 0.0259\n",
            "Epoch 5/70, Batch 19/25, Image: rainy_481.jpg, Loss_G: 18.3784, Loss_D_A: 0.0353, Loss_D_B: 0.0142\n",
            "Epoch 5/70, Batch 20/25, Image: rainy_2486.jpg, Loss_G: 15.3088, Loss_D_A: 0.0536, Loss_D_B: 0.0316\n",
            "Epoch 5/70, Batch 21/25, Image: rainy_232.jpg, Loss_G: 15.2353, Loss_D_A: 0.0378, Loss_D_B: 0.0594\n",
            "Epoch 5/70, Batch 22/25, Image: rainy_3063.jpg, Loss_G: 18.8674, Loss_D_A: 0.0778, Loss_D_B: 0.0502\n",
            "Epoch 5/70, Batch 23/25, Image: rainy_2619.jpg, Loss_G: 14.4018, Loss_D_A: 0.0493, Loss_D_B: 0.0237\n",
            "Epoch 5/70, Batch 24/25, Image: rainy_788.jpg, Loss_G: 17.6656, Loss_D_A: 0.0332, Loss_D_B: 0.0212\n",
            "✅ Checkpoint saved at epoch 5\n",
            "Epoch 6/70, Batch 0/25, Image: rainy_429.jpg, Loss_G: 13.6376, Loss_D_A: 0.0589, Loss_D_B: 0.0585\n",
            "Epoch 6/70, Batch 1/25, Image: rainy_3363.jpg, Loss_G: 15.8083, Loss_D_A: 0.0361, Loss_D_B: 0.0506\n",
            "Epoch 6/70, Batch 2/25, Image: rainy_3821.jpg, Loss_G: 12.9666, Loss_D_A: 0.0244, Loss_D_B: 0.0164\n",
            "Epoch 6/70, Batch 3/25, Image: rainy_335.jpg, Loss_G: 14.8571, Loss_D_A: 0.0741, Loss_D_B: 0.0212\n",
            "Epoch 6/70, Batch 4/25, Image: rainy_2691.jpg, Loss_G: 13.3999, Loss_D_A: 0.0684, Loss_D_B: 0.0180\n",
            "Epoch 6/70, Batch 5/25, Image: rainy_481.jpg, Loss_G: 13.4379, Loss_D_A: 0.0210, Loss_D_B: 0.0167\n",
            "Epoch 6/70, Batch 6/25, Image: rainy_119.jpg, Loss_G: 14.6743, Loss_D_A: 0.0268, Loss_D_B: 0.0524\n",
            "Epoch 6/70, Batch 7/25, Image: rainy_868.jpg, Loss_G: 14.6288, Loss_D_A: 0.0315, Loss_D_B: 0.0542\n",
            "Epoch 6/70, Batch 8/25, Image: rainy_1434.jpg, Loss_G: 16.1626, Loss_D_A: 0.0420, Loss_D_B: 0.0160\n",
            "Epoch 6/70, Batch 9/25, Image: rainy_865.jpg, Loss_G: 14.4297, Loss_D_A: 0.0221, Loss_D_B: 0.0376\n",
            "Epoch 6/70, Batch 10/25, Image: rainy_3445.jpg, Loss_G: 17.3849, Loss_D_A: 0.0500, Loss_D_B: 0.1280\n",
            "Epoch 6/70, Batch 11/25, Image: rainy_1836.jpg, Loss_G: 15.2250, Loss_D_A: 0.0817, Loss_D_B: 0.1359\n",
            "Epoch 6/70, Batch 12/25, Image: rainy_79.jpg, Loss_G: 13.8067, Loss_D_A: 0.0581, Loss_D_B: 0.0476\n",
            "Epoch 6/70, Batch 13/25, Image: rainy_1931.jpg, Loss_G: 14.6290, Loss_D_A: 0.0239, Loss_D_B: 0.0346\n",
            "Epoch 6/70, Batch 14/25, Image: rainy_2275.jpg, Loss_G: 19.2568, Loss_D_A: 0.0242, Loss_D_B: 0.0383\n",
            "Epoch 6/70, Batch 15/25, Image: rainy_1690.jpg, Loss_G: 18.0574, Loss_D_A: 0.0434, Loss_D_B: 0.0583\n",
            "Epoch 6/70, Batch 16/25, Image: rainy_902.jpg, Loss_G: 12.9548, Loss_D_A: 0.0233, Loss_D_B: 0.0717\n",
            "Epoch 6/70, Batch 17/25, Image: rainy_1820 (1).jpg, Loss_G: 15.7526, Loss_D_A: 0.0140, Loss_D_B: 0.0845\n",
            "Epoch 6/70, Batch 18/25, Image: rainy_3795.jpg, Loss_G: 13.6507, Loss_D_A: 0.0218, Loss_D_B: 0.1148\n",
            "Epoch 6/70, Batch 19/25, Image: rainy_3769.jpg, Loss_G: 14.5492, Loss_D_A: 0.0156, Loss_D_B: 0.1068\n",
            "Epoch 6/70, Batch 20/25, Image: rainy_826.jpg, Loss_G: 12.8558, Loss_D_A: 0.0229, Loss_D_B: 0.0671\n",
            "Epoch 6/70, Batch 21/25, Image: rainy_1269.jpg, Loss_G: 12.3936, Loss_D_A: 0.0247, Loss_D_B: 0.0388\n",
            "Epoch 6/70, Batch 22/25, Image: rainy_3063.jpg, Loss_G: 13.5909, Loss_D_A: 0.0220, Loss_D_B: 0.0297\n",
            "Epoch 6/70, Batch 23/25, Image: rainy_2004.jpg, Loss_G: 16.0105, Loss_D_A: 0.0142, Loss_D_B: 0.0240\n",
            "Epoch 6/70, Batch 24/25, Image: rainy_1957.jpg, Loss_G: 19.9319, Loss_D_A: 0.0445, Loss_D_B: 0.0388\n",
            "Epoch 7/70, Batch 0/25, Image: rainy_1899.jpg, Loss_G: 21.8561, Loss_D_A: 0.0404, Loss_D_B: 0.0443\n",
            "Epoch 7/70, Batch 1/25, Image: rainy_413.jpg, Loss_G: 13.6420, Loss_D_A: 0.0220, Loss_D_B: 0.0351\n",
            "Epoch 7/70, Batch 2/25, Image: rainy_260.jpg, Loss_G: 16.2862, Loss_D_A: 0.0215, Loss_D_B: 0.0180\n",
            "Epoch 7/70, Batch 3/25, Image: rainy_2814.jpg, Loss_G: 14.1010, Loss_D_A: 0.0371, Loss_D_B: 0.0125\n",
            "Epoch 7/70, Batch 4/25, Image: rainy_2259.jpg, Loss_G: 12.7365, Loss_D_A: 0.0272, Loss_D_B: 0.0125\n",
            "Epoch 7/70, Batch 5/25, Image: rainy_429.jpg, Loss_G: 14.9476, Loss_D_A: 0.0558, Loss_D_B: 0.0124\n",
            "Epoch 7/70, Batch 6/25, Image: rainy_3010.jpg, Loss_G: 14.4568, Loss_D_A: 0.0601, Loss_D_B: 0.0208\n",
            "Epoch 7/70, Batch 7/25, Image: rainy_2857.jpg, Loss_G: 13.5805, Loss_D_A: 0.0539, Loss_D_B: 0.0172\n",
            "Epoch 7/70, Batch 8/25, Image: rainy_3342.jpg, Loss_G: 15.7272, Loss_D_A: 0.0360, Loss_D_B: 0.0115\n",
            "Epoch 7/70, Batch 9/25, Image: rainy_904.jpg, Loss_G: 15.5379, Loss_D_A: 0.0158, Loss_D_B: 0.0098\n",
            "Epoch 7/70, Batch 10/25, Image: rainy_3355.jpg, Loss_G: 13.2892, Loss_D_A: 0.0387, Loss_D_B: 0.0098\n",
            "Epoch 7/70, Batch 11/25, Image: rainy_1931.jpg, Loss_G: 12.2625, Loss_D_A: 0.0284, Loss_D_B: 0.0098\n",
            "Epoch 7/70, Batch 12/25, Image: rainy_3193.jpg, Loss_G: 14.1344, Loss_D_A: 0.0196, Loss_D_B: 0.0098\n",
            "Epoch 7/70, Batch 13/25, Image: rainy_2460.jpg, Loss_G: 13.4507, Loss_D_A: 0.0204, Loss_D_B: 0.0245\n",
            "Epoch 7/70, Batch 14/25, Image: rainy_3090.jpg, Loss_G: 14.7362, Loss_D_A: 0.0213, Loss_D_B: 0.0367\n",
            "Epoch 7/70, Batch 15/25, Image: rainy_298.jpg, Loss_G: 13.3059, Loss_D_A: 0.0157, Loss_D_B: 0.0215\n",
            "Epoch 7/70, Batch 16/25, Image: rainy_3769.jpg, Loss_G: 13.6945, Loss_D_A: 0.0126, Loss_D_B: 0.0090\n",
            "Epoch 7/70, Batch 17/25, Image: rainy_2973.jpg, Loss_G: 13.2488, Loss_D_A: 0.0162, Loss_D_B: 0.0129\n",
            "Epoch 7/70, Batch 18/25, Image: rainy_2197.jpg, Loss_G: 17.4804, Loss_D_A: 0.0393, Loss_D_B: 0.0198\n",
            "Epoch 7/70, Batch 19/25, Image: rainy_2836.jpg, Loss_G: 13.3101, Loss_D_A: 0.0476, Loss_D_B: 0.0227\n",
            "Epoch 7/70, Batch 20/25, Image: rainy_1059.jpg, Loss_G: 16.1424, Loss_D_A: 0.0350, Loss_D_B: 0.0163\n",
            "Epoch 7/70, Batch 21/25, Image: rainy_2787.jpg, Loss_G: 13.9518, Loss_D_A: 0.0338, Loss_D_B: 0.0148\n",
            "Epoch 7/70, Batch 22/25, Image: rainy_923.jpg, Loss_G: 14.4794, Loss_D_A: 0.0264, Loss_D_B: 0.0103\n",
            "Epoch 7/70, Batch 23/25, Image: rainy_2943.jpg, Loss_G: 11.7198, Loss_D_A: 0.0160, Loss_D_B: 0.0089\n",
            "Epoch 7/70, Batch 24/25, Image: rainy_902.jpg, Loss_G: 13.6888, Loss_D_A: 0.0149, Loss_D_B: 0.0185\n",
            "Epoch 8/70, Batch 0/25, Image: rainy_752.jpg, Loss_G: 15.4842, Loss_D_A: 0.0196, Loss_D_B: 0.0164\n",
            "Epoch 8/70, Batch 1/25, Image: rainy_2859.jpg, Loss_G: 11.7081, Loss_D_A: 0.0212, Loss_D_B: 0.0187\n",
            "Epoch 8/70, Batch 2/25, Image: rainy_1820 (1).jpg, Loss_G: 14.4041, Loss_D_A: 0.0287, Loss_D_B: 0.0388\n",
            "Epoch 8/70, Batch 3/25, Image: rainy_2628.jpg, Loss_G: 15.5813, Loss_D_A: 0.0200, Loss_D_B: 0.0308\n",
            "Epoch 8/70, Batch 4/25, Image: rainy_902.jpg, Loss_G: 13.8451, Loss_D_A: 0.0247, Loss_D_B: 0.0122\n",
            "Epoch 8/70, Batch 5/25, Image: rainy_1669.jpg, Loss_G: 13.4108, Loss_D_A: 0.0206, Loss_D_B: 0.0245\n",
            "Epoch 8/70, Batch 6/25, Image: rainy_3371.jpg, Loss_G: 19.6595, Loss_D_A: 0.0438, Loss_D_B: 0.0565\n",
            "Epoch 8/70, Batch 7/25, Image: rainy_1426.jpg, Loss_G: 12.3315, Loss_D_A: 0.0297, Loss_D_B: 0.0326\n",
            "Epoch 8/70, Batch 8/25, Image: rainy_2259.jpg, Loss_G: 12.3437, Loss_D_A: 0.0144, Loss_D_B: 0.0149\n",
            "Epoch 8/70, Batch 9/25, Image: rainy_3156.jpg, Loss_G: 13.7742, Loss_D_A: 0.0144, Loss_D_B: 0.0157\n",
            "Epoch 8/70, Batch 10/25, Image: rainy_2838.jpg, Loss_G: 16.2359, Loss_D_A: 0.0171, Loss_D_B: 0.0212\n",
            "Epoch 8/70, Batch 11/25, Image: rainy_518.jpg, Loss_G: 19.3450, Loss_D_A: 0.0115, Loss_D_B: 0.0244\n",
            "Epoch 8/70, Batch 12/25, Image: rainy_1172.jpg, Loss_G: 15.2538, Loss_D_A: 0.0146, Loss_D_B: 0.0178\n",
            "Epoch 8/70, Batch 13/25, Image: rainy_382.jpg, Loss_G: 17.0874, Loss_D_A: 0.0091, Loss_D_B: 0.0087\n",
            "Epoch 8/70, Batch 14/25, Image: rainy_3060.jpg, Loss_G: 16.9744, Loss_D_A: 0.0158, Loss_D_B: 0.0116\n",
            "Epoch 8/70, Batch 15/25, Image: rainy_79.jpg, Loss_G: 13.7882, Loss_D_A: 0.0185, Loss_D_B: 0.0150\n",
            "Epoch 8/70, Batch 16/25, Image: rainy_1185.jpg, Loss_G: 17.3327, Loss_D_A: 0.0189, Loss_D_B: 0.0133\n",
            "Epoch 8/70, Batch 17/25, Image: rainy_3337.jpg, Loss_G: 13.4107, Loss_D_A: 0.0112, Loss_D_B: 0.0085\n",
            "Epoch 8/70, Batch 18/25, Image: rainy_2724.jpg, Loss_G: 11.6070, Loss_D_A: 0.0194, Loss_D_B: 0.0096\n",
            "Epoch 8/70, Batch 19/25, Image: rainy_3213.jpg, Loss_G: 12.6571, Loss_D_A: 0.0319, Loss_D_B: 0.0139\n",
            "Epoch 8/70, Batch 20/25, Image: rainy_2620.jpg, Loss_G: 12.7062, Loss_D_A: 0.0270, Loss_D_B: 0.0189\n",
            "Epoch 8/70, Batch 21/25, Image: rainy_2973.jpg, Loss_G: 14.4911, Loss_D_A: 0.0132, Loss_D_B: 0.0135\n",
            "Epoch 8/70, Batch 22/25, Image: rainy_170.jpg, Loss_G: 12.8785, Loss_D_A: 0.0121, Loss_D_B: 0.0120\n",
            "Epoch 8/70, Batch 23/25, Image: rainy_119.jpg, Loss_G: 12.8424, Loss_D_A: 0.0114, Loss_D_B: 0.0117\n",
            "Epoch 8/70, Batch 24/25, Image: rainy_537.jpg, Loss_G: 11.5917, Loss_D_A: 0.0094, Loss_D_B: 0.0081\n",
            "Epoch 9/70, Batch 0/25, Image: rainy_1071.jpg, Loss_G: 17.7293, Loss_D_A: 0.0263, Loss_D_B: 0.0163\n",
            "Epoch 9/70, Batch 1/25, Image: rainy_170.jpg, Loss_G: 13.7497, Loss_D_A: 0.0337, Loss_D_B: 0.0240\n",
            "Epoch 9/70, Batch 2/25, Image: rainy_1931.jpg, Loss_G: 12.6305, Loss_D_A: 0.0151, Loss_D_B: 0.0127\n",
            "Epoch 9/70, Batch 3/25, Image: rainy_2570.jpg, Loss_G: 13.7087, Loss_D_A: 0.0133, Loss_D_B: 0.0097\n",
            "Epoch 9/70, Batch 4/25, Image: rainy_3445.jpg, Loss_G: 12.5070, Loss_D_A: 0.0124, Loss_D_B: 0.0163\n",
            "Epoch 9/70, Batch 5/25, Image: rainy_2943.jpg, Loss_G: 12.9651, Loss_D_A: 0.0169, Loss_D_B: 0.0174\n",
            "Epoch 9/70, Batch 6/25, Image: rainy_2747.jpg, Loss_G: 11.2902, Loss_D_A: 0.0152, Loss_D_B: 0.0113\n",
            "Epoch 9/70, Batch 7/25, Image: rainy_2114.jpg, Loss_G: 14.2184, Loss_D_A: 0.0135, Loss_D_B: 0.0069\n",
            "Epoch 9/70, Batch 8/25, Image: rainy_3813.jpg, Loss_G: 10.8493, Loss_D_A: 0.0091, Loss_D_B: 0.0082\n",
            "Epoch 9/70, Batch 9/25, Image: rainy_2779.jpg, Loss_G: 16.3546, Loss_D_A: 0.0149, Loss_D_B: 0.0147\n",
            "Epoch 9/70, Batch 10/25, Image: rainy_3342.jpg, Loss_G: 11.9612, Loss_D_A: 0.0133, Loss_D_B: 0.0148\n",
            "Epoch 9/70, Batch 11/25, Image: rainy_79.jpg, Loss_G: 15.6251, Loss_D_A: 0.0113, Loss_D_B: 0.0130\n",
            "Epoch 9/70, Batch 12/25, Image: rainy_2460.jpg, Loss_G: 14.6089, Loss_D_A: 0.0123, Loss_D_B: 0.0085\n",
            "Epoch 9/70, Batch 13/25, Image: rainy_988.jpg, Loss_G: 13.2113, Loss_D_A: 0.0132, Loss_D_B: 0.0111\n",
            "Epoch 9/70, Batch 14/25, Image: rainy_1237.jpg, Loss_G: 17.5416, Loss_D_A: 0.0231, Loss_D_B: 0.0172\n",
            "Epoch 9/70, Batch 15/25, Image: rainy_1674.jpg, Loss_G: 16.3596, Loss_D_A: 0.0466, Loss_D_B: 0.0169\n",
            "Epoch 9/70, Batch 16/25, Image: rainy_2474.jpg, Loss_G: 12.2738, Loss_D_A: 0.0338, Loss_D_B: 0.0103\n",
            "Epoch 9/70, Batch 17/25, Image: rainy_3156.jpg, Loss_G: 14.2161, Loss_D_A: 0.0138, Loss_D_B: 0.0095\n",
            "Epoch 9/70, Batch 18/25, Image: rainy_3193.jpg, Loss_G: 15.6898, Loss_D_A: 0.0114, Loss_D_B: 0.0089\n",
            "Epoch 9/70, Batch 19/25, Image: rainy_2533.jpg, Loss_G: 13.2849, Loss_D_A: 0.0115, Loss_D_B: 0.0085\n",
            "Epoch 9/70, Batch 20/25, Image: rainy_1599.jpg, Loss_G: 13.7642, Loss_D_A: 0.0129, Loss_D_B: 0.0102\n",
            "Epoch 9/70, Batch 21/25, Image: rainy_859.jpg, Loss_G: 13.9067, Loss_D_A: 0.0114, Loss_D_B: 0.0081\n",
            "Epoch 9/70, Batch 22/25, Image: rainy_3795.jpg, Loss_G: 11.0663, Loss_D_A: 0.0175, Loss_D_B: 0.0066\n",
            "Epoch 9/70, Batch 23/25, Image: rainy_2198.jpg, Loss_G: 16.6919, Loss_D_A: 0.0086, Loss_D_B: 0.0078\n",
            "Epoch 9/70, Batch 24/25, Image: rainy_814.jpg, Loss_G: 15.9611, Loss_D_A: 0.0101, Loss_D_B: 0.0089\n",
            "Epoch 10/70, Batch 0/25, Image: rainy_2977.jpg, Loss_G: 15.9586, Loss_D_A: 0.0100, Loss_D_B: 0.0064\n",
            "Epoch 10/70, Batch 1/25, Image: rainy_298.jpg, Loss_G: 12.4417, Loss_D_A: 0.0121, Loss_D_B: 0.0106\n",
            "Epoch 10/70, Batch 2/25, Image: rainy_1482.jpg, Loss_G: 12.0988, Loss_D_A: 0.0129, Loss_D_B: 0.0106\n",
            "Epoch 10/70, Batch 3/25, Image: rainy_1669.jpg, Loss_G: 15.1843, Loss_D_A: 0.0117, Loss_D_B: 0.0124\n",
            "Epoch 10/70, Batch 4/25, Image: rainy_2779.jpg, Loss_G: 15.9064, Loss_D_A: 0.0166, Loss_D_B: 0.0243\n",
            "Epoch 10/70, Batch 5/25, Image: rainy_3859.jpg, Loss_G: 13.3072, Loss_D_A: 0.0148, Loss_D_B: 0.0328\n",
            "Epoch 10/70, Batch 6/25, Image: rainy_2259.jpg, Loss_G: 17.8088, Loss_D_A: 0.0171, Loss_D_B: 0.0188\n",
            "Epoch 10/70, Batch 7/25, Image: rainy_2263.jpg, Loss_G: 17.7924, Loss_D_A: 0.0158, Loss_D_B: 0.0091\n",
            "Epoch 10/70, Batch 8/25, Image: rainy_184.jpg, Loss_G: 11.3861, Loss_D_A: 0.0121, Loss_D_B: 0.0070\n",
            "Epoch 10/70, Batch 9/25, Image: rainy_540.jpg, Loss_G: 18.0047, Loss_D_A: 0.0080, Loss_D_B: 0.0092\n",
            "Epoch 10/70, Batch 10/25, Image: rainy_3445.jpg, Loss_G: 12.4646, Loss_D_A: 0.0159, Loss_D_B: 0.0176\n",
            "Epoch 10/70, Batch 11/25, Image: rainy_1426.jpg, Loss_G: 15.0472, Loss_D_A: 0.0300, Loss_D_B: 0.0229\n",
            "Epoch 10/70, Batch 12/25, Image: rainy_2431.jpg, Loss_G: 15.0500, Loss_D_A: 0.0227, Loss_D_B: 0.0150\n",
            "Epoch 10/70, Batch 13/25, Image: rainy_491.jpg, Loss_G: 17.0495, Loss_D_A: 0.0104, Loss_D_B: 0.0154\n",
            "Epoch 10/70, Batch 14/25, Image: rainy_2836.jpg, Loss_G: 13.1099, Loss_D_A: 0.0101, Loss_D_B: 0.0166\n",
            "Epoch 10/70, Batch 15/25, Image: rainy_1185.jpg, Loss_G: 13.1383, Loss_D_A: 0.0098, Loss_D_B: 0.0096\n",
            "Epoch 10/70, Batch 16/25, Image: rainy_1674.jpg, Loss_G: 15.9667, Loss_D_A: 0.0088, Loss_D_B: 0.0157\n",
            "Epoch 10/70, Batch 17/25, Image: rainy_2814.jpg, Loss_G: 13.1051, Loss_D_A: 0.0115, Loss_D_B: 0.0128\n",
            "Epoch 10/70, Batch 18/25, Image: rainy_2628.jpg, Loss_G: 10.9459, Loss_D_A: 0.0070, Loss_D_B: 0.0077\n",
            "Epoch 10/70, Batch 19/25, Image: rainy_3014.jpg, Loss_G: 14.5549, Loss_D_A: 0.0117, Loss_D_B: 0.0143\n",
            "Epoch 10/70, Batch 20/25, Image: rainy_2195.jpg, Loss_G: 12.3728, Loss_D_A: 0.0235, Loss_D_B: 0.0309\n",
            "Epoch 10/70, Batch 21/25, Image: rainy_335.jpg, Loss_G: 12.9647, Loss_D_A: 0.0399, Loss_D_B: 0.0436\n",
            "Epoch 10/70, Batch 22/25, Image: rainy_814.jpg, Loss_G: 12.1636, Loss_D_A: 0.0311, Loss_D_B: 0.0279\n",
            "Epoch 10/70, Batch 23/25, Image: rainy_752.jpg, Loss_G: 11.5819, Loss_D_A: 0.0107, Loss_D_B: 0.0094\n",
            "Epoch 10/70, Batch 24/25, Image: rainy_750.jpg, Loss_G: 16.2072, Loss_D_A: 0.0100, Loss_D_B: 0.0092\n",
            "✅ Checkpoint saved at epoch 10\n",
            "Epoch 11/70, Batch 0/25, Image: rainy_3428.jpg, Loss_G: 13.2099, Loss_D_A: 0.0112, Loss_D_B: 0.0084\n",
            "Epoch 11/70, Batch 1/25, Image: rainy_3529.jpg, Loss_G: 13.0971, Loss_D_A: 0.0155, Loss_D_B: 0.0078\n",
            "Epoch 11/70, Batch 2/25, Image: rainy_3398.jpg, Loss_G: 14.9826, Loss_D_A: 0.0135, Loss_D_B: 0.0074\n",
            "Epoch 11/70, Batch 3/25, Image: rainy_1820 (1).jpg, Loss_G: 17.3759, Loss_D_A: 0.0115, Loss_D_B: 0.0075\n",
            "Epoch 11/70, Batch 4/25, Image: rainy_270.jpg, Loss_G: 14.0117, Loss_D_A: 0.0066, Loss_D_B: 0.0065\n",
            "Epoch 11/70, Batch 5/25, Image: rainy_1836.jpg, Loss_G: 16.0141, Loss_D_A: 0.0177, Loss_D_B: 0.0098\n",
            "Epoch 11/70, Batch 6/25, Image: rainy_2257.jpg, Loss_G: 12.6465, Loss_D_A: 0.0192, Loss_D_B: 0.0082\n",
            "Epoch 11/70, Batch 7/25, Image: rainy_2714.jpg, Loss_G: 16.0750, Loss_D_A: 0.0161, Loss_D_B: 0.0142\n",
            "Epoch 11/70, Batch 8/25, Image: rainy_3821.jpg, Loss_G: 11.9462, Loss_D_A: 0.0134, Loss_D_B: 0.0129\n",
            "Epoch 11/70, Batch 9/25, Image: rainy_298.jpg, Loss_G: 14.5670, Loss_D_A: 0.0081, Loss_D_B: 0.0137\n",
            "Epoch 11/70, Batch 10/25, Image: rainy_904.jpg, Loss_G: 13.8821, Loss_D_A: 0.0097, Loss_D_B: 0.0124\n",
            "Epoch 11/70, Batch 11/25, Image: rainy_2857.jpg, Loss_G: 13.0534, Loss_D_A: 0.0167, Loss_D_B: 0.0150\n",
            "Epoch 11/70, Batch 12/25, Image: rainy_166.jpg, Loss_G: 10.7069, Loss_D_A: 0.0175, Loss_D_B: 0.0081\n",
            "Epoch 11/70, Batch 13/25, Image: rainy_868.jpg, Loss_G: 13.5563, Loss_D_A: 0.0161, Loss_D_B: 0.0079\n",
            "Epoch 11/70, Batch 14/25, Image: rainy_3020.jpg, Loss_G: 14.1916, Loss_D_A: 0.0126, Loss_D_B: 0.0079\n",
            "Epoch 11/70, Batch 15/25, Image: rainy_1167.jpg, Loss_G: 12.5658, Loss_D_A: 0.0085, Loss_D_B: 0.0067\n",
            "Epoch 11/70, Batch 16/25, Image: rainy_328.jpg, Loss_G: 12.3965, Loss_D_A: 0.0081, Loss_D_B: 0.0092\n",
            "Epoch 11/70, Batch 17/25, Image: rainy_1432.jpg, Loss_G: 11.9226, Loss_D_A: 0.0076, Loss_D_B: 0.0115\n",
            "Epoch 11/70, Batch 18/25, Image: rainy_2259.jpg, Loss_G: 12.2917, Loss_D_A: 0.0117, Loss_D_B: 0.0148\n",
            "Epoch 11/70, Batch 19/25, Image: rainy_1080.jpg, Loss_G: 13.6756, Loss_D_A: 0.0122, Loss_D_B: 0.0129\n",
            "Epoch 11/70, Batch 20/25, Image: rainy_849.jpg, Loss_G: 12.0897, Loss_D_A: 0.0102, Loss_D_B: 0.0162\n",
            "Epoch 11/70, Batch 21/25, Image: rainy_1899.jpg, Loss_G: 11.8118, Loss_D_A: 0.0117, Loss_D_B: 0.0184\n",
            "Epoch 11/70, Batch 22/25, Image: rainy_865.jpg, Loss_G: 14.3410, Loss_D_A: 0.0211, Loss_D_B: 0.0194\n",
            "Epoch 11/70, Batch 23/25, Image: rainy_2968.jpg, Loss_G: 13.1608, Loss_D_A: 0.0225, Loss_D_B: 0.0153\n",
            "Epoch 11/70, Batch 24/25, Image: rainy_2160.jpg, Loss_G: 13.3332, Loss_D_A: 0.0195, Loss_D_B: 0.0089\n",
            "Epoch 12/70, Batch 0/25, Image: rainy_3606.jpg, Loss_G: 11.7131, Loss_D_A: 0.0133, Loss_D_B: 0.0055\n",
            "Epoch 12/70, Batch 1/25, Image: rainy_3911.jpg, Loss_G: 12.4530, Loss_D_A: 0.0148, Loss_D_B: 0.0078\n",
            "Epoch 12/70, Batch 2/25, Image: rainy_2952.jpg, Loss_G: 12.6189, Loss_D_A: 0.0147, Loss_D_B: 0.0086\n",
            "Epoch 12/70, Batch 3/25, Image: rainy_2985.jpg, Loss_G: 12.2206, Loss_D_A: 0.0244, Loss_D_B: 0.0168\n",
            "Epoch 12/70, Batch 4/25, Image: rainy_1966.jpg, Loss_G: 11.7768, Loss_D_A: 0.0276, Loss_D_B: 0.0250\n",
            "Epoch 12/70, Batch 5/25, Image: rainy_748.jpg, Loss_G: 10.6871, Loss_D_A: 0.0088, Loss_D_B: 0.0190\n",
            "Epoch 12/70, Batch 6/25, Image: rainy_2838.jpg, Loss_G: 10.9559, Loss_D_A: 0.0132, Loss_D_B: 0.0126\n",
            "Epoch 12/70, Batch 7/25, Image: rainy_3014.jpg, Loss_G: 12.4196, Loss_D_A: 0.0233, Loss_D_B: 0.0118\n",
            "Epoch 12/70, Batch 8/25, Image: rainy_1508.jpg, Loss_G: 14.8818, Loss_D_A: 0.0179, Loss_D_B: 0.0091\n",
            "Epoch 12/70, Batch 9/25, Image: rainy_1091.jpg, Loss_G: 16.1182, Loss_D_A: 0.0077, Loss_D_B: 0.0056\n",
            "Epoch 12/70, Batch 10/25, Image: rainy_3010.jpg, Loss_G: 12.0507, Loss_D_A: 0.0112, Loss_D_B: 0.0069\n",
            "Epoch 12/70, Batch 11/25, Image: rainy_332.jpg, Loss_G: 14.2711, Loss_D_A: 0.0146, Loss_D_B: 0.0134\n",
            "Epoch 12/70, Batch 12/25, Image: rainy_3337.jpg, Loss_G: 14.8967, Loss_D_A: 0.0243, Loss_D_B: 0.0227\n",
            "Epoch 12/70, Batch 13/25, Image: rainy_1733.jpg, Loss_G: 13.1285, Loss_D_A: 0.0233, Loss_D_B: 0.0228\n",
            "Epoch 12/70, Batch 14/25, Image: rainy_2859.jpg, Loss_G: 13.0973, Loss_D_A: 0.0115, Loss_D_B: 0.0146\n",
            "Epoch 12/70, Batch 15/25, Image: rainy_3385.jpg, Loss_G: 11.2969, Loss_D_A: 0.0067, Loss_D_B: 0.0098\n",
            "Epoch 12/70, Batch 16/25, Image: rainy_3509.jpg, Loss_G: 11.3749, Loss_D_A: 0.0087, Loss_D_B: 0.0045\n",
            "Epoch 12/70, Batch 17/25, Image: rainy_923.jpg, Loss_G: 11.9826, Loss_D_A: 0.0167, Loss_D_B: 0.0050\n",
            "Epoch 12/70, Batch 18/25, Image: rainy_3136.jpg, Loss_G: 13.3344, Loss_D_A: 0.0124, Loss_D_B: 0.0060\n",
            "Epoch 12/70, Batch 19/25, Image: rainy_1591.jpg, Loss_G: 12.8312, Loss_D_A: 0.0080, Loss_D_B: 0.0087\n",
            "Epoch 12/70, Batch 20/25, Image: rainy_3795.jpg, Loss_G: 10.9100, Loss_D_A: 0.0117, Loss_D_B: 0.0075\n",
            "Epoch 12/70, Batch 21/25, Image: rainy_1761.jpg, Loss_G: 12.3412, Loss_D_A: 0.0103, Loss_D_B: 0.0101\n",
            "Epoch 12/70, Batch 22/25, Image: rainy_1426.jpg, Loss_G: 15.1078, Loss_D_A: 0.0135, Loss_D_B: 0.0107\n",
            "Epoch 12/70, Batch 23/25, Image: rainy_1237.jpg, Loss_G: 15.0936, Loss_D_A: 0.0152, Loss_D_B: 0.0112\n",
            "Epoch 12/70, Batch 24/25, Image: rainy_814.jpg, Loss_G: 12.5730, Loss_D_A: 0.0059, Loss_D_B: 0.0076\n",
            "Epoch 13/70, Batch 0/25, Image: rainy_3428.jpg, Loss_G: 12.9369, Loss_D_A: 0.0122, Loss_D_B: 0.0059\n",
            "Epoch 13/70, Batch 1/25, Image: rainy_3164.jpg, Loss_G: 11.1098, Loss_D_A: 0.0165, Loss_D_B: 0.0149\n",
            "Epoch 13/70, Batch 2/25, Image: rainy_2492.jpg, Loss_G: 11.6558, Loss_D_A: 0.0211, Loss_D_B: 0.0209\n",
            "Epoch 13/70, Batch 3/25, Image: rainy_1662.jpg, Loss_G: 12.1744, Loss_D_A: 0.0145, Loss_D_B: 0.0128\n",
            "Epoch 13/70, Batch 4/25, Image: rainy_3398.jpg, Loss_G: 13.1014, Loss_D_A: 0.0068, Loss_D_B: 0.0111\n",
            "Epoch 13/70, Batch 5/25, Image: rainy_3213.jpg, Loss_G: 11.4845, Loss_D_A: 0.0087, Loss_D_B: 0.0132\n",
            "Epoch 13/70, Batch 6/25, Image: rainy_3019.jpg, Loss_G: 13.0437, Loss_D_A: 0.0071, Loss_D_B: 0.0076\n",
            "Epoch 13/70, Batch 7/25, Image: rainy_3951.jpg, Loss_G: 11.4557, Loss_D_A: 0.0126, Loss_D_B: 0.0080\n",
            "Epoch 13/70, Batch 8/25, Image: rainy_1228.jpg, Loss_G: 12.9400, Loss_D_A: 0.0152, Loss_D_B: 0.0118\n",
            "Epoch 13/70, Batch 9/25, Image: rainy_3756.jpg, Loss_G: 11.9844, Loss_D_A: 0.0123, Loss_D_B: 0.0197\n",
            "Epoch 13/70, Batch 10/25, Image: rainy_1876.jpg, Loss_G: 12.6433, Loss_D_A: 0.0054, Loss_D_B: 0.0180\n",
            "Epoch 13/70, Batch 11/25, Image: rainy_3813.jpg, Loss_G: 14.5184, Loss_D_A: 0.0116, Loss_D_B: 0.0132\n",
            "Epoch 13/70, Batch 12/25, Image: rainy_3385.jpg, Loss_G: 11.9732, Loss_D_A: 0.0125, Loss_D_B: 0.0080\n",
            "Epoch 13/70, Batch 13/25, Image: rainy_1269.jpg, Loss_G: 16.0014, Loss_D_A: 0.0080, Loss_D_B: 0.0067\n",
            "Epoch 13/70, Batch 14/25, Image: rainy_3156.jpg, Loss_G: 15.0805, Loss_D_A: 0.0267, Loss_D_B: 0.0088\n",
            "Epoch 13/70, Batch 15/25, Image: rainy_750.jpg, Loss_G: 20.4664, Loss_D_A: 0.0632, Loss_D_B: 0.0164\n",
            "Epoch 13/70, Batch 16/25, Image: rainy_1931.jpg, Loss_G: 12.0235, Loss_D_A: 0.0636, Loss_D_B: 0.0269\n",
            "Epoch 13/70, Batch 17/25, Image: rainy_3020.jpg, Loss_G: 12.6333, Loss_D_A: 0.0325, Loss_D_B: 0.0294\n",
            "Epoch 13/70, Batch 18/25, Image: rainy_491.jpg, Loss_G: 16.6693, Loss_D_A: 0.0134, Loss_D_B: 0.0238\n",
            "Epoch 13/70, Batch 19/25, Image: rainy_2973.jpg, Loss_G: 14.2593, Loss_D_A: 0.0130, Loss_D_B: 0.0200\n",
            "Epoch 13/70, Batch 20/25, Image: rainy_2544.jpg, Loss_G: 11.8561, Loss_D_A: 0.0074, Loss_D_B: 0.0131\n",
            "Epoch 13/70, Batch 21/25, Image: rainy_2759.jpg, Loss_G: 13.2057, Loss_D_A: 0.0094, Loss_D_B: 0.0110\n",
            "Epoch 13/70, Batch 22/25, Image: rainy_912.jpg, Loss_G: 12.7909, Loss_D_A: 0.0071, Loss_D_B: 0.0091\n",
            "Epoch 13/70, Batch 23/25, Image: rainy_267.jpg, Loss_G: 13.8354, Loss_D_A: 0.0053, Loss_D_B: 0.0064\n",
            "Epoch 13/70, Batch 24/25, Image: rainy_1471.jpg, Loss_G: 13.1373, Loss_D_A: 0.0061, Loss_D_B: 0.0064\n",
            "Epoch 14/70, Batch 0/25, Image: rainy_3710.jpg, Loss_G: 9.8723, Loss_D_A: 0.0052, Loss_D_B: 0.0055\n",
            "Epoch 14/70, Batch 1/25, Image: rainy_232.jpg, Loss_G: 16.2799, Loss_D_A: 0.0078, Loss_D_B: 0.0068\n",
            "Epoch 14/70, Batch 2/25, Image: rainy_3019.jpg, Loss_G: 11.9906, Loss_D_A: 0.0087, Loss_D_B: 0.0055\n",
            "Epoch 14/70, Batch 3/25, Image: rainy_267.jpg, Loss_G: 15.6526, Loss_D_A: 0.0112, Loss_D_B: 0.0058\n",
            "Epoch 14/70, Batch 4/25, Image: rainy_332.jpg, Loss_G: 13.5118, Loss_D_A: 0.0148, Loss_D_B: 0.0128\n",
            "Epoch 14/70, Batch 5/25, Image: rainy_3010.jpg, Loss_G: 12.1787, Loss_D_A: 0.0242, Loss_D_B: 0.0177\n",
            "Epoch 14/70, Batch 6/25, Image: rainy_3363.jpg, Loss_G: 11.4238, Loss_D_A: 0.0149, Loss_D_B: 0.0118\n",
            "Epoch 14/70, Batch 7/25, Image: rainy_2814.jpg, Loss_G: 13.4901, Loss_D_A: 0.0136, Loss_D_B: 0.0096\n",
            "Epoch 14/70, Batch 8/25, Image: rainy_1742.jpg, Loss_G: 22.1901, Loss_D_A: 0.0119, Loss_D_B: 0.0104\n",
            "Epoch 14/70, Batch 9/25, Image: rainy_1784.jpg, Loss_G: 13.8323, Loss_D_A: 0.0092, Loss_D_B: 0.0121\n",
            "Epoch 14/70, Batch 10/25, Image: rainy_1228.jpg, Loss_G: 12.4728, Loss_D_A: 0.0106, Loss_D_B: 0.0103\n",
            "Epoch 14/70, Batch 11/25, Image: rainy_2619.jpg, Loss_G: 11.3568, Loss_D_A: 0.0169, Loss_D_B: 0.0080\n",
            "Epoch 14/70, Batch 12/25, Image: rainy_1530.jpg, Loss_G: 13.0311, Loss_D_A: 0.0146, Loss_D_B: 0.0068\n",
            "Epoch 14/70, Batch 13/25, Image: rainy_2132.jpg, Loss_G: 12.0087, Loss_D_A: 0.0097, Loss_D_B: 0.0053\n",
            "Epoch 14/70, Batch 14/25, Image: rainy_3703.jpg, Loss_G: 12.6636, Loss_D_A: 0.0058, Loss_D_B: 0.0043\n",
            "Epoch 14/70, Batch 15/25, Image: rainy_298.jpg, Loss_G: 10.2872, Loss_D_A: 0.0088, Loss_D_B: 0.0057\n",
            "Epoch 14/70, Batch 16/25, Image: rainy_2197.jpg, Loss_G: 10.4917, Loss_D_A: 0.0079, Loss_D_B: 0.0066\n",
            "Epoch 14/70, Batch 17/25, Image: rainy_481.jpg, Loss_G: 11.7141, Loss_D_A: 0.0164, Loss_D_B: 0.0066\n",
            "Epoch 14/70, Batch 18/25, Image: rainy_382.jpg, Loss_G: 10.4005, Loss_D_A: 0.0149, Loss_D_B: 0.0060\n",
            "Epoch 14/70, Batch 19/25, Image: rainy_184.jpg, Loss_G: 12.0088, Loss_D_A: 0.0073, Loss_D_B: 0.0051\n",
            "Epoch 14/70, Batch 20/25, Image: rainy_926.jpg, Loss_G: 11.5862, Loss_D_A: 0.0056, Loss_D_B: 0.0060\n",
            "Epoch 14/70, Batch 21/25, Image: rainy_2779.jpg, Loss_G: 12.9459, Loss_D_A: 0.0070, Loss_D_B: 0.0051\n",
            "Epoch 14/70, Batch 22/25, Image: rainy_2060.jpg, Loss_G: 13.7242, Loss_D_A: 0.0097, Loss_D_B: 0.0045\n",
            "Epoch 14/70, Batch 23/25, Image: rainy_2838.jpg, Loss_G: 14.0954, Loss_D_A: 0.0095, Loss_D_B: 0.0094\n",
            "Epoch 14/70, Batch 24/25, Image: rainy_2160.jpg, Loss_G: 15.7635, Loss_D_A: 0.0049, Loss_D_B: 0.0126\n",
            "Epoch 15/70, Batch 0/25, Image: rainy_1761.jpg, Loss_G: 12.8759, Loss_D_A: 0.0079, Loss_D_B: 0.0108\n",
            "Epoch 15/70, Batch 1/25, Image: rainy_3445.jpg, Loss_G: 14.0390, Loss_D_A: 0.0094, Loss_D_B: 0.0081\n",
            "Epoch 15/70, Batch 2/25, Image: rainy_1599.jpg, Loss_G: 16.0756, Loss_D_A: 0.0102, Loss_D_B: 0.0059\n",
            "Epoch 15/70, Batch 3/25, Image: rainy_429.jpg, Loss_G: 12.9467, Loss_D_A: 0.0262, Loss_D_B: 0.0062\n",
            "Epoch 15/70, Batch 4/25, Image: rainy_398.jpg, Loss_G: 12.5890, Loss_D_A: 0.0321, Loss_D_B: 0.0079\n",
            "Epoch 15/70, Batch 5/25, Image: rainy_2431.jpg, Loss_G: 13.6998, Loss_D_A: 0.0121, Loss_D_B: 0.0053\n",
            "Epoch 15/70, Batch 6/25, Image: rainy_2453.jpg, Loss_G: 12.3400, Loss_D_A: 0.0151, Loss_D_B: 0.0166\n",
            "Epoch 15/70, Batch 7/25, Image: rainy_3019.jpg, Loss_G: 13.4297, Loss_D_A: 0.0466, Loss_D_B: 0.0390\n",
            "Epoch 15/70, Batch 8/25, Image: rainy_2197.jpg, Loss_G: 13.7897, Loss_D_A: 0.0703, Loss_D_B: 0.0695\n",
            "Epoch 15/70, Batch 9/25, Image: rainy_2259.jpg, Loss_G: 10.8938, Loss_D_A: 0.0604, Loss_D_B: 0.0738\n",
            "Epoch 15/70, Batch 10/25, Image: rainy_3911.jpg, Loss_G: 12.0313, Loss_D_A: 0.0329, Loss_D_B: 0.0712\n",
            "Epoch 15/70, Batch 11/25, Image: rainy_2968.jpg, Loss_G: 10.6492, Loss_D_A: 0.0172, Loss_D_B: 0.0564\n",
            "Epoch 15/70, Batch 12/25, Image: rainy_2474.jpg, Loss_G: 13.0530, Loss_D_A: 0.0103, Loss_D_B: 0.0298\n",
            "Epoch 15/70, Batch 13/25, Image: rainy_923.jpg, Loss_G: 11.3171, Loss_D_A: 0.0114, Loss_D_B: 0.0154\n",
            "Epoch 15/70, Batch 14/25, Image: rainy_3078.jpg, Loss_G: 10.6647, Loss_D_A: 0.0102, Loss_D_B: 0.0100\n",
            "Epoch 15/70, Batch 15/25, Image: rainy_3756.jpg, Loss_G: 13.7173, Loss_D_A: 0.0115, Loss_D_B: 0.0122\n",
            "Epoch 15/70, Batch 16/25, Image: rainy_2544.jpg, Loss_G: 10.3253, Loss_D_A: 0.0065, Loss_D_B: 0.0215\n",
            "Epoch 15/70, Batch 17/25, Image: rainy_2570.jpg, Loss_G: 12.7062, Loss_D_A: 0.0093, Loss_D_B: 0.0363\n",
            "Epoch 15/70, Batch 18/25, Image: rainy_1555.jpg, Loss_G: 13.5882, Loss_D_A: 0.0072, Loss_D_B: 0.0474\n",
            "Epoch 15/70, Batch 19/25, Image: rainy_1957.jpg, Loss_G: 13.3690, Loss_D_A: 0.0068, Loss_D_B: 0.0443\n",
            "Epoch 15/70, Batch 20/25, Image: rainy_2714.jpg, Loss_G: 14.7888, Loss_D_A: 0.0085, Loss_D_B: 0.0162\n",
            "Epoch 15/70, Batch 21/25, Image: rainy_3813.jpg, Loss_G: 12.2397, Loss_D_A: 0.0078, Loss_D_B: 0.0130\n",
            "Epoch 15/70, Batch 22/25, Image: rainy_2404.jpg, Loss_G: 14.9104, Loss_D_A: 0.0070, Loss_D_B: 0.0197\n",
            "Epoch 15/70, Batch 23/25, Image: rainy_1784.jpg, Loss_G: 14.4528, Loss_D_A: 0.0130, Loss_D_B: 0.0387\n",
            "Epoch 15/70, Batch 24/25, Image: rainy_1639.jpg, Loss_G: 12.2096, Loss_D_A: 0.0238, Loss_D_B: 0.0401\n",
            "✅ Checkpoint saved at epoch 15\n",
            "Epoch 16/70, Batch 0/25, Image: rainy_3398.jpg, Loss_G: 13.7678, Loss_D_A: 0.0210, Loss_D_B: 0.0282\n",
            "Epoch 16/70, Batch 1/25, Image: rainy_447.jpg, Loss_G: 11.0297, Loss_D_A: 0.0147, Loss_D_B: 0.0091\n",
            "Epoch 16/70, Batch 2/25, Image: rainy_3428.jpg, Loss_G: 15.2948, Loss_D_A: 0.0102, Loss_D_B: 0.0065\n",
            "Epoch 16/70, Batch 3/25, Image: rainy_3859.jpg, Loss_G: 14.1604, Loss_D_A: 0.0107, Loss_D_B: 0.0085\n",
            "Epoch 16/70, Batch 4/25, Image: rainy_2346.jpg, Loss_G: 10.3967, Loss_D_A: 0.0086, Loss_D_B: 0.0127\n",
            "Epoch 16/70, Batch 5/25, Image: rainy_2968.jpg, Loss_G: 16.7742, Loss_D_A: 0.0081, Loss_D_B: 0.0079\n",
            "Epoch 16/70, Batch 6/25, Image: rainy_865.jpg, Loss_G: 15.6835, Loss_D_A: 0.0067, Loss_D_B: 0.0075\n",
            "Epoch 16/70, Batch 7/25, Image: rainy_1931.jpg, Loss_G: 10.2459, Loss_D_A: 0.0054, Loss_D_B: 0.0109\n",
            "Epoch 16/70, Batch 8/25, Image: rainy_1237.jpg, Loss_G: 11.5035, Loss_D_A: 0.0059, Loss_D_B: 0.0103\n",
            "Epoch 16/70, Batch 9/25, Image: rainy_859.jpg, Loss_G: 11.2049, Loss_D_A: 0.0097, Loss_D_B: 0.0062\n",
            "Epoch 16/70, Batch 10/25, Image: rainy_2544.jpg, Loss_G: 10.5587, Loss_D_A: 0.0101, Loss_D_B: 0.0076\n",
            "Epoch 16/70, Batch 11/25, Image: rainy_814.jpg, Loss_G: 11.7883, Loss_D_A: 0.0055, Loss_D_B: 0.0067\n",
            "Epoch 16/70, Batch 12/25, Image: rainy_3014.jpg, Loss_G: 11.8590, Loss_D_A: 0.0078, Loss_D_B: 0.0081\n",
            "Epoch 16/70, Batch 13/25, Image: rainy_475.jpg, Loss_G: 9.5258, Loss_D_A: 0.0075, Loss_D_B: 0.0108\n",
            "Epoch 16/70, Batch 14/25, Image: rainy_2877.jpg, Loss_G: 13.1750, Loss_D_A: 0.0068, Loss_D_B: 0.0086\n",
            "Epoch 16/70, Batch 15/25, Image: rainy_1771.jpg, Loss_G: 16.5096, Loss_D_A: 0.0066, Loss_D_B: 0.0121\n",
            "Epoch 16/70, Batch 16/25, Image: rainy_2620.jpg, Loss_G: 12.3957, Loss_D_A: 0.0223, Loss_D_B: 0.0362\n",
            "Epoch 16/70, Batch 17/25, Image: rainy_3371.jpg, Loss_G: 13.8855, Loss_D_A: 0.0087, Loss_D_B: 0.0251\n",
            "Epoch 16/70, Batch 18/25, Image: rainy_849.jpg, Loss_G: 14.9689, Loss_D_A: 0.0188, Loss_D_B: 0.0114\n",
            "Epoch 16/70, Batch 19/25, Image: rainy_3355.jpg, Loss_G: 11.4092, Loss_D_A: 0.0467, Loss_D_B: 0.0181\n",
            "Epoch 16/70, Batch 20/25, Image: rainy_3010.jpg, Loss_G: 13.3444, Loss_D_A: 0.0195, Loss_D_B: 0.0177\n",
            "Epoch 16/70, Batch 21/25, Image: rainy_2570.jpg, Loss_G: 13.2969, Loss_D_A: 0.0067, Loss_D_B: 0.0188\n",
            "Epoch 16/70, Batch 22/25, Image: rainy_826.jpg, Loss_G: 10.8954, Loss_D_A: 0.0128, Loss_D_B: 0.0207\n",
            "Epoch 16/70, Batch 23/25, Image: rainy_1471.jpg, Loss_G: 11.8814, Loss_D_A: 0.0104, Loss_D_B: 0.0100\n",
            "Epoch 16/70, Batch 24/25, Image: rainy_2836.jpg, Loss_G: 10.8895, Loss_D_A: 0.0087, Loss_D_B: 0.0059\n",
            "Epoch 17/70, Batch 0/25, Image: rainy_3661.jpg, Loss_G: 13.9951, Loss_D_A: 0.0078, Loss_D_B: 0.0049\n",
            "Epoch 17/70, Batch 1/25, Image: rainy_3911.jpg, Loss_G: 13.0891, Loss_D_A: 0.0225, Loss_D_B: 0.0100\n",
            "Epoch 17/70, Batch 2/25, Image: rainy_1761.jpg, Loss_G: 13.0057, Loss_D_A: 0.0625, Loss_D_B: 0.0200\n",
            "Epoch 17/70, Batch 3/25, Image: rainy_1966.jpg, Loss_G: 18.4303, Loss_D_A: 0.0225, Loss_D_B: 0.0085\n",
            "Epoch 17/70, Batch 4/25, Image: rainy_859.jpg, Loss_G: 10.4257, Loss_D_A: 0.0320, Loss_D_B: 0.0302\n",
            "Epoch 17/70, Batch 5/25, Image: rainy_1071.jpg, Loss_G: 10.8718, Loss_D_A: 0.1177, Loss_D_B: 0.0844\n",
            "Epoch 17/70, Batch 6/25, Image: rainy_3606.jpg, Loss_G: 12.1719, Loss_D_A: 0.0633, Loss_D_B: 0.0461\n",
            "Epoch 17/70, Batch 7/25, Image: rainy_1059.jpg, Loss_G: 12.4964, Loss_D_A: 0.0071, Loss_D_B: 0.0100\n",
            "Epoch 17/70, Batch 8/25, Image: rainy_3385.jpg, Loss_G: 13.8229, Loss_D_A: 0.0191, Loss_D_B: 0.0103\n",
            "Epoch 17/70, Batch 9/25, Image: rainy_3164.jpg, Loss_G: 12.5845, Loss_D_A: 0.0113, Loss_D_B: 0.0093\n",
            "Epoch 17/70, Batch 10/25, Image: rainy_166.jpg, Loss_G: 11.5769, Loss_D_A: 0.0246, Loss_D_B: 0.0199\n",
            "Epoch 17/70, Batch 11/25, Image: rainy_1482.jpg, Loss_G: 12.1531, Loss_D_A: 0.0373, Loss_D_B: 0.0311\n",
            "Epoch 17/70, Batch 12/25, Image: rainy_3337.jpg, Loss_G: 12.0440, Loss_D_A: 0.0275, Loss_D_B: 0.0175\n",
            "Epoch 17/70, Batch 13/25, Image: rainy_2787.jpg, Loss_G: 9.6997, Loss_D_A: 0.0154, Loss_D_B: 0.0076\n",
            "Epoch 17/70, Batch 14/25, Image: rainy_2973.jpg, Loss_G: 10.0974, Loss_D_A: 0.0115, Loss_D_B: 0.0066\n",
            "Epoch 17/70, Batch 15/25, Image: rainy_3813.jpg, Loss_G: 13.6720, Loss_D_A: 0.0109, Loss_D_B: 0.0076\n",
            "Epoch 17/70, Batch 16/25, Image: rainy_1826.jpg, Loss_G: 14.4822, Loss_D_A: 0.0096, Loss_D_B: 0.0047\n",
            "Epoch 17/70, Batch 17/25, Image: rainy_3821.jpg, Loss_G: 18.7752, Loss_D_A: 0.0104, Loss_D_B: 0.0105\n",
            "Epoch 17/70, Batch 18/25, Image: rainy_1861.jpg, Loss_G: 11.3752, Loss_D_A: 0.0214, Loss_D_B: 0.0180\n",
            "Epoch 17/70, Batch 19/25, Image: rainy_53.jpg, Loss_G: 12.8338, Loss_D_A: 0.0084, Loss_D_B: 0.0165\n",
            "Epoch 17/70, Batch 20/25, Image: rainy_1834.jpg, Loss_G: 18.0836, Loss_D_A: 0.0076, Loss_D_B: 0.0169\n",
            "Epoch 17/70, Batch 21/25, Image: rainy_2691.jpg, Loss_G: 19.0081, Loss_D_A: 0.0210, Loss_D_B: 0.0187\n",
            "Epoch 17/70, Batch 22/25, Image: rainy_199.jpg, Loss_G: 10.5902, Loss_D_A: 0.0242, Loss_D_B: 0.0128\n",
            "Epoch 17/70, Batch 23/25, Image: rainy_2513.jpg, Loss_G: 14.6999, Loss_D_A: 0.0124, Loss_D_B: 0.0084\n",
            "Epoch 17/70, Batch 24/25, Image: rainy_1599.jpg, Loss_G: 9.8746, Loss_D_A: 0.0067, Loss_D_B: 0.0043\n",
            "Epoch 18/70, Batch 0/25, Image: rainy_536.jpg, Loss_G: 11.1609, Loss_D_A: 0.0066, Loss_D_B: 0.0066\n",
            "Epoch 18/70, Batch 1/25, Image: rainy_1269.jpg, Loss_G: 12.2423, Loss_D_A: 0.0133, Loss_D_B: 0.0108\n",
            "Epoch 18/70, Batch 2/25, Image: rainy_1508.jpg, Loss_G: 11.0052, Loss_D_A: 0.0211, Loss_D_B: 0.0076\n",
            "Epoch 18/70, Batch 3/25, Image: rainy_2431.jpg, Loss_G: 12.9538, Loss_D_A: 0.0052, Loss_D_B: 0.0048\n",
            "Epoch 18/70, Batch 4/25, Image: rainy_1761.jpg, Loss_G: 13.3692, Loss_D_A: 0.0155, Loss_D_B: 0.0072\n",
            "Epoch 18/70, Batch 5/25, Image: rainy_199.jpg, Loss_G: 12.1219, Loss_D_A: 0.0116, Loss_D_B: 0.0073\n",
            "Epoch 18/70, Batch 6/25, Image: rainy_2619.jpg, Loss_G: 15.4751, Loss_D_A: 0.0160, Loss_D_B: 0.0079\n",
            "Epoch 18/70, Batch 7/25, Image: rainy_481.jpg, Loss_G: 10.0809, Loss_D_A: 0.0326, Loss_D_B: 0.0089\n",
            "Epoch 18/70, Batch 8/25, Image: rainy_3156.jpg, Loss_G: 11.5300, Loss_D_A: 0.0178, Loss_D_B: 0.0093\n",
            "Epoch 18/70, Batch 9/25, Image: rainy_923.jpg, Loss_G: 10.6262, Loss_D_A: 0.0120, Loss_D_B: 0.0103\n",
            "Epoch 18/70, Batch 10/25, Image: rainy_1656.jpg, Loss_G: 10.3661, Loss_D_A: 0.0094, Loss_D_B: 0.0081\n",
            "Epoch 18/70, Batch 11/25, Image: rainy_1482.jpg, Loss_G: 10.1764, Loss_D_A: 0.0067, Loss_D_B: 0.0059\n",
            "Epoch 18/70, Batch 12/25, Image: rainy_1769.jpg, Loss_G: 13.3590, Loss_D_A: 0.0057, Loss_D_B: 0.0047\n",
            "Epoch 18/70, Batch 13/25, Image: rainy_3821.jpg, Loss_G: 11.9945, Loss_D_A: 0.0261, Loss_D_B: 0.0049\n",
            "Epoch 18/70, Batch 14/25, Image: rainy_3606.jpg, Loss_G: 9.6151, Loss_D_A: 0.0414, Loss_D_B: 0.0069\n",
            "Epoch 18/70, Batch 15/25, Image: rainy_398.jpg, Loss_G: 9.6762, Loss_D_A: 0.0425, Loss_D_B: 0.0119\n",
            "Epoch 18/70, Batch 16/25, Image: rainy_2198.jpg, Loss_G: 10.7850, Loss_D_A: 0.0313, Loss_D_B: 0.0069\n",
            "Epoch 18/70, Batch 17/25, Image: rainy_328.jpg, Loss_G: 12.0087, Loss_D_A: 0.0158, Loss_D_B: 0.0053\n",
            "Epoch 18/70, Batch 18/25, Image: rainy_1674.jpg, Loss_G: 16.4939, Loss_D_A: 0.0072, Loss_D_B: 0.0051\n",
            "Epoch 18/70, Batch 19/25, Image: rainy_1931.jpg, Loss_G: 11.7063, Loss_D_A: 0.0100, Loss_D_B: 0.0074\n",
            "Epoch 18/70, Batch 20/25, Image: rainy_1434.jpg, Loss_G: 13.7159, Loss_D_A: 0.0048, Loss_D_B: 0.0064\n",
            "Epoch 18/70, Batch 21/25, Image: rainy_2513.jpg, Loss_G: 10.8068, Loss_D_A: 0.0073, Loss_D_B: 0.0058\n",
            "Epoch 18/70, Batch 22/25, Image: rainy_1046.jpg, Loss_G: 11.8668, Loss_D_A: 0.0098, Loss_D_B: 0.0058\n",
            "Epoch 18/70, Batch 23/25, Image: rainy_1826.jpg, Loss_G: 11.3548, Loss_D_A: 0.0090, Loss_D_B: 0.0110\n",
            "Epoch 18/70, Batch 24/25, Image: rainy_3355.jpg, Loss_G: 11.4641, Loss_D_A: 0.0101, Loss_D_B: 0.0138\n",
            "Epoch 19/70, Batch 0/25, Image: rainy_1591.jpg, Loss_G: 11.0720, Loss_D_A: 0.0096, Loss_D_B: 0.0106\n",
            "Epoch 19/70, Batch 1/25, Image: rainy_1381.jpg, Loss_G: 10.0472, Loss_D_A: 0.0044, Loss_D_B: 0.0043\n",
            "Epoch 19/70, Batch 2/25, Image: rainy_3063.jpg, Loss_G: 11.0282, Loss_D_A: 0.0051, Loss_D_B: 0.0043\n",
            "Epoch 19/70, Batch 3/25, Image: rainy_446.jpg, Loss_G: 10.2865, Loss_D_A: 0.0056, Loss_D_B: 0.0046\n",
            "Epoch 19/70, Batch 4/25, Image: rainy_267.jpg, Loss_G: 13.0460, Loss_D_A: 0.0045, Loss_D_B: 0.0056\n",
            "Epoch 19/70, Batch 5/25, Image: rainy_170.jpg, Loss_G: 12.8946, Loss_D_A: 0.0097, Loss_D_B: 0.0034\n",
            "Epoch 19/70, Batch 6/25, Image: rainy_1456.jpg, Loss_G: 10.7789, Loss_D_A: 0.0067, Loss_D_B: 0.0048\n",
            "Epoch 19/70, Batch 7/25, Image: rainy_3445.jpg, Loss_G: 13.9695, Loss_D_A: 0.0075, Loss_D_B: 0.0051\n",
            "Epoch 19/70, Batch 8/25, Image: rainy_335.jpg, Loss_G: 10.4026, Loss_D_A: 0.0152, Loss_D_B: 0.0055\n",
            "Epoch 19/70, Batch 9/25, Image: rainy_1826.jpg, Loss_G: 14.3420, Loss_D_A: 0.0077, Loss_D_B: 0.0055\n",
            "Epoch 19/70, Batch 10/25, Image: rainy_3090.jpg, Loss_G: 12.5971, Loss_D_A: 0.0039, Loss_D_B: 0.0036\n",
            "Epoch 19/70, Batch 11/25, Image: rainy_1836.jpg, Loss_G: 15.7924, Loss_D_A: 0.0043, Loss_D_B: 0.0101\n",
            "Epoch 19/70, Batch 12/25, Image: rainy_53.jpg, Loss_G: 10.2979, Loss_D_A: 0.0097, Loss_D_B: 0.0258\n",
            "Epoch 19/70, Batch 13/25, Image: rainy_205.jpg, Loss_G: 12.2278, Loss_D_A: 0.0291, Loss_D_B: 0.0339\n",
            "Epoch 19/70, Batch 14/25, Image: rainy_1426.jpg, Loss_G: 11.1246, Loss_D_A: 0.0268, Loss_D_B: 0.0182\n",
            "Epoch 19/70, Batch 15/25, Image: rainy_2004.jpg, Loss_G: 10.4421, Loss_D_A: 0.0054, Loss_D_B: 0.0047\n",
            "Epoch 19/70, Batch 16/25, Image: rainy_475.jpg, Loss_G: 10.3548, Loss_D_A: 0.0089, Loss_D_B: 0.0076\n",
            "Epoch 19/70, Batch 17/25, Image: rainy_3060.jpg, Loss_G: 10.0122, Loss_D_A: 0.0057, Loss_D_B: 0.0068\n",
            "Epoch 19/70, Batch 18/25, Image: rainy_3213.jpg, Loss_G: 11.1926, Loss_D_A: 0.0088, Loss_D_B: 0.0072\n",
            "Epoch 19/70, Batch 19/25, Image: rainy_769.jpg, Loss_G: 12.1568, Loss_D_A: 0.0108, Loss_D_B: 0.0097\n",
            "Epoch 19/70, Batch 20/25, Image: rainy_166.jpg, Loss_G: 10.4942, Loss_D_A: 0.0078, Loss_D_B: 0.0180\n",
            "Epoch 19/70, Batch 21/25, Image: rainy_773.jpg, Loss_G: 11.8149, Loss_D_A: 0.0051, Loss_D_B: 0.0230\n",
            "Epoch 19/70, Batch 22/25, Image: rainy_536.jpg, Loss_G: 11.7655, Loss_D_A: 0.0123, Loss_D_B: 0.0145\n",
            "Epoch 19/70, Batch 23/25, Image: rainy_849.jpg, Loss_G: 12.4844, Loss_D_A: 0.0087, Loss_D_B: 0.0097\n",
            "Epoch 19/70, Batch 24/25, Image: rainy_558.jpg, Loss_G: 12.9982, Loss_D_A: 0.0056, Loss_D_B: 0.0056\n",
            "Epoch 20/70, Batch 0/25, Image: rainy_3710.jpg, Loss_G: 14.5329, Loss_D_A: 0.0156, Loss_D_B: 0.0084\n",
            "Epoch 20/70, Batch 1/25, Image: rainy_2263.jpg, Loss_G: 10.4550, Loss_D_A: 0.0152, Loss_D_B: 0.0076\n",
            "Epoch 20/70, Batch 2/25, Image: rainy_3911.jpg, Loss_G: 8.9995, Loss_D_A: 0.0102, Loss_D_B: 0.0053\n",
            "Epoch 20/70, Batch 3/25, Image: rainy_1769.jpg, Loss_G: 10.0245, Loss_D_A: 0.0107, Loss_D_B: 0.0050\n",
            "Epoch 20/70, Batch 4/25, Image: rainy_1346.jpg, Loss_G: 11.1588, Loss_D_A: 0.0105, Loss_D_B: 0.0123\n",
            "Epoch 20/70, Batch 5/25, Image: rainy_3337.jpg, Loss_G: 10.1371, Loss_D_A: 0.0189, Loss_D_B: 0.0233\n",
            "Epoch 20/70, Batch 6/25, Image: rainy_1957.jpg, Loss_G: 13.5978, Loss_D_A: 0.0159, Loss_D_B: 0.0293\n",
            "Epoch 20/70, Batch 7/25, Image: rainy_536.jpg, Loss_G: 10.9605, Loss_D_A: 0.0058, Loss_D_B: 0.0198\n",
            "Epoch 20/70, Batch 8/25, Image: rainy_2619.jpg, Loss_G: 11.9722, Loss_D_A: 0.0070, Loss_D_B: 0.0150\n",
            "Epoch 20/70, Batch 9/25, Image: rainy_1599.jpg, Loss_G: 12.0576, Loss_D_A: 0.0061, Loss_D_B: 0.0093\n",
            "Epoch 20/70, Batch 10/25, Image: rainy_3821.jpg, Loss_G: 9.7400, Loss_D_A: 0.0045, Loss_D_B: 0.0051\n",
            "Epoch 20/70, Batch 11/25, Image: rainy_119.jpg, Loss_G: 12.2143, Loss_D_A: 0.0041, Loss_D_B: 0.0045\n",
            "Epoch 20/70, Batch 12/25, Image: rainy_2877.jpg, Loss_G: 9.2789, Loss_D_A: 0.0054, Loss_D_B: 0.0046\n",
            "Epoch 20/70, Batch 13/25, Image: rainy_926.jpg, Loss_G: 9.4276, Loss_D_A: 0.0052, Loss_D_B: 0.0044\n",
            "Epoch 20/70, Batch 14/25, Image: rainy_335.jpg, Loss_G: 13.2637, Loss_D_A: 0.0103, Loss_D_B: 0.0050\n",
            "Epoch 20/70, Batch 15/25, Image: rainy_2977.jpg, Loss_G: 12.5292, Loss_D_A: 0.0191, Loss_D_B: 0.0053\n",
            "Epoch 20/70, Batch 16/25, Image: rainy_2453.jpg, Loss_G: 11.2679, Loss_D_A: 0.0102, Loss_D_B: 0.0037\n",
            "Epoch 20/70, Batch 17/25, Image: rainy_1836.jpg, Loss_G: 9.7536, Loss_D_A: 0.0039, Loss_D_B: 0.0051\n",
            "Epoch 20/70, Batch 18/25, Image: rainy_3703.jpg, Loss_G: 11.9532, Loss_D_A: 0.0066, Loss_D_B: 0.0064\n",
            "Epoch 20/70, Batch 19/25, Image: rainy_2004.jpg, Loss_G: 10.2889, Loss_D_A: 0.0158, Loss_D_B: 0.0050\n",
            "Epoch 20/70, Batch 20/25, Image: rainy_1286.jpg, Loss_G: 11.6837, Loss_D_A: 0.0092, Loss_D_B: 0.0064\n",
            "Epoch 20/70, Batch 21/25, Image: rainy_2533.jpg, Loss_G: 11.1185, Loss_D_A: 0.0069, Loss_D_B: 0.0113\n",
            "Epoch 20/70, Batch 22/25, Image: rainy_750.jpg, Loss_G: 11.2322, Loss_D_A: 0.0070, Loss_D_B: 0.0106\n",
            "Epoch 20/70, Batch 23/25, Image: rainy_1639.jpg, Loss_G: 11.4482, Loss_D_A: 0.0041, Loss_D_B: 0.0052\n",
            "Epoch 20/70, Batch 24/25, Image: rainy_993.jpg, Loss_G: 11.0231, Loss_D_A: 0.0074, Loss_D_B: 0.0067\n",
            "✅ Checkpoint saved at epoch 20\n",
            "Epoch 21/70, Batch 0/25, Image: rainy_3428.jpg, Loss_G: 11.4555, Loss_D_A: 0.0259, Loss_D_B: 0.0112\n",
            "Epoch 21/70, Batch 1/25, Image: rainy_3371.jpg, Loss_G: 16.3928, Loss_D_A: 0.0404, Loss_D_B: 0.0078\n",
            "Epoch 21/70, Batch 2/25, Image: rainy_104.jpg, Loss_G: 10.2783, Loss_D_A: 0.0389, Loss_D_B: 0.0048\n",
            "Epoch 21/70, Batch 3/25, Image: rainy_3014.jpg, Loss_G: 15.1976, Loss_D_A: 0.0136, Loss_D_B: 0.0053\n",
            "Epoch 21/70, Batch 4/25, Image: rainy_2404.jpg, Loss_G: 14.1047, Loss_D_A: 0.0083, Loss_D_B: 0.0055\n",
            "Epoch 21/70, Batch 5/25, Image: rainy_2570.jpg, Loss_G: 11.5811, Loss_D_A: 0.0110, Loss_D_B: 0.0097\n",
            "Epoch 21/70, Batch 6/25, Image: rainy_1957.jpg, Loss_G: 10.5731, Loss_D_A: 0.0079, Loss_D_B: 0.0147\n",
            "Epoch 21/70, Batch 7/25, Image: rainy_184.jpg, Loss_G: 12.4147, Loss_D_A: 0.0092, Loss_D_B: 0.0166\n",
            "Epoch 21/70, Batch 8/25, Image: rainy_2629.jpg, Loss_G: 13.5749, Loss_D_A: 0.0047, Loss_D_B: 0.0094\n",
            "Epoch 21/70, Batch 9/25, Image: rainy_748.jpg, Loss_G: 16.2040, Loss_D_A: 0.0092, Loss_D_B: 0.0066\n",
            "Epoch 21/70, Batch 10/25, Image: rainy_2198.jpg, Loss_G: 11.2010, Loss_D_A: 0.0087, Loss_D_B: 0.0069\n",
            "Epoch 21/70, Batch 11/25, Image: rainy_1185.jpg, Loss_G: 11.6591, Loss_D_A: 0.0039, Loss_D_B: 0.0071\n",
            "Epoch 21/70, Batch 12/25, Image: rainy_1286.jpg, Loss_G: 11.8029, Loss_D_A: 0.0065, Loss_D_B: 0.0078\n",
            "Epoch 21/70, Batch 13/25, Image: rainy_2985.jpg, Loss_G: 12.6047, Loss_D_A: 0.0137, Loss_D_B: 0.0061\n",
            "Epoch 21/70, Batch 14/25, Image: rainy_2779.jpg, Loss_G: 10.9983, Loss_D_A: 0.0268, Loss_D_B: 0.0089\n",
            "Epoch 21/70, Batch 15/25, Image: rainy_1269.jpg, Loss_G: 9.4878, Loss_D_A: 0.0226, Loss_D_B: 0.0111\n",
            "Epoch 21/70, Batch 16/25, Image: rainy_166.jpg, Loss_G: 13.0274, Loss_D_A: 0.0090, Loss_D_B: 0.0119\n",
            "Epoch 21/70, Batch 17/25, Image: rainy_298.jpg, Loss_G: 10.2010, Loss_D_A: 0.0053, Loss_D_B: 0.0093\n",
            "Epoch 21/70, Batch 18/25, Image: rainy_53.jpg, Loss_G: 13.8698, Loss_D_A: 0.0062, Loss_D_B: 0.0070\n",
            "Epoch 21/70, Batch 19/25, Image: rainy_3355.jpg, Loss_G: 11.1227, Loss_D_A: 0.0050, Loss_D_B: 0.0083\n",
            "Epoch 21/70, Batch 20/25, Image: rainy_773.jpg, Loss_G: 13.8623, Loss_D_A: 0.0063, Loss_D_B: 0.0127\n",
            "Epoch 21/70, Batch 21/25, Image: rainy_3019.jpg, Loss_G: 10.5470, Loss_D_A: 0.0073, Loss_D_B: 0.0110\n",
            "Epoch 21/70, Batch 22/25, Image: rainy_170.jpg, Loss_G: 10.8238, Loss_D_A: 0.0047, Loss_D_B: 0.0081\n",
            "Epoch 21/70, Batch 23/25, Image: rainy_3060.jpg, Loss_G: 11.4615, Loss_D_A: 0.0044, Loss_D_B: 0.0097\n",
            "Epoch 21/70, Batch 24/25, Image: rainy_1820 (1).jpg, Loss_G: 12.4048, Loss_D_A: 0.0042, Loss_D_B: 0.0040\n",
            "Epoch 22/70, Batch 0/25, Image: rainy_2691.jpg, Loss_G: 12.3938, Loss_D_A: 0.0049, Loss_D_B: 0.0077\n",
            "Epoch 22/70, Batch 1/25, Image: rainy_1957.jpg, Loss_G: 10.0218, Loss_D_A: 0.0070, Loss_D_B: 0.0093\n",
            "Epoch 22/70, Batch 2/25, Image: rainy_3821.jpg, Loss_G: 11.3106, Loss_D_A: 0.0075, Loss_D_B: 0.0128\n",
            "Epoch 22/70, Batch 3/25, Image: rainy_2955.jpg, Loss_G: 10.5523, Loss_D_A: 0.0115, Loss_D_B: 0.0100\n",
            "Epoch 22/70, Batch 4/25, Image: rainy_2346.jpg, Loss_G: 12.7902, Loss_D_A: 0.0128, Loss_D_B: 0.0111\n",
            "Epoch 22/70, Batch 5/25, Image: rainy_1662.jpg, Loss_G: 13.7206, Loss_D_A: 0.0083, Loss_D_B: 0.0096\n",
            "Epoch 22/70, Batch 6/25, Image: rainy_2060.jpg, Loss_G: 9.8195, Loss_D_A: 0.0118, Loss_D_B: 0.0036\n",
            "Epoch 22/70, Batch 7/25, Image: rainy_2431.jpg, Loss_G: 11.0455, Loss_D_A: 0.0195, Loss_D_B: 0.0048\n",
            "Epoch 22/70, Batch 8/25, Image: rainy_558.jpg, Loss_G: 9.6345, Loss_D_A: 0.0184, Loss_D_B: 0.0064\n",
            "Epoch 22/70, Batch 9/25, Image: rainy_232.jpg, Loss_G: 11.6136, Loss_D_A: 0.0107, Loss_D_B: 0.0058\n",
            "Epoch 22/70, Batch 10/25, Image: rainy_2263.jpg, Loss_G: 10.0563, Loss_D_A: 0.0057, Loss_D_B: 0.0041\n",
            "Epoch 22/70, Batch 11/25, Image: rainy_1599.jpg, Loss_G: 9.7377, Loss_D_A: 0.0083, Loss_D_B: 0.0029\n",
            "Epoch 22/70, Batch 12/25, Image: rainy_184.jpg, Loss_G: 10.4034, Loss_D_A: 0.0084, Loss_D_B: 0.0033\n",
            "Epoch 22/70, Batch 13/25, Image: rainy_750.jpg, Loss_G: 11.0827, Loss_D_A: 0.0057, Loss_D_B: 0.0032\n",
            "Epoch 22/70, Batch 14/25, Image: rainy_2404.jpg, Loss_G: 10.2387, Loss_D_A: 0.0048, Loss_D_B: 0.0033\n",
            "Epoch 22/70, Batch 15/25, Image: rainy_1237.jpg, Loss_G: 10.0682, Loss_D_A: 0.0044, Loss_D_B: 0.0032\n",
            "Epoch 22/70, Batch 16/25, Image: rainy_3337.jpg, Loss_G: 11.8262, Loss_D_A: 0.0039, Loss_D_B: 0.0040\n",
            "Epoch 22/70, Batch 17/25, Image: rainy_2779.jpg, Loss_G: 15.0120, Loss_D_A: 0.0062, Loss_D_B: 0.0059\n",
            "Epoch 22/70, Batch 18/25, Image: rainy_3371.jpg, Loss_G: 10.1297, Loss_D_A: 0.0042, Loss_D_B: 0.0052\n",
            "Epoch 22/70, Batch 19/25, Image: rainy_1766.jpg, Loss_G: 9.5850, Loss_D_A: 0.0088, Loss_D_B: 0.0060\n",
            "Epoch 22/70, Batch 20/25, Image: rainy_3213.jpg, Loss_G: 9.9424, Loss_D_A: 0.0055, Loss_D_B: 0.0071\n",
            "Epoch 22/70, Batch 21/25, Image: rainy_2513.jpg, Loss_G: 9.6050, Loss_D_A: 0.0042, Loss_D_B: 0.0034\n",
            "Epoch 22/70, Batch 22/25, Image: rainy_2928.jpg, Loss_G: 10.5981, Loss_D_A: 0.0083, Loss_D_B: 0.0031\n",
            "Epoch 22/70, Batch 23/25, Image: rainy_814.jpg, Loss_G: 9.2107, Loss_D_A: 0.0093, Loss_D_B: 0.0049\n",
            "Epoch 22/70, Batch 24/25, Image: rainy_332.jpg, Loss_G: 9.5646, Loss_D_A: 0.0124, Loss_D_B: 0.0069\n",
            "Epoch 23/70, Batch 0/25, Image: rainy_1269.jpg, Loss_G: 9.8096, Loss_D_A: 0.0090, Loss_D_B: 0.0038\n",
            "Epoch 23/70, Batch 1/25, Image: rainy_913.jpg, Loss_G: 10.3290, Loss_D_A: 0.0047, Loss_D_B: 0.0027\n",
            "Epoch 23/70, Batch 2/25, Image: rainy_2629.jpg, Loss_G: 9.4923, Loss_D_A: 0.0036, Loss_D_B: 0.0035\n",
            "Epoch 23/70, Batch 3/25, Image: rainy_1899.jpg, Loss_G: 9.2839, Loss_D_A: 0.0036, Loss_D_B: 0.0055\n",
            "Epoch 23/70, Batch 4/25, Image: rainy_1228.jpg, Loss_G: 10.3478, Loss_D_A: 0.0050, Loss_D_B: 0.0091\n",
            "Epoch 23/70, Batch 5/25, Image: rainy_1456.jpg, Loss_G: 11.3998, Loss_D_A: 0.0026, Loss_D_B: 0.0076\n",
            "Epoch 23/70, Batch 6/25, Image: rainy_79.jpg, Loss_G: 9.3876, Loss_D_A: 0.0043, Loss_D_B: 0.0046\n",
            "Epoch 23/70, Batch 7/25, Image: rainy_1083.jpg, Loss_G: 10.1053, Loss_D_A: 0.0050, Loss_D_B: 0.0051\n",
            "Epoch 23/70, Batch 8/25, Image: rainy_1784.jpg, Loss_G: 11.3300, Loss_D_A: 0.0075, Loss_D_B: 0.0167\n",
            "Epoch 23/70, Batch 9/25, Image: rainy_2619.jpg, Loss_G: 9.8326, Loss_D_A: 0.0046, Loss_D_B: 0.0177\n",
            "Epoch 23/70, Batch 10/25, Image: rainy_3769.jpg, Loss_G: 11.9115, Loss_D_A: 0.0053, Loss_D_B: 0.0132\n",
            "Epoch 23/70, Batch 11/25, Image: rainy_3573.jpg, Loss_G: 11.1318, Loss_D_A: 0.0134, Loss_D_B: 0.0074\n",
            "Epoch 23/70, Batch 12/25, Image: rainy_2779.jpg, Loss_G: 8.6137, Loss_D_A: 0.0255, Loss_D_B: 0.0043\n",
            "Epoch 23/70, Batch 13/25, Image: rainy_988.jpg, Loss_G: 14.0694, Loss_D_A: 0.0114, Loss_D_B: 0.0040\n",
            "Epoch 23/70, Batch 14/25, Image: rainy_2474.jpg, Loss_G: 14.0710, Loss_D_A: 0.0102, Loss_D_B: 0.0030\n",
            "Epoch 23/70, Batch 15/25, Image: rainy_3371.jpg, Loss_G: 10.0901, Loss_D_A: 0.0142, Loss_D_B: 0.0043\n",
            "Epoch 23/70, Batch 16/25, Image: rainy_912.jpg, Loss_G: 10.0973, Loss_D_A: 0.0065, Loss_D_B: 0.0044\n",
            "Epoch 23/70, Batch 17/25, Image: rainy_1931.jpg, Loss_G: 10.8475, Loss_D_A: 0.0038, Loss_D_B: 0.0039\n",
            "Epoch 23/70, Batch 18/25, Image: rainy_1508.jpg, Loss_G: 13.1658, Loss_D_A: 0.0095, Loss_D_B: 0.0039\n",
            "Epoch 23/70, Batch 19/25, Image: rainy_3063.jpg, Loss_G: 10.9268, Loss_D_A: 0.0159, Loss_D_B: 0.0034\n",
            "Epoch 23/70, Batch 20/25, Image: rainy_1876.jpg, Loss_G: 11.6040, Loss_D_A: 0.0105, Loss_D_B: 0.0029\n",
            "Epoch 23/70, Batch 21/25, Image: rainy_3710.jpg, Loss_G: 9.8214, Loss_D_A: 0.0048, Loss_D_B: 0.0027\n",
            "Epoch 23/70, Batch 22/25, Image: rainy_1766.jpg, Loss_G: 12.7391, Loss_D_A: 0.0070, Loss_D_B: 0.0032\n",
            "Epoch 23/70, Batch 23/25, Image: rainy_328.jpg, Loss_G: 9.3638, Loss_D_A: 0.0087, Loss_D_B: 0.0030\n",
            "Epoch 23/70, Batch 24/25, Image: rainy_2628.jpg, Loss_G: 9.7237, Loss_D_A: 0.0054, Loss_D_B: 0.0036\n",
            "Epoch 24/70, Batch 0/25, Image: rainy_2346.jpg, Loss_G: 9.5162, Loss_D_A: 0.0058, Loss_D_B: 0.0023\n",
            "Epoch 24/70, Batch 1/25, Image: rainy_2453.jpg, Loss_G: 9.4190, Loss_D_A: 0.0056, Loss_D_B: 0.0035\n",
            "Epoch 24/70, Batch 2/25, Image: rainy_3703.jpg, Loss_G: 9.3943, Loss_D_A: 0.0038, Loss_D_B: 0.0032\n",
            "Epoch 24/70, Batch 3/25, Image: rainy_1834.jpg, Loss_G: 9.3866, Loss_D_A: 0.0058, Loss_D_B: 0.0040\n",
            "Epoch 24/70, Batch 4/25, Image: rainy_1901.jpg, Loss_G: 10.1634, Loss_D_A: 0.0055, Loss_D_B: 0.0053\n",
            "Epoch 24/70, Batch 5/25, Image: rainy_3795.jpg, Loss_G: 9.5499, Loss_D_A: 0.0060, Loss_D_B: 0.0069\n",
            "Epoch 24/70, Batch 6/25, Image: rainy_270.jpg, Loss_G: 10.7748, Loss_D_A: 0.0036, Loss_D_B: 0.0083\n",
            "Epoch 24/70, Batch 7/25, Image: rainy_1876.jpg, Loss_G: 11.1376, Loss_D_A: 0.0093, Loss_D_B: 0.0081\n",
            "Epoch 24/70, Batch 8/25, Image: rainy_2857.jpg, Loss_G: 10.1193, Loss_D_A: 0.0092, Loss_D_B: 0.0092\n",
            "Epoch 24/70, Batch 9/25, Image: rainy_267.jpg, Loss_G: 9.8261, Loss_D_A: 0.0044, Loss_D_B: 0.0070\n",
            "Epoch 24/70, Batch 10/25, Image: rainy_2859.jpg, Loss_G: 11.0229, Loss_D_A: 0.0039, Loss_D_B: 0.0057\n",
            "Epoch 24/70, Batch 11/25, Image: rainy_1966.jpg, Loss_G: 10.3920, Loss_D_A: 0.0049, Loss_D_B: 0.0074\n",
            "Epoch 24/70, Batch 12/25, Image: rainy_3511.jpg, Loss_G: 9.7959, Loss_D_A: 0.0041, Loss_D_B: 0.0060\n",
            "Epoch 24/70, Batch 13/25, Image: rainy_1381.jpg, Loss_G: 14.2933, Loss_D_A: 0.0043, Loss_D_B: 0.0035\n",
            "Epoch 24/70, Batch 14/25, Image: rainy_244.jpg, Loss_G: 10.9108, Loss_D_A: 0.0116, Loss_D_B: 0.0089\n",
            "Epoch 24/70, Batch 15/25, Image: rainy_2060.jpg, Loss_G: 10.9572, Loss_D_A: 0.0114, Loss_D_B: 0.0070\n",
            "Epoch 24/70, Batch 16/25, Image: rainy_1674.jpg, Loss_G: 9.0914, Loss_D_A: 0.0075, Loss_D_B: 0.0140\n",
            "Epoch 24/70, Batch 17/25, Image: rainy_3606.jpg, Loss_G: 12.6655, Loss_D_A: 0.0052, Loss_D_B: 0.0126\n",
            "Epoch 24/70, Batch 18/25, Image: rainy_904.jpg, Loss_G: 11.3161, Loss_D_A: 0.0078, Loss_D_B: 0.0104\n",
            "Epoch 24/70, Batch 19/25, Image: rainy_2533.jpg, Loss_G: 9.8076, Loss_D_A: 0.0075, Loss_D_B: 0.0065\n",
            "Epoch 24/70, Batch 20/25, Image: rainy_2973.jpg, Loss_G: 8.9837, Loss_D_A: 0.0086, Loss_D_B: 0.0039\n",
            "Epoch 24/70, Batch 21/25, Image: rainy_788.jpg, Loss_G: 9.8566, Loss_D_A: 0.0045, Loss_D_B: 0.0033\n",
            "Epoch 24/70, Batch 22/25, Image: rainy_3020.jpg, Loss_G: 11.7042, Loss_D_A: 0.0057, Loss_D_B: 0.0044\n",
            "Epoch 24/70, Batch 23/25, Image: rainy_1742.jpg, Loss_G: 13.0028, Loss_D_A: 0.0092, Loss_D_B: 0.0057\n",
            "Epoch 24/70, Batch 24/25, Image: rainy_3019.jpg, Loss_G: 10.4498, Loss_D_A: 0.0082, Loss_D_B: 0.0079\n",
            "Epoch 25/70, Batch 0/25, Image: rainy_2691.jpg, Loss_G: 9.4859, Loss_D_A: 0.0075, Loss_D_B: 0.0072\n",
            "Epoch 25/70, Batch 1/25, Image: rainy_1591.jpg, Loss_G: 12.3821, Loss_D_A: 0.0042, Loss_D_B: 0.0082\n",
            "Epoch 25/70, Batch 2/25, Image: rainy_913.jpg, Loss_G: 8.8013, Loss_D_A: 0.0059, Loss_D_B: 0.0099\n",
            "Epoch 25/70, Batch 3/25, Image: rainy_3606.jpg, Loss_G: 8.8426, Loss_D_A: 0.0078, Loss_D_B: 0.0092\n",
            "Epoch 25/70, Batch 4/25, Image: rainy_2004.jpg, Loss_G: 11.4427, Loss_D_A: 0.0055, Loss_D_B: 0.0062\n",
            "Epoch 25/70, Batch 5/25, Image: rainy_3821.jpg, Loss_G: 9.8397, Loss_D_A: 0.0027, Loss_D_B: 0.0117\n",
            "Epoch 25/70, Batch 6/25, Image: rainy_3813.jpg, Loss_G: 13.8375, Loss_D_A: 0.0038, Loss_D_B: 0.0216\n",
            "Epoch 25/70, Batch 7/25, Image: rainy_963.jpg, Loss_G: 10.2091, Loss_D_A: 0.0035, Loss_D_B: 0.0091\n",
            "Epoch 25/70, Batch 8/25, Image: rainy_3156.jpg, Loss_G: 9.4641, Loss_D_A: 0.0033, Loss_D_B: 0.0056\n",
            "Epoch 25/70, Batch 9/25, Image: rainy_1046.jpg, Loss_G: 8.8612, Loss_D_A: 0.0081, Loss_D_B: 0.0068\n",
            "Epoch 25/70, Batch 10/25, Image: rainy_3661.jpg, Loss_G: 9.0703, Loss_D_A: 0.0156, Loss_D_B: 0.0076\n",
            "Epoch 25/70, Batch 11/25, Image: rainy_2404.jpg, Loss_G: 11.1899, Loss_D_A: 0.0216, Loss_D_B: 0.0067\n",
            "Epoch 25/70, Batch 12/25, Image: rainy_748.jpg, Loss_G: 12.8349, Loss_D_A: 0.0217, Loss_D_B: 0.0083\n",
            "Epoch 25/70, Batch 13/25, Image: rainy_1158.jpg, Loss_G: 10.0326, Loss_D_A: 0.0109, Loss_D_B: 0.0173\n",
            "Epoch 25/70, Batch 14/25, Image: rainy_1432.jpg, Loss_G: 10.2917, Loss_D_A: 0.0047, Loss_D_B: 0.0111\n",
            "Epoch 25/70, Batch 15/25, Image: rainy_1656.jpg, Loss_G: 10.1616, Loss_D_A: 0.0070, Loss_D_B: 0.0059\n",
            "Epoch 25/70, Batch 16/25, Image: rainy_429.jpg, Loss_G: 10.2773, Loss_D_A: 0.0113, Loss_D_B: 0.0032\n",
            "Epoch 25/70, Batch 17/25, Image: rainy_2943.jpg, Loss_G: 10.4349, Loss_D_A: 0.0174, Loss_D_B: 0.0041\n",
            "Epoch 25/70, Batch 18/25, Image: rainy_1901.jpg, Loss_G: 10.5101, Loss_D_A: 0.0156, Loss_D_B: 0.0050\n",
            "Epoch 25/70, Batch 19/25, Image: rainy_3769.jpg, Loss_G: 8.8050, Loss_D_A: 0.0069, Loss_D_B: 0.0044\n",
            "Epoch 25/70, Batch 20/25, Image: rainy_752.jpg, Loss_G: 10.7098, Loss_D_A: 0.0043, Loss_D_B: 0.0038\n",
            "Epoch 25/70, Batch 21/25, Image: rainy_1861.jpg, Loss_G: 10.4207, Loss_D_A: 0.0084, Loss_D_B: 0.0046\n",
            "Epoch 25/70, Batch 22/25, Image: rainy_382.jpg, Loss_G: 15.4809, Loss_D_A: 0.0156, Loss_D_B: 0.0044\n",
            "Epoch 25/70, Batch 23/25, Image: rainy_2973.jpg, Loss_G: 12.2091, Loss_D_A: 0.0107, Loss_D_B: 0.0043\n",
            "Epoch 25/70, Batch 24/25, Image: rainy_1185.jpg, Loss_G: 10.5159, Loss_D_A: 0.0053, Loss_D_B: 0.0073\n",
            "✅ Checkpoint saved at epoch 25\n",
            "Epoch 26/70, Batch 0/25, Image: rainy_2877.jpg, Loss_G: 10.1678, Loss_D_A: 0.0033, Loss_D_B: 0.0115\n",
            "Epoch 26/70, Batch 1/25, Image: rainy_1669.jpg, Loss_G: 10.3780, Loss_D_A: 0.0051, Loss_D_B: 0.0096\n",
            "Epoch 26/70, Batch 2/25, Image: rainy_1861.jpg, Loss_G: 9.5980, Loss_D_A: 0.0055, Loss_D_B: 0.0032\n",
            "Epoch 26/70, Batch 3/25, Image: rainy_1080.jpg, Loss_G: 11.4199, Loss_D_A: 0.0039, Loss_D_B: 0.0028\n",
            "Epoch 26/70, Batch 4/25, Image: rainy_1899.jpg, Loss_G: 10.3478, Loss_D_A: 0.0032, Loss_D_B: 0.0041\n",
            "Epoch 26/70, Batch 5/25, Image: rainy_475.jpg, Loss_G: 10.8036, Loss_D_A: 0.0032, Loss_D_B: 0.0078\n",
            "Epoch 26/70, Batch 6/25, Image: rainy_332.jpg, Loss_G: 11.2164, Loss_D_A: 0.0043, Loss_D_B: 0.0150\n",
            "Epoch 26/70, Batch 7/25, Image: rainy_988.jpg, Loss_G: 10.8453, Loss_D_A: 0.0029, Loss_D_B: 0.0142\n",
            "Epoch 26/70, Batch 8/25, Image: rainy_1530.jpg, Loss_G: 9.6113, Loss_D_A: 0.0041, Loss_D_B: 0.0104\n",
            "Epoch 26/70, Batch 9/25, Image: rainy_1426.jpg, Loss_G: 10.1286, Loss_D_A: 0.0052, Loss_D_B: 0.0090\n",
            "Epoch 26/70, Batch 10/25, Image: rainy_1957.jpg, Loss_G: 8.9379, Loss_D_A: 0.0034, Loss_D_B: 0.0054\n",
            "Epoch 26/70, Batch 11/25, Image: rainy_3385.jpg, Loss_G: 9.4106, Loss_D_A: 0.0054, Loss_D_B: 0.0074\n",
            "Epoch 26/70, Batch 12/25, Image: rainy_2620.jpg, Loss_G: 9.7858, Loss_D_A: 0.0078, Loss_D_B: 0.0121\n",
            "Epoch 26/70, Batch 13/25, Image: rainy_2259.jpg, Loss_G: 10.4915, Loss_D_A: 0.0041, Loss_D_B: 0.0209\n",
            "Epoch 26/70, Batch 14/25, Image: rainy_3371.jpg, Loss_G: 10.5441, Loss_D_A: 0.0044, Loss_D_B: 0.0380\n",
            "Epoch 26/70, Batch 15/25, Image: rainy_3337.jpg, Loss_G: 10.5940, Loss_D_A: 0.0086, Loss_D_B: 0.0493\n",
            "Epoch 26/70, Batch 16/25, Image: rainy_2346.jpg, Loss_G: 16.1438, Loss_D_A: 0.0074, Loss_D_B: 0.0649\n",
            "Epoch 26/70, Batch 17/25, Image: rainy_912.jpg, Loss_G: 11.3442, Loss_D_A: 0.0040, Loss_D_B: 0.0447\n",
            "Epoch 26/70, Batch 18/25, Image: rainy_2814.jpg, Loss_G: 10.4230, Loss_D_A: 0.0038, Loss_D_B: 0.0228\n",
            "Epoch 26/70, Batch 19/25, Image: rainy_3078.jpg, Loss_G: 10.9343, Loss_D_A: 0.0049, Loss_D_B: 0.0153\n",
            "Epoch 26/70, Batch 20/25, Image: rainy_1091.jpg, Loss_G: 10.2001, Loss_D_A: 0.0043, Loss_D_B: 0.0331\n",
            "Epoch 26/70, Batch 21/25, Image: rainy_904.jpg, Loss_G: 10.3433, Loss_D_A: 0.0042, Loss_D_B: 0.0251\n",
            "Epoch 26/70, Batch 22/25, Image: rainy_926.jpg, Loss_G: 10.9866, Loss_D_A: 0.0027, Loss_D_B: 0.0116\n",
            "Epoch 26/70, Batch 23/25, Image: rainy_2952.jpg, Loss_G: 11.2182, Loss_D_A: 0.0043, Loss_D_B: 0.0107\n",
            "Epoch 26/70, Batch 24/25, Image: rainy_104.jpg, Loss_G: 9.3333, Loss_D_A: 0.0040, Loss_D_B: 0.0054\n",
            "Epoch 27/70, Batch 0/25, Image: rainy_3911.jpg, Loss_G: 9.7792, Loss_D_A: 0.0029, Loss_D_B: 0.0030\n",
            "Epoch 27/70, Batch 1/25, Image: rainy_3635.jpg, Loss_G: 9.4087, Loss_D_A: 0.0028, Loss_D_B: 0.0033\n",
            "Epoch 27/70, Batch 2/25, Image: rainy_2486.jpg, Loss_G: 10.4342, Loss_D_A: 0.0033, Loss_D_B: 0.0037\n",
            "Epoch 27/70, Batch 3/25, Image: rainy_3001.jpg, Loss_G: 10.6397, Loss_D_A: 0.0042, Loss_D_B: 0.0029\n",
            "Epoch 27/70, Batch 4/25, Image: rainy_1861.jpg, Loss_G: 10.5199, Loss_D_A: 0.0055, Loss_D_B: 0.0034\n",
            "Epoch 27/70, Batch 5/25, Image: rainy_3156.jpg, Loss_G: 12.8818, Loss_D_A: 0.0059, Loss_D_B: 0.0127\n",
            "Epoch 27/70, Batch 6/25, Image: rainy_540.jpg, Loss_G: 10.3766, Loss_D_A: 0.0033, Loss_D_B: 0.0119\n",
            "Epoch 27/70, Batch 7/25, Image: rainy_1237.jpg, Loss_G: 15.5142, Loss_D_A: 0.0034, Loss_D_B: 0.0053\n",
            "Epoch 27/70, Batch 8/25, Image: rainy_2132.jpg, Loss_G: 10.0781, Loss_D_A: 0.0034, Loss_D_B: 0.0067\n",
            "Epoch 27/70, Batch 9/25, Image: rainy_3428.jpg, Loss_G: 11.2240, Loss_D_A: 0.0042, Loss_D_B: 0.0111\n",
            "Epoch 27/70, Batch 10/25, Image: rainy_3445.jpg, Loss_G: 10.1029, Loss_D_A: 0.0044, Loss_D_B: 0.0072\n",
            "Epoch 27/70, Batch 11/25, Image: rainy_2859.jpg, Loss_G: 9.2612, Loss_D_A: 0.0074, Loss_D_B: 0.0058\n",
            "Epoch 27/70, Batch 12/25, Image: rainy_3342.jpg, Loss_G: 9.6137, Loss_D_A: 0.0083, Loss_D_B: 0.0033\n",
            "Epoch 27/70, Batch 13/25, Image: rainy_270.jpg, Loss_G: 9.6453, Loss_D_A: 0.0061, Loss_D_B: 0.0044\n",
            "Epoch 27/70, Batch 14/25, Image: rainy_3529.jpg, Loss_G: 12.7832, Loss_D_A: 0.0033, Loss_D_B: 0.0036\n",
            "Epoch 27/70, Batch 15/25, Image: rainy_536.jpg, Loss_G: 10.7284, Loss_D_A: 0.0070, Loss_D_B: 0.0090\n",
            "Epoch 27/70, Batch 16/25, Image: rainy_1966.jpg, Loss_G: 10.7777, Loss_D_A: 0.0042, Loss_D_B: 0.0131\n",
            "Epoch 27/70, Batch 17/25, Image: rainy_1426.jpg, Loss_G: 10.4917, Loss_D_A: 0.0043, Loss_D_B: 0.0078\n",
            "Epoch 27/70, Batch 18/25, Image: rainy_859.jpg, Loss_G: 11.0760, Loss_D_A: 0.0081, Loss_D_B: 0.0027\n",
            "Epoch 27/70, Batch 19/25, Image: rainy_3573.jpg, Loss_G: 13.4212, Loss_D_A: 0.0219, Loss_D_B: 0.0038\n",
            "Epoch 27/70, Batch 20/25, Image: rainy_769.jpg, Loss_G: 14.7396, Loss_D_A: 0.0355, Loss_D_B: 0.0074\n",
            "Epoch 27/70, Batch 21/25, Image: rainy_3090.jpg, Loss_G: 9.2053, Loss_D_A: 0.0232, Loss_D_B: 0.0065\n",
            "Epoch 27/70, Batch 22/25, Image: rainy_849.jpg, Loss_G: 9.8253, Loss_D_A: 0.0084, Loss_D_B: 0.0111\n",
            "Epoch 27/70, Batch 23/25, Image: rainy_1784.jpg, Loss_G: 9.8954, Loss_D_A: 0.0050, Loss_D_B: 0.0146\n",
            "Epoch 27/70, Batch 24/25, Image: rainy_1901.jpg, Loss_G: 8.8830, Loss_D_A: 0.0137, Loss_D_B: 0.0078\n",
            "Epoch 28/70, Batch 0/25, Image: rainy_244.jpg, Loss_G: 11.2575, Loss_D_A: 0.0178, Loss_D_B: 0.0087\n",
            "Epoch 28/70, Batch 1/25, Image: rainy_1761.jpg, Loss_G: 14.3084, Loss_D_A: 0.0069, Loss_D_B: 0.0268\n",
            "Epoch 28/70, Batch 2/25, Image: rainy_335.jpg, Loss_G: 12.1403, Loss_D_A: 0.0076, Loss_D_B: 0.0466\n",
            "Epoch 28/70, Batch 3/25, Image: rainy_328.jpg, Loss_G: 9.8711, Loss_D_A: 0.0177, Loss_D_B: 0.0345\n",
            "Epoch 28/70, Batch 4/25, Image: rainy_3584.jpg, Loss_G: 10.0689, Loss_D_A: 0.0198, Loss_D_B: 0.0242\n",
            "Epoch 28/70, Batch 5/25, Image: rainy_2779.jpg, Loss_G: 12.8917, Loss_D_A: 0.0084, Loss_D_B: 0.0159\n",
            "Epoch 28/70, Batch 6/25, Image: rainy_2857.jpg, Loss_G: 10.5139, Loss_D_A: 0.0067, Loss_D_B: 0.0086\n",
            "Epoch 28/70, Batch 7/25, Image: rainy_2486.jpg, Loss_G: 10.8504, Loss_D_A: 0.0220, Loss_D_B: 0.0044\n",
            "Epoch 28/70, Batch 8/25, Image: rainy_537.jpg, Loss_G: 10.5117, Loss_D_A: 0.0177, Loss_D_B: 0.0039\n",
            "Epoch 28/70, Batch 9/25, Image: rainy_2747.jpg, Loss_G: 11.7449, Loss_D_A: 0.0062, Loss_D_B: 0.0042\n",
            "Epoch 28/70, Batch 10/25, Image: rainy_3136.jpg, Loss_G: 9.8564, Loss_D_A: 0.0044, Loss_D_B: 0.0068\n",
            "Epoch 28/70, Batch 11/25, Image: rainy_2004.jpg, Loss_G: 10.5001, Loss_D_A: 0.0118, Loss_D_B: 0.0041\n",
            "Epoch 28/70, Batch 12/25, Image: rainy_1185.jpg, Loss_G: 9.2959, Loss_D_A: 0.0251, Loss_D_B: 0.0030\n",
            "Epoch 28/70, Batch 13/25, Image: rainy_3078.jpg, Loss_G: 11.8666, Loss_D_A: 0.0097, Loss_D_B: 0.0029\n",
            "Epoch 28/70, Batch 14/25, Image: rainy_3193.jpg, Loss_G: 11.4015, Loss_D_A: 0.0097, Loss_D_B: 0.0023\n",
            "Epoch 28/70, Batch 15/25, Image: rainy_2955.jpg, Loss_G: 10.0141, Loss_D_A: 0.0262, Loss_D_B: 0.0037\n",
            "Epoch 28/70, Batch 16/25, Image: rainy_3769.jpg, Loss_G: 8.2386, Loss_D_A: 0.0125, Loss_D_B: 0.0040\n",
            "Epoch 28/70, Batch 17/25, Image: rainy_3336.jpg, Loss_G: 8.8427, Loss_D_A: 0.0036, Loss_D_B: 0.0054\n",
            "Epoch 28/70, Batch 18/25, Image: rainy_2492.jpg, Loss_G: 9.1010, Loss_D_A: 0.0048, Loss_D_B: 0.0029\n",
            "Epoch 28/70, Batch 19/25, Image: rainy_868.jpg, Loss_G: 8.3727, Loss_D_A: 0.0050, Loss_D_B: 0.0029\n",
            "Epoch 28/70, Batch 20/25, Image: rainy_2404.jpg, Loss_G: 11.7718, Loss_D_A: 0.0074, Loss_D_B: 0.0093\n",
            "Epoch 28/70, Batch 21/25, Image: rainy_993.jpg, Loss_G: 10.1689, Loss_D_A: 0.0064, Loss_D_B: 0.0152\n",
            "Epoch 28/70, Batch 22/25, Image: rainy_1456.jpg, Loss_G: 13.1555, Loss_D_A: 0.0062, Loss_D_B: 0.0169\n",
            "Epoch 28/70, Batch 23/25, Image: rainy_2132.jpg, Loss_G: 10.5442, Loss_D_A: 0.0043, Loss_D_B: 0.0087\n",
            "Epoch 28/70, Batch 24/25, Image: rainy_2985.jpg, Loss_G: 13.2473, Loss_D_A: 0.0070, Loss_D_B: 0.0045\n",
            "Epoch 29/70, Batch 0/25, Image: rainy_1901.jpg, Loss_G: 11.1098, Loss_D_A: 0.0290, Loss_D_B: 0.0029\n",
            "Epoch 29/70, Batch 1/25, Image: rainy_1286.jpg, Loss_G: 10.6069, Loss_D_A: 0.0492, Loss_D_B: 0.0085\n",
            "Epoch 29/70, Batch 2/25, Image: rainy_1966.jpg, Loss_G: 13.6101, Loss_D_A: 0.0398, Loss_D_B: 0.0229\n",
            "Epoch 29/70, Batch 3/25, Image: rainy_3363.jpg, Loss_G: 10.3286, Loss_D_A: 0.0190, Loss_D_B: 0.0249\n",
            "Epoch 29/70, Batch 4/25, Image: rainy_53.jpg, Loss_G: 9.9350, Loss_D_A: 0.0040, Loss_D_B: 0.0082\n",
            "Epoch 29/70, Batch 5/25, Image: rainy_1769.jpg, Loss_G: 12.4900, Loss_D_A: 0.0064, Loss_D_B: 0.0030\n",
            "Epoch 29/70, Batch 6/25, Image: rainy_1555.jpg, Loss_G: 10.3302, Loss_D_A: 0.0032, Loss_D_B: 0.0032\n",
            "Epoch 29/70, Batch 7/25, Image: rainy_429.jpg, Loss_G: 9.6765, Loss_D_A: 0.0033, Loss_D_B: 0.0036\n",
            "Epoch 29/70, Batch 8/25, Image: rainy_926.jpg, Loss_G: 10.6822, Loss_D_A: 0.0028, Loss_D_B: 0.0024\n",
            "Epoch 29/70, Batch 9/25, Image: rainy_447.jpg, Loss_G: 9.2219, Loss_D_A: 0.0026, Loss_D_B: 0.0032\n",
            "Epoch 29/70, Batch 10/25, Image: rainy_2628.jpg, Loss_G: 8.5523, Loss_D_A: 0.0021, Loss_D_B: 0.0039\n",
            "Epoch 29/70, Batch 11/25, Image: rainy_2474.jpg, Loss_G: 9.9720, Loss_D_A: 0.0050, Loss_D_B: 0.0043\n",
            "Epoch 29/70, Batch 12/25, Image: rainy_1834.jpg, Loss_G: 9.8731, Loss_D_A: 0.0135, Loss_D_B: 0.0042\n",
            "Epoch 29/70, Batch 13/25, Image: rainy_3859.jpg, Loss_G: 13.5479, Loss_D_A: 0.0170, Loss_D_B: 0.0035\n",
            "Epoch 29/70, Batch 14/25, Image: rainy_3584.jpg, Loss_G: 9.2785, Loss_D_A: 0.0123, Loss_D_B: 0.0031\n",
            "Epoch 29/70, Batch 15/25, Image: rainy_3756.jpg, Loss_G: 9.3307, Loss_D_A: 0.0107, Loss_D_B: 0.0059\n",
            "Epoch 29/70, Batch 16/25, Image: rainy_1784.jpg, Loss_G: 9.7735, Loss_D_A: 0.0078, Loss_D_B: 0.0066\n",
            "Epoch 29/70, Batch 17/25, Image: rainy_3428.jpg, Loss_G: 9.0791, Loss_D_A: 0.0044, Loss_D_B: 0.0043\n",
            "Epoch 29/70, Batch 18/25, Image: rainy_1071.jpg, Loss_G: 9.3418, Loss_D_A: 0.0031, Loss_D_B: 0.0027\n",
            "Epoch 29/70, Batch 19/25, Image: rainy_748.jpg, Loss_G: 11.2557, Loss_D_A: 0.0081, Loss_D_B: 0.0073\n",
            "Epoch 29/70, Batch 20/25, Image: rainy_865.jpg, Loss_G: 9.8111, Loss_D_A: 0.0057, Loss_D_B: 0.0092\n",
            "Epoch 29/70, Batch 21/25, Image: rainy_2257.jpg, Loss_G: 10.4468, Loss_D_A: 0.0038, Loss_D_B: 0.0070\n",
            "Epoch 29/70, Batch 22/25, Image: rainy_3385.jpg, Loss_G: 11.1050, Loss_D_A: 0.0049, Loss_D_B: 0.0031\n",
            "Epoch 29/70, Batch 23/25, Image: rainy_795.jpg, Loss_G: 10.1690, Loss_D_A: 0.0064, Loss_D_B: 0.0036\n",
            "Epoch 29/70, Batch 24/25, Image: rainy_1158.jpg, Loss_G: 10.7112, Loss_D_A: 0.0044, Loss_D_B: 0.0030\n",
            "Epoch 30/70, Batch 0/25, Image: rainy_1080.jpg, Loss_G: 9.5254, Loss_D_A: 0.0036, Loss_D_B: 0.0040\n",
            "Epoch 30/70, Batch 1/25, Image: rainy_3001.jpg, Loss_G: 10.4449, Loss_D_A: 0.0113, Loss_D_B: 0.0042\n",
            "Epoch 30/70, Batch 2/25, Image: rainy_1769.jpg, Loss_G: 8.6430, Loss_D_A: 0.0129, Loss_D_B: 0.0053\n",
            "Epoch 30/70, Batch 3/25, Image: rainy_1434.jpg, Loss_G: 10.3496, Loss_D_A: 0.0052, Loss_D_B: 0.0068\n",
            "Epoch 30/70, Batch 4/25, Image: rainy_1836.jpg, Loss_G: 9.6873, Loss_D_A: 0.0040, Loss_D_B: 0.0121\n",
            "Epoch 30/70, Batch 5/25, Image: rainy_1456.jpg, Loss_G: 10.7962, Loss_D_A: 0.0102, Loss_D_B: 0.0212\n",
            "Epoch 30/70, Batch 6/25, Image: rainy_3756.jpg, Loss_G: 9.5873, Loss_D_A: 0.0214, Loss_D_B: 0.0246\n",
            "Epoch 30/70, Batch 7/25, Image: rainy_3063.jpg, Loss_G: 9.7790, Loss_D_A: 0.0209, Loss_D_B: 0.0188\n",
            "Epoch 30/70, Batch 8/25, Image: rainy_1826.jpg, Loss_G: 11.6727, Loss_D_A: 0.0131, Loss_D_B: 0.0147\n",
            "Epoch 30/70, Batch 9/25, Image: rainy_2857.jpg, Loss_G: 9.9060, Loss_D_A: 0.0047, Loss_D_B: 0.0085\n",
            "Epoch 30/70, Batch 10/25, Image: rainy_53.jpg, Loss_G: 8.8436, Loss_D_A: 0.0039, Loss_D_B: 0.0033\n",
            "Epoch 30/70, Batch 11/25, Image: rainy_2747.jpg, Loss_G: 8.7867, Loss_D_A: 0.0039, Loss_D_B: 0.0037\n",
            "Epoch 30/70, Batch 12/25, Image: rainy_1690.jpg, Loss_G: 12.4802, Loss_D_A: 0.0035, Loss_D_B: 0.0043\n",
            "Epoch 30/70, Batch 13/25, Image: rainy_491.jpg, Loss_G: 10.0522, Loss_D_A: 0.0059, Loss_D_B: 0.0035\n",
            "Epoch 30/70, Batch 14/25, Image: rainy_2257.jpg, Loss_G: 8.7225, Loss_D_A: 0.0079, Loss_D_B: 0.0051\n",
            "Epoch 30/70, Batch 15/25, Image: rainy_1861.jpg, Loss_G: 8.8955, Loss_D_A: 0.0052, Loss_D_B: 0.0062\n",
            "Epoch 30/70, Batch 16/25, Image: rainy_2198.jpg, Loss_G: 9.4946, Loss_D_A: 0.0050, Loss_D_B: 0.0042\n",
            "Epoch 30/70, Batch 17/25, Image: rainy_1639.jpg, Loss_G: 9.8457, Loss_D_A: 0.0028, Loss_D_B: 0.0035\n",
            "Epoch 30/70, Batch 18/25, Image: rainy_1172.jpg, Loss_G: 14.1347, Loss_D_A: 0.0069, Loss_D_B: 0.0073\n",
            "Epoch 30/70, Batch 19/25, Image: rainy_3445.jpg, Loss_G: 11.9008, Loss_D_A: 0.0104, Loss_D_B: 0.0161\n",
            "Epoch 30/70, Batch 20/25, Image: rainy_841.jpg, Loss_G: 11.3969, Loss_D_A: 0.0074, Loss_D_B: 0.0141\n",
            "Epoch 30/70, Batch 21/25, Image: rainy_481.jpg, Loss_G: 11.0588, Loss_D_A: 0.0040, Loss_D_B: 0.0092\n",
            "Epoch 30/70, Batch 22/25, Image: rainy_773.jpg, Loss_G: 10.1794, Loss_D_A: 0.0029, Loss_D_B: 0.0062\n",
            "Epoch 30/70, Batch 23/25, Image: rainy_3078.jpg, Loss_G: 9.7018, Loss_D_A: 0.0065, Loss_D_B: 0.0091\n",
            "Epoch 30/70, Batch 24/25, Image: rainy_446.jpg, Loss_G: 9.7848, Loss_D_A: 0.0042, Loss_D_B: 0.0046\n",
            "✅ Checkpoint saved at epoch 30\n",
            "Epoch 31/70, Batch 0/25, Image: rainy_2691.jpg, Loss_G: 9.8035, Loss_D_A: 0.0028, Loss_D_B: 0.0025\n",
            "Epoch 31/70, Batch 1/25, Image: rainy_750.jpg, Loss_G: 9.2410, Loss_D_A: 0.0045, Loss_D_B: 0.0061\n",
            "Epoch 31/70, Batch 2/25, Image: rainy_3336.jpg, Loss_G: 9.6247, Loss_D_A: 0.0045, Loss_D_B: 0.0050\n",
            "Epoch 31/70, Batch 3/25, Image: rainy_2275.jpg, Loss_G: 8.7739, Loss_D_A: 0.0051, Loss_D_B: 0.0052\n",
            "Epoch 31/70, Batch 4/25, Image: rainy_491.jpg, Loss_G: 12.3951, Loss_D_A: 0.0047, Loss_D_B: 0.0025\n",
            "Epoch 31/70, Batch 5/25, Image: rainy_3661.jpg, Loss_G: 10.5511, Loss_D_A: 0.0029, Loss_D_B: 0.0030\n",
            "Epoch 31/70, Batch 6/25, Image: rainy_1876.jpg, Loss_G: 9.7009, Loss_D_A: 0.0050, Loss_D_B: 0.0084\n",
            "Epoch 31/70, Batch 7/25, Image: rainy_540.jpg, Loss_G: 9.5664, Loss_D_A: 0.0039, Loss_D_B: 0.0079\n",
            "Epoch 31/70, Batch 8/25, Image: rainy_3859.jpg, Loss_G: 10.6813, Loss_D_A: 0.0071, Loss_D_B: 0.0081\n",
            "Epoch 31/70, Batch 9/25, Image: rainy_104.jpg, Loss_G: 9.6174, Loss_D_A: 0.0111, Loss_D_B: 0.0043\n",
            "Epoch 31/70, Batch 10/25, Image: rainy_2197.jpg, Loss_G: 9.9331, Loss_D_A: 0.0166, Loss_D_B: 0.0057\n",
            "Epoch 31/70, Batch 11/25, Image: rainy_963.jpg, Loss_G: 10.4724, Loss_D_A: 0.0142, Loss_D_B: 0.0049\n",
            "Epoch 31/70, Batch 12/25, Image: rainy_3019.jpg, Loss_G: 7.9597, Loss_D_A: 0.0039, Loss_D_B: 0.0037\n",
            "Epoch 31/70, Batch 13/25, Image: rainy_814.jpg, Loss_G: 12.6981, Loss_D_A: 0.0070, Loss_D_B: 0.0067\n",
            "Epoch 31/70, Batch 14/25, Image: rainy_904.jpg, Loss_G: 10.1768, Loss_D_A: 0.0064, Loss_D_B: 0.0080\n",
            "Epoch 31/70, Batch 15/25, Image: rainy_270.jpg, Loss_G: 16.7548, Loss_D_A: 0.0102, Loss_D_B: 0.0062\n",
            "Epoch 31/70, Batch 16/25, Image: rainy_1530.jpg, Loss_G: 9.8498, Loss_D_A: 0.0179, Loss_D_B: 0.0034\n",
            "Epoch 31/70, Batch 17/25, Image: rainy_1771.jpg, Loss_G: 10.7191, Loss_D_A: 0.0142, Loss_D_B: 0.0030\n",
            "Epoch 31/70, Batch 18/25, Image: rainy_2928.jpg, Loss_G: 9.4328, Loss_D_A: 0.0073, Loss_D_B: 0.0020\n",
            "Epoch 31/70, Batch 19/25, Image: rainy_2943.jpg, Loss_G: 9.7352, Loss_D_A: 0.0045, Loss_D_B: 0.0017\n",
            "Epoch 31/70, Batch 20/25, Image: rainy_1286.jpg, Loss_G: 8.8012, Loss_D_A: 0.0045, Loss_D_B: 0.0026\n",
            "Epoch 31/70, Batch 21/25, Image: rainy_3164.jpg, Loss_G: 8.6858, Loss_D_A: 0.0065, Loss_D_B: 0.0049\n",
            "Epoch 31/70, Batch 22/25, Image: rainy_1861.jpg, Loss_G: 8.3868, Loss_D_A: 0.0056, Loss_D_B: 0.0066\n",
            "Epoch 31/70, Batch 23/25, Image: rainy_1733.jpg, Loss_G: 9.2312, Loss_D_A: 0.0049, Loss_D_B: 0.0101\n",
            "Epoch 31/70, Batch 24/25, Image: rainy_2973.jpg, Loss_G: 12.7722, Loss_D_A: 0.0103, Loss_D_B: 0.0115\n",
            "Epoch 32/70, Batch 0/25, Image: rainy_199.jpg, Loss_G: 8.6342, Loss_D_A: 0.0187, Loss_D_B: 0.0144\n",
            "Epoch 32/70, Batch 1/25, Image: rainy_1599.jpg, Loss_G: 13.1082, Loss_D_A: 0.0122, Loss_D_B: 0.0177\n",
            "Epoch 32/70, Batch 2/25, Image: rainy_1434.jpg, Loss_G: 15.0702, Loss_D_A: 0.0041, Loss_D_B: 0.0133\n",
            "Epoch 32/70, Batch 3/25, Image: rainy_1733.jpg, Loss_G: 9.5219, Loss_D_A: 0.0047, Loss_D_B: 0.0086\n",
            "Epoch 32/70, Batch 4/25, Image: rainy_3371.jpg, Loss_G: 9.5507, Loss_D_A: 0.0035, Loss_D_B: 0.0042\n",
            "Epoch 32/70, Batch 5/25, Image: rainy_1690.jpg, Loss_G: 14.8703, Loss_D_A: 0.0132, Loss_D_B: 0.0067\n",
            "Epoch 32/70, Batch 6/25, Image: rainy_3001.jpg, Loss_G: 10.9858, Loss_D_A: 0.0336, Loss_D_B: 0.0097\n",
            "Epoch 32/70, Batch 7/25, Image: rainy_1071.jpg, Loss_G: 10.3170, Loss_D_A: 0.0361, Loss_D_B: 0.0073\n",
            "Epoch 32/70, Batch 8/25, Image: rainy_2195.jpg, Loss_G: 8.3637, Loss_D_A: 0.0148, Loss_D_B: 0.0056\n",
            "Epoch 32/70, Batch 9/25, Image: rainy_2747.jpg, Loss_G: 10.0002, Loss_D_A: 0.0059, Loss_D_B: 0.0077\n",
            "Epoch 32/70, Batch 10/25, Image: rainy_1662.jpg, Loss_G: 12.4951, Loss_D_A: 0.0042, Loss_D_B: 0.0132\n",
            "Epoch 32/70, Batch 11/25, Image: rainy_2928.jpg, Loss_G: 9.7125, Loss_D_A: 0.0084, Loss_D_B: 0.0220\n",
            "Epoch 32/70, Batch 12/25, Image: rainy_2460.jpg, Loss_G: 8.7459, Loss_D_A: 0.0111, Loss_D_B: 0.0229\n",
            "Epoch 32/70, Batch 13/25, Image: rainy_2004.jpg, Loss_G: 12.5080, Loss_D_A: 0.0060, Loss_D_B: 0.0126\n",
            "Epoch 32/70, Batch 14/25, Image: rainy_2955.jpg, Loss_G: 9.0448, Loss_D_A: 0.0039, Loss_D_B: 0.0087\n",
            "Epoch 32/70, Batch 15/25, Image: rainy_3813.jpg, Loss_G: 8.6315, Loss_D_A: 0.0061, Loss_D_B: 0.0115\n",
            "Epoch 32/70, Batch 16/25, Image: rainy_3911.jpg, Loss_G: 10.8080, Loss_D_A: 0.0029, Loss_D_B: 0.0047\n",
            "Epoch 32/70, Batch 17/25, Image: rainy_3355.jpg, Loss_G: 9.3061, Loss_D_A: 0.0030, Loss_D_B: 0.0031\n",
            "Epoch 32/70, Batch 18/25, Image: rainy_3014.jpg, Loss_G: 11.1698, Loss_D_A: 0.0040, Loss_D_B: 0.0044\n",
            "Epoch 32/70, Batch 19/25, Image: rainy_1080.jpg, Loss_G: 8.2639, Loss_D_A: 0.0063, Loss_D_B: 0.0032\n",
            "Epoch 32/70, Batch 20/25, Image: rainy_2198.jpg, Loss_G: 9.6464, Loss_D_A: 0.0080, Loss_D_B: 0.0041\n",
            "Epoch 32/70, Batch 21/25, Image: rainy_662.jpg, Loss_G: 13.1495, Loss_D_A: 0.0083, Loss_D_B: 0.0038\n",
            "Epoch 32/70, Batch 22/25, Image: rainy_1346.jpg, Loss_G: 9.6070, Loss_D_A: 0.0080, Loss_D_B: 0.0024\n",
            "Epoch 32/70, Batch 23/25, Image: rainy_1508.jpg, Loss_G: 10.5974, Loss_D_A: 0.0050, Loss_D_B: 0.0031\n",
            "Epoch 32/70, Batch 24/25, Image: rainy_2197.jpg, Loss_G: 10.7588, Loss_D_A: 0.0046, Loss_D_B: 0.0054\n",
            "Epoch 33/70, Batch 0/25, Image: rainy_3355.jpg, Loss_G: 11.9845, Loss_D_A: 0.0030, Loss_D_B: 0.0069\n",
            "Epoch 33/70, Batch 1/25, Image: rainy_3428.jpg, Loss_G: 10.8026, Loss_D_A: 0.0072, Loss_D_B: 0.0078\n",
            "Epoch 33/70, Batch 2/25, Image: rainy_53.jpg, Loss_G: 10.2440, Loss_D_A: 0.0090, Loss_D_B: 0.0055\n",
            "Epoch 33/70, Batch 3/25, Image: rainy_752.jpg, Loss_G: 9.9566, Loss_D_A: 0.0084, Loss_D_B: 0.0086\n",
            "Epoch 33/70, Batch 4/25, Image: rainy_2928.jpg, Loss_G: 9.5457, Loss_D_A: 0.0050, Loss_D_B: 0.0091\n",
            "Epoch 33/70, Batch 5/25, Image: rainy_1434.jpg, Loss_G: 9.7830, Loss_D_A: 0.0038, Loss_D_B: 0.0048\n",
            "Epoch 33/70, Batch 6/25, Image: rainy_1820 (1).jpg, Loss_G: 9.9522, Loss_D_A: 0.0045, Loss_D_B: 0.0023\n",
            "Epoch 33/70, Batch 7/25, Image: rainy_2263.jpg, Loss_G: 10.3366, Loss_D_A: 0.0105, Loss_D_B: 0.0049\n",
            "Epoch 33/70, Batch 8/25, Image: rainy_2132.jpg, Loss_G: 10.5271, Loss_D_A: 0.0165, Loss_D_B: 0.0078\n",
            "Epoch 33/70, Batch 9/25, Image: rainy_537.jpg, Loss_G: 9.1113, Loss_D_A: 0.0182, Loss_D_B: 0.0116\n",
            "Epoch 33/70, Batch 10/25, Image: rainy_3584.jpg, Loss_G: 10.3013, Loss_D_A: 0.0091, Loss_D_B: 0.0149\n",
            "Epoch 33/70, Batch 11/25, Image: rainy_3445.jpg, Loss_G: 8.6347, Loss_D_A: 0.0035, Loss_D_B: 0.0112\n",
            "Epoch 33/70, Batch 12/25, Image: rainy_1674.jpg, Loss_G: 10.3219, Loss_D_A: 0.0057, Loss_D_B: 0.0085\n",
            "Epoch 33/70, Batch 13/25, Image: rainy_3164.jpg, Loss_G: 9.1325, Loss_D_A: 0.0046, Loss_D_B: 0.0070\n",
            "Epoch 33/70, Batch 14/25, Image: rainy_3063.jpg, Loss_G: 9.2915, Loss_D_A: 0.0053, Loss_D_B: 0.0052\n",
            "Epoch 33/70, Batch 15/25, Image: rainy_2259.jpg, Loss_G: 11.5600, Loss_D_A: 0.0050, Loss_D_B: 0.0040\n",
            "Epoch 33/70, Batch 16/25, Image: rainy_481.jpg, Loss_G: 9.5433, Loss_D_A: 0.0035, Loss_D_B: 0.0035\n",
            "Epoch 33/70, Batch 17/25, Image: rainy_1876.jpg, Loss_G: 9.7906, Loss_D_A: 0.0039, Loss_D_B: 0.0054\n",
            "Epoch 33/70, Batch 18/25, Image: rainy_1761.jpg, Loss_G: 9.4892, Loss_D_A: 0.0042, Loss_D_B: 0.0047\n",
            "Epoch 33/70, Batch 19/25, Image: rainy_2257.jpg, Loss_G: 10.7244, Loss_D_A: 0.0035, Loss_D_B: 0.0052\n",
            "Epoch 33/70, Batch 20/25, Image: rainy_1172.jpg, Loss_G: 8.1454, Loss_D_A: 0.0043, Loss_D_B: 0.0040\n",
            "Epoch 33/70, Batch 21/25, Image: rainy_3710.jpg, Loss_G: 10.2946, Loss_D_A: 0.0030, Loss_D_B: 0.0037\n",
            "Epoch 33/70, Batch 22/25, Image: rainy_1071.jpg, Loss_G: 9.6258, Loss_D_A: 0.0046, Loss_D_B: 0.0049\n",
            "Epoch 33/70, Batch 23/25, Image: rainy_2486.jpg, Loss_G: 9.6710, Loss_D_A: 0.0074, Loss_D_B: 0.0035\n",
            "Epoch 33/70, Batch 24/25, Image: rainy_3635.jpg, Loss_G: 9.9915, Loss_D_A: 0.0062, Loss_D_B: 0.0035\n",
            "Epoch 34/70, Batch 0/25, Image: rainy_3164.jpg, Loss_G: 9.5040, Loss_D_A: 0.0025, Loss_D_B: 0.0024\n",
            "Epoch 34/70, Batch 1/25, Image: rainy_475.jpg, Loss_G: 9.1416, Loss_D_A: 0.0022, Loss_D_B: 0.0018\n",
            "Epoch 34/70, Batch 2/25, Image: rainy_2973.jpg, Loss_G: 8.5663, Loss_D_A: 0.0026, Loss_D_B: 0.0041\n",
            "Epoch 34/70, Batch 3/25, Image: rainy_3511.jpg, Loss_G: 10.4937, Loss_D_A: 0.0024, Loss_D_B: 0.0055\n",
            "Epoch 34/70, Batch 4/25, Image: rainy_841.jpg, Loss_G: 9.4538, Loss_D_A: 0.0039, Loss_D_B: 0.0045\n",
            "Epoch 34/70, Batch 5/25, Image: rainy_1046.jpg, Loss_G: 12.2830, Loss_D_A: 0.0054, Loss_D_B: 0.0037\n",
            "Epoch 34/70, Batch 6/25, Image: rainy_1899.jpg, Loss_G: 10.4090, Loss_D_A: 0.0047, Loss_D_B: 0.0073\n",
            "Epoch 34/70, Batch 7/25, Image: rainy_332.jpg, Loss_G: 10.4411, Loss_D_A: 0.0046, Loss_D_B: 0.0080\n",
            "Epoch 34/70, Batch 8/25, Image: rainy_1426.jpg, Loss_G: 10.7993, Loss_D_A: 0.0079, Loss_D_B: 0.0056\n",
            "Epoch 34/70, Batch 9/25, Image: rainy_1591.jpg, Loss_G: 9.6147, Loss_D_A: 0.0119, Loss_D_B: 0.0067\n",
            "Epoch 34/70, Batch 10/25, Image: rainy_3813.jpg, Loss_G: 8.7875, Loss_D_A: 0.0071, Loss_D_B: 0.0075\n",
            "Epoch 34/70, Batch 11/25, Image: rainy_1530.jpg, Loss_G: 9.4884, Loss_D_A: 0.0038, Loss_D_B: 0.0072\n",
            "Epoch 34/70, Batch 12/25, Image: rainy_335.jpg, Loss_G: 11.6923, Loss_D_A: 0.0030, Loss_D_B: 0.0079\n",
            "Epoch 34/70, Batch 13/25, Image: rainy_119.jpg, Loss_G: 9.8759, Loss_D_A: 0.0021, Loss_D_B: 0.0067\n",
            "Epoch 34/70, Batch 14/25, Image: rainy_912.jpg, Loss_G: 12.2892, Loss_D_A: 0.0031, Loss_D_B: 0.0030\n",
            "Epoch 34/70, Batch 15/25, Image: rainy_769.jpg, Loss_G: 9.4833, Loss_D_A: 0.0025, Loss_D_B: 0.0024\n",
            "Epoch 34/70, Batch 16/25, Image: rainy_2431.jpg, Loss_G: 14.2826, Loss_D_A: 0.0025, Loss_D_B: 0.0025\n",
            "Epoch 34/70, Batch 17/25, Image: rainy_3010.jpg, Loss_G: 13.1783, Loss_D_A: 0.0026, Loss_D_B: 0.0032\n",
            "Epoch 34/70, Batch 18/25, Image: rainy_2628.jpg, Loss_G: 10.0212, Loss_D_A: 0.0035, Loss_D_B: 0.0024\n",
            "Epoch 34/70, Batch 19/25, Image: rainy_913.jpg, Loss_G: 13.9470, Loss_D_A: 0.0048, Loss_D_B: 0.0039\n",
            "Epoch 34/70, Batch 20/25, Image: rainy_2952.jpg, Loss_G: 11.5528, Loss_D_A: 0.0039, Loss_D_B: 0.0076\n",
            "Epoch 34/70, Batch 21/25, Image: rainy_3337.jpg, Loss_G: 8.2662, Loss_D_A: 0.0097, Loss_D_B: 0.0180\n",
            "Epoch 34/70, Batch 22/25, Image: rainy_1471.jpg, Loss_G: 10.7783, Loss_D_A: 0.0100, Loss_D_B: 0.0268\n",
            "Epoch 34/70, Batch 23/25, Image: rainy_2747.jpg, Loss_G: 10.1096, Loss_D_A: 0.0062, Loss_D_B: 0.0221\n",
            "Epoch 34/70, Batch 24/25, Image: rainy_2263.jpg, Loss_G: 9.6546, Loss_D_A: 0.0020, Loss_D_B: 0.0143\n",
            "Epoch 35/70, Batch 0/25, Image: rainy_3268.jpg, Loss_G: 9.5069, Loss_D_A: 0.0038, Loss_D_B: 0.0057\n",
            "Epoch 35/70, Batch 1/25, Image: rainy_2928.jpg, Loss_G: 9.7659, Loss_D_A: 0.0053, Loss_D_B: 0.0043\n",
            "Epoch 35/70, Batch 2/25, Image: rainy_1080.jpg, Loss_G: 8.7854, Loss_D_A: 0.0061, Loss_D_B: 0.0105\n",
            "Epoch 35/70, Batch 3/25, Image: rainy_3821.jpg, Loss_G: 10.0120, Loss_D_A: 0.0065, Loss_D_B: 0.0082\n",
            "Epoch 35/70, Batch 4/25, Image: rainy_2952.jpg, Loss_G: 10.1175, Loss_D_A: 0.0123, Loss_D_B: 0.0027\n",
            "Epoch 35/70, Batch 5/25, Image: rainy_1662.jpg, Loss_G: 9.5445, Loss_D_A: 0.0205, Loss_D_B: 0.0040\n",
            "Epoch 35/70, Batch 6/25, Image: rainy_232.jpg, Loss_G: 8.4183, Loss_D_A: 0.0198, Loss_D_B: 0.0133\n",
            "Epoch 35/70, Batch 7/25, Image: rainy_3710.jpg, Loss_G: 10.0068, Loss_D_A: 0.0121, Loss_D_B: 0.0169\n",
            "Epoch 35/70, Batch 8/25, Image: rainy_1083.jpg, Loss_G: 15.9538, Loss_D_A: 0.0077, Loss_D_B: 0.0224\n",
            "Epoch 35/70, Batch 9/25, Image: rainy_3385.jpg, Loss_G: 8.5122, Loss_D_A: 0.0110, Loss_D_B: 0.0320\n",
            "Epoch 35/70, Batch 10/25, Image: rainy_3014.jpg, Loss_G: 10.0617, Loss_D_A: 0.0133, Loss_D_B: 0.0227\n",
            "Epoch 35/70, Batch 11/25, Image: rainy_446.jpg, Loss_G: 9.1899, Loss_D_A: 0.0135, Loss_D_B: 0.0042\n",
            "Epoch 35/70, Batch 12/25, Image: rainy_923.jpg, Loss_G: 11.7301, Loss_D_A: 0.0123, Loss_D_B: 0.0182\n",
            "Epoch 35/70, Batch 13/25, Image: rainy_3193.jpg, Loss_G: 9.0117, Loss_D_A: 0.0042, Loss_D_B: 0.0354\n",
            "Epoch 35/70, Batch 14/25, Image: rainy_2453.jpg, Loss_G: 10.3358, Loss_D_A: 0.0031, Loss_D_B: 0.0379\n",
            "Epoch 35/70, Batch 15/25, Image: rainy_3584.jpg, Loss_G: 9.6474, Loss_D_A: 0.0026, Loss_D_B: 0.0347\n",
            "Epoch 35/70, Batch 16/25, Image: rainy_3063.jpg, Loss_G: 10.9797, Loss_D_A: 0.0063, Loss_D_B: 0.0326\n",
            "Epoch 35/70, Batch 17/25, Image: rainy_537.jpg, Loss_G: 13.3579, Loss_D_A: 0.0220, Loss_D_B: 0.0340\n",
            "Epoch 35/70, Batch 18/25, Image: rainy_2263.jpg, Loss_G: 9.4524, Loss_D_A: 0.0260, Loss_D_B: 0.0233\n",
            "Epoch 35/70, Batch 19/25, Image: rainy_3164.jpg, Loss_G: 9.9341, Loss_D_A: 0.0184, Loss_D_B: 0.0073\n",
            "Epoch 35/70, Batch 20/25, Image: rainy_3911.jpg, Loss_G: 11.6783, Loss_D_A: 0.0096, Loss_D_B: 0.0105\n",
            "Epoch 35/70, Batch 21/25, Image: rainy_2257.jpg, Loss_G: 11.2589, Loss_D_A: 0.0047, Loss_D_B: 0.0145\n",
            "Epoch 35/70, Batch 22/25, Image: rainy_2759.jpg, Loss_G: 10.2654, Loss_D_A: 0.0030, Loss_D_B: 0.0076\n",
            "Epoch 35/70, Batch 23/25, Image: rainy_1861.jpg, Loss_G: 8.6974, Loss_D_A: 0.0076, Loss_D_B: 0.0036\n",
            "Epoch 35/70, Batch 24/25, Image: rainy_748.jpg, Loss_G: 11.7968, Loss_D_A: 0.0127, Loss_D_B: 0.0028\n",
            "✅ Checkpoint saved at epoch 35\n",
            "Epoch 36/70, Batch 0/25, Image: rainy_773.jpg, Loss_G: 8.5241, Loss_D_A: 0.0070, Loss_D_B: 0.0025\n",
            "Epoch 36/70, Batch 1/25, Image: rainy_2928.jpg, Loss_G: 11.9723, Loss_D_A: 0.0036, Loss_D_B: 0.0021\n",
            "Epoch 36/70, Batch 2/25, Image: rainy_750.jpg, Loss_G: 10.1698, Loss_D_A: 0.0117, Loss_D_B: 0.0044\n",
            "Epoch 36/70, Batch 3/25, Image: rainy_2197.jpg, Loss_G: 13.5784, Loss_D_A: 0.0228, Loss_D_B: 0.0117\n",
            "Epoch 36/70, Batch 4/25, Image: rainy_3337.jpg, Loss_G: 8.7746, Loss_D_A: 0.0174, Loss_D_B: 0.0259\n",
            "Epoch 36/70, Batch 5/25, Image: rainy_1931.jpg, Loss_G: 9.5578, Loss_D_A: 0.0073, Loss_D_B: 0.0314\n",
            "Epoch 36/70, Batch 6/25, Image: rainy_2259.jpg, Loss_G: 9.0269, Loss_D_A: 0.0037, Loss_D_B: 0.0178\n",
            "Epoch 36/70, Batch 7/25, Image: rainy_2275.jpg, Loss_G: 9.7840, Loss_D_A: 0.0045, Loss_D_B: 0.0052\n",
            "Epoch 36/70, Batch 8/25, Image: rainy_540.jpg, Loss_G: 9.5582, Loss_D_A: 0.0054, Loss_D_B: 0.0036\n",
            "Epoch 36/70, Batch 9/25, Image: rainy_1432.jpg, Loss_G: 8.4810, Loss_D_A: 0.0051, Loss_D_B: 0.0066\n",
            "Epoch 36/70, Batch 10/25, Image: rainy_3156.jpg, Loss_G: 12.1060, Loss_D_A: 0.0090, Loss_D_B: 0.0135\n",
            "Epoch 36/70, Batch 11/25, Image: rainy_3769.jpg, Loss_G: 11.6755, Loss_D_A: 0.0166, Loss_D_B: 0.0214\n",
            "Epoch 36/70, Batch 12/25, Image: rainy_3398.jpg, Loss_G: 9.1883, Loss_D_A: 0.0115, Loss_D_B: 0.0181\n",
            "Epoch 36/70, Batch 13/25, Image: rainy_2973.jpg, Loss_G: 8.7925, Loss_D_A: 0.0039, Loss_D_B: 0.0072\n",
            "Epoch 36/70, Batch 14/25, Image: rainy_1071.jpg, Loss_G: 8.3994, Loss_D_A: 0.0076, Loss_D_B: 0.0061\n",
            "Epoch 36/70, Batch 15/25, Image: rainy_3164.jpg, Loss_G: 12.7917, Loss_D_A: 0.0096, Loss_D_B: 0.0061\n",
            "Epoch 36/70, Batch 16/25, Image: rainy_270.jpg, Loss_G: 12.8085, Loss_D_A: 0.0070, Loss_D_B: 0.0143\n",
            "Epoch 36/70, Batch 17/25, Image: rainy_1820 (1).jpg, Loss_G: 10.1321, Loss_D_A: 0.0047, Loss_D_B: 0.0170\n",
            "Epoch 36/70, Batch 18/25, Image: rainy_1381.jpg, Loss_G: 9.2571, Loss_D_A: 0.0048, Loss_D_B: 0.0196\n",
            "Epoch 36/70, Batch 19/25, Image: rainy_868.jpg, Loss_G: 9.5004, Loss_D_A: 0.0064, Loss_D_B: 0.0229\n",
            "Epoch 36/70, Batch 20/25, Image: rainy_3019.jpg, Loss_G: 11.9873, Loss_D_A: 0.0098, Loss_D_B: 0.0151\n",
            "Epoch 36/70, Batch 21/25, Image: rainy_2877.jpg, Loss_G: 11.8270, Loss_D_A: 0.0092, Loss_D_B: 0.0044\n",
            "Epoch 36/70, Batch 22/25, Image: rainy_1172.jpg, Loss_G: 11.1640, Loss_D_A: 0.0045, Loss_D_B: 0.0023\n",
            "Epoch 36/70, Batch 23/25, Image: rainy_1690.jpg, Loss_G: 9.0934, Loss_D_A: 0.0038, Loss_D_B: 0.0033\n",
            "Epoch 36/70, Batch 24/25, Image: rainy_3710.jpg, Loss_G: 10.4019, Loss_D_A: 0.0054, Loss_D_B: 0.0026\n",
            "Epoch 37/70, Batch 0/25, Image: rainy_298.jpg, Loss_G: 9.4746, Loss_D_A: 0.0088, Loss_D_B: 0.0030\n",
            "Epoch 37/70, Batch 1/25, Image: rainy_79.jpg, Loss_G: 8.8677, Loss_D_A: 0.0074, Loss_D_B: 0.0018\n",
            "Epoch 37/70, Batch 2/25, Image: rainy_2275.jpg, Loss_G: 9.0531, Loss_D_A: 0.0068, Loss_D_B: 0.0021\n",
            "Epoch 37/70, Batch 3/25, Image: rainy_1656.jpg, Loss_G: 9.4692, Loss_D_A: 0.0040, Loss_D_B: 0.0034\n",
            "Epoch 37/70, Batch 4/25, Image: rainy_2724.jpg, Loss_G: 8.7313, Loss_D_A: 0.0059, Loss_D_B: 0.0053\n",
            "Epoch 37/70, Batch 5/25, Image: rainy_2973.jpg, Loss_G: 9.2951, Loss_D_A: 0.0092, Loss_D_B: 0.0116\n",
            "Epoch 37/70, Batch 6/25, Image: rainy_2955.jpg, Loss_G: 8.7113, Loss_D_A: 0.0043, Loss_D_B: 0.0117\n",
            "Epoch 37/70, Batch 7/25, Image: rainy_2838.jpg, Loss_G: 8.5836, Loss_D_A: 0.0029, Loss_D_B: 0.0089\n",
            "Epoch 37/70, Batch 8/25, Image: rainy_1568.jpg, Loss_G: 8.9400, Loss_D_A: 0.0029, Loss_D_B: 0.0071\n",
            "Epoch 37/70, Batch 9/25, Image: rainy_923.jpg, Loss_G: 8.3731, Loss_D_A: 0.0025, Loss_D_B: 0.0053\n",
            "Epoch 37/70, Batch 10/25, Image: rainy_3337.jpg, Loss_G: 10.4687, Loss_D_A: 0.0048, Loss_D_B: 0.0049\n",
            "Epoch 37/70, Batch 11/25, Image: rainy_335.jpg, Loss_G: 9.7572, Loss_D_A: 0.0039, Loss_D_B: 0.0055\n",
            "Epoch 37/70, Batch 12/25, Image: rainy_1733.jpg, Loss_G: 8.5798, Loss_D_A: 0.0027, Loss_D_B: 0.0039\n",
            "Epoch 37/70, Batch 13/25, Image: rainy_1046.jpg, Loss_G: 8.5844, Loss_D_A: 0.0035, Loss_D_B: 0.0049\n",
            "Epoch 37/70, Batch 14/25, Image: rainy_1876.jpg, Loss_G: 8.1831, Loss_D_A: 0.0021, Loss_D_B: 0.0031\n",
            "Epoch 37/70, Batch 15/25, Image: rainy_795.jpg, Loss_G: 10.9471, Loss_D_A: 0.0023, Loss_D_B: 0.0033\n",
            "Epoch 37/70, Batch 16/25, Image: rainy_1381.jpg, Loss_G: 11.5368, Loss_D_A: 0.0019, Loss_D_B: 0.0052\n",
            "Epoch 37/70, Batch 17/25, Image: rainy_537.jpg, Loss_G: 9.1192, Loss_D_A: 0.0039, Loss_D_B: 0.0027\n",
            "Epoch 37/70, Batch 18/25, Image: rainy_2747.jpg, Loss_G: 10.4192, Loss_D_A: 0.0040, Loss_D_B: 0.0023\n",
            "Epoch 37/70, Batch 19/25, Image: rainy_1674.jpg, Loss_G: 14.9852, Loss_D_A: 0.0029, Loss_D_B: 0.0023\n",
            "Epoch 37/70, Batch 20/25, Image: rainy_3136.jpg, Loss_G: 9.2135, Loss_D_A: 0.0053, Loss_D_B: 0.0039\n",
            "Epoch 37/70, Batch 21/25, Image: rainy_1639.jpg, Loss_G: 11.0140, Loss_D_A: 0.0060, Loss_D_B: 0.0057\n",
            "Epoch 37/70, Batch 22/25, Image: rainy_119.jpg, Loss_G: 11.5281, Loss_D_A: 0.0059, Loss_D_B: 0.0050\n",
            "Epoch 37/70, Batch 23/25, Image: rainy_3821.jpg, Loss_G: 10.6862, Loss_D_A: 0.0026, Loss_D_B: 0.0027\n",
            "Epoch 37/70, Batch 24/25, Image: rainy_2943.jpg, Loss_G: 9.0963, Loss_D_A: 0.0027, Loss_D_B: 0.0023\n",
            "Epoch 38/70, Batch 0/25, Image: rainy_199.jpg, Loss_G: 11.0439, Loss_D_A: 0.0019, Loss_D_B: 0.0023\n",
            "Epoch 38/70, Batch 1/25, Image: rainy_849.jpg, Loss_G: 8.7724, Loss_D_A: 0.0035, Loss_D_B: 0.0034\n",
            "Epoch 38/70, Batch 2/25, Image: rainy_2977.jpg, Loss_G: 10.4650, Loss_D_A: 0.0052, Loss_D_B: 0.0054\n",
            "Epoch 38/70, Batch 3/25, Image: rainy_1059.jpg, Loss_G: 9.5485, Loss_D_A: 0.0045, Loss_D_B: 0.0081\n",
            "Epoch 38/70, Batch 4/25, Image: rainy_1555.jpg, Loss_G: 9.8487, Loss_D_A: 0.0022, Loss_D_B: 0.0044\n",
            "Epoch 38/70, Batch 5/25, Image: rainy_1286.jpg, Loss_G: 8.8265, Loss_D_A: 0.0037, Loss_D_B: 0.0042\n",
            "Epoch 38/70, Batch 6/25, Image: rainy_2620.jpg, Loss_G: 10.2695, Loss_D_A: 0.0051, Loss_D_B: 0.0040\n",
            "Epoch 38/70, Batch 7/25, Image: rainy_1185.jpg, Loss_G: 11.5345, Loss_D_A: 0.0041, Loss_D_B: 0.0063\n",
            "Epoch 38/70, Batch 8/25, Image: rainy_3336.jpg, Loss_G: 11.3396, Loss_D_A: 0.0086, Loss_D_B: 0.0101\n",
            "Epoch 38/70, Batch 9/25, Image: rainy_398.jpg, Loss_G: 10.0089, Loss_D_A: 0.0150, Loss_D_B: 0.0161\n",
            "Epoch 38/70, Batch 10/25, Image: rainy_814.jpg, Loss_G: 9.5172, Loss_D_A: 0.0168, Loss_D_B: 0.0134\n",
            "Epoch 38/70, Batch 11/25, Image: rainy_2195.jpg, Loss_G: 9.1715, Loss_D_A: 0.0183, Loss_D_B: 0.0097\n",
            "Epoch 38/70, Batch 12/25, Image: rainy_3063.jpg, Loss_G: 8.8100, Loss_D_A: 0.0240, Loss_D_B: 0.0052\n",
            "Epoch 38/70, Batch 13/25, Image: rainy_2985.jpg, Loss_G: 9.9263, Loss_D_A: 0.0240, Loss_D_B: 0.0046\n",
            "Epoch 38/70, Batch 14/25, Image: rainy_2838.jpg, Loss_G: 8.5940, Loss_D_A: 0.0168, Loss_D_B: 0.0065\n",
            "Epoch 38/70, Batch 15/25, Image: rainy_2197.jpg, Loss_G: 8.7287, Loss_D_A: 0.0093, Loss_D_B: 0.0059\n",
            "Epoch 38/70, Batch 16/25, Image: rainy_3363.jpg, Loss_G: 10.2861, Loss_D_A: 0.0076, Loss_D_B: 0.0061\n",
            "Epoch 38/70, Batch 17/25, Image: rainy_1766.jpg, Loss_G: 8.0293, Loss_D_A: 0.0050, Loss_D_B: 0.0045\n",
            "Epoch 38/70, Batch 18/25, Image: rainy_335.jpg, Loss_G: 8.6305, Loss_D_A: 0.0065, Loss_D_B: 0.0085\n",
            "Epoch 38/70, Batch 19/25, Image: rainy_2198.jpg, Loss_G: 9.6093, Loss_D_A: 0.0075, Loss_D_B: 0.0039\n",
            "Epoch 38/70, Batch 20/25, Image: rainy_2629.jpg, Loss_G: 8.8466, Loss_D_A: 0.0072, Loss_D_B: 0.0031\n",
            "Epoch 38/70, Batch 21/25, Image: rainy_2257.jpg, Loss_G: 9.6543, Loss_D_A: 0.0059, Loss_D_B: 0.0021\n",
            "Epoch 38/70, Batch 22/25, Image: rainy_2747.jpg, Loss_G: 7.9377, Loss_D_A: 0.0027, Loss_D_B: 0.0037\n",
            "Epoch 38/70, Batch 23/25, Image: rainy_2973.jpg, Loss_G: 13.0385, Loss_D_A: 0.0034, Loss_D_B: 0.0087\n",
            "Epoch 38/70, Batch 24/25, Image: rainy_3821.jpg, Loss_G: 9.6331, Loss_D_A: 0.0056, Loss_D_B: 0.0190\n",
            "Epoch 39/70, Batch 0/25, Image: rainy_3951.jpg, Loss_G: 9.1311, Loss_D_A: 0.0070, Loss_D_B: 0.0243\n",
            "Epoch 39/70, Batch 1/25, Image: rainy_270.jpg, Loss_G: 9.0834, Loss_D_A: 0.0072, Loss_D_B: 0.0200\n",
            "Epoch 39/70, Batch 2/25, Image: rainy_1674.jpg, Loss_G: 11.1528, Loss_D_A: 0.0035, Loss_D_B: 0.0135\n",
            "Epoch 39/70, Batch 3/25, Image: rainy_3090.jpg, Loss_G: 9.4147, Loss_D_A: 0.0067, Loss_D_B: 0.0041\n",
            "Epoch 39/70, Batch 4/25, Image: rainy_3020.jpg, Loss_G: 8.6946, Loss_D_A: 0.0116, Loss_D_B: 0.0036\n",
            "Epoch 39/70, Batch 5/25, Image: rainy_2513.jpg, Loss_G: 10.7249, Loss_D_A: 0.0078, Loss_D_B: 0.0065\n",
            "Epoch 39/70, Batch 6/25, Image: rainy_2619.jpg, Loss_G: 8.9154, Loss_D_A: 0.0024, Loss_D_B: 0.0127\n",
            "Epoch 39/70, Batch 7/25, Image: rainy_3385.jpg, Loss_G: 7.9763, Loss_D_A: 0.0076, Loss_D_B: 0.0176\n",
            "Epoch 39/70, Batch 8/25, Image: rainy_2747.jpg, Loss_G: 9.1296, Loss_D_A: 0.0067, Loss_D_B: 0.0123\n",
            "Epoch 39/70, Batch 9/25, Image: rainy_1820 (1).jpg, Loss_G: 12.5746, Loss_D_A: 0.0113, Loss_D_B: 0.0100\n",
            "Epoch 39/70, Batch 10/25, Image: rainy_1766.jpg, Loss_G: 9.8103, Loss_D_A: 0.0375, Loss_D_B: 0.0147\n",
            "Epoch 39/70, Batch 11/25, Image: rainy_2629.jpg, Loss_G: 7.9567, Loss_D_A: 0.0456, Loss_D_B: 0.0195\n",
            "Epoch 39/70, Batch 12/25, Image: rainy_1876.jpg, Loss_G: 8.6085, Loss_D_A: 0.0347, Loss_D_B: 0.0092\n",
            "Epoch 39/70, Batch 13/25, Image: rainy_2263.jpg, Loss_G: 8.6833, Loss_D_A: 0.0245, Loss_D_B: 0.0040\n",
            "Epoch 39/70, Batch 14/25, Image: rainy_3078.jpg, Loss_G: 9.9975, Loss_D_A: 0.0136, Loss_D_B: 0.0034\n",
            "Epoch 39/70, Batch 15/25, Image: rainy_1690.jpg, Loss_G: 10.6573, Loss_D_A: 0.0053, Loss_D_B: 0.0034\n",
            "Epoch 39/70, Batch 16/25, Image: rainy_1771.jpg, Loss_G: 8.0497, Loss_D_A: 0.0067, Loss_D_B: 0.0025\n",
            "Epoch 39/70, Batch 17/25, Image: rainy_662.jpg, Loss_G: 8.7600, Loss_D_A: 0.0087, Loss_D_B: 0.0069\n",
            "Epoch 39/70, Batch 18/25, Image: rainy_3342.jpg, Loss_G: 8.0210, Loss_D_A: 0.0057, Loss_D_B: 0.0061\n",
            "Epoch 39/70, Batch 19/25, Image: rainy_2714.jpg, Loss_G: 9.2955, Loss_D_A: 0.0057, Loss_D_B: 0.0071\n",
            "Epoch 39/70, Batch 20/25, Image: rainy_1059.jpg, Loss_G: 9.9886, Loss_D_A: 0.0036, Loss_D_B: 0.0032\n",
            "Epoch 39/70, Batch 21/25, Image: rainy_3584.jpg, Loss_G: 9.5923, Loss_D_A: 0.0042, Loss_D_B: 0.0019\n",
            "Epoch 39/70, Batch 22/25, Image: rainy_1456.jpg, Loss_G: 8.7225, Loss_D_A: 0.0050, Loss_D_B: 0.0019\n",
            "Epoch 39/70, Batch 23/25, Image: rainy_2877.jpg, Loss_G: 9.2005, Loss_D_A: 0.0068, Loss_D_B: 0.0025\n",
            "Epoch 39/70, Batch 24/25, Image: rainy_826.jpg, Loss_G: 8.4839, Loss_D_A: 0.0041, Loss_D_B: 0.0058\n",
            "Epoch 40/70, Batch 0/25, Image: rainy_79.jpg, Loss_G: 9.1595, Loss_D_A: 0.0032, Loss_D_B: 0.0102\n",
            "Epoch 40/70, Batch 1/25, Image: rainy_3010.jpg, Loss_G: 8.5885, Loss_D_A: 0.0058, Loss_D_B: 0.0109\n",
            "Epoch 40/70, Batch 2/25, Image: rainy_2857.jpg, Loss_G: 9.1392, Loss_D_A: 0.0030, Loss_D_B: 0.0127\n",
            "Epoch 40/70, Batch 3/25, Image: rainy_3428.jpg, Loss_G: 8.6796, Loss_D_A: 0.0106, Loss_D_B: 0.0148\n",
            "Epoch 40/70, Batch 4/25, Image: rainy_2943.jpg, Loss_G: 7.9987, Loss_D_A: 0.0192, Loss_D_B: 0.0111\n",
            "Epoch 40/70, Batch 5/25, Image: rainy_2859.jpg, Loss_G: 8.4784, Loss_D_A: 0.0121, Loss_D_B: 0.0043\n",
            "Epoch 40/70, Batch 6/25, Image: rainy_3342.jpg, Loss_G: 7.5622, Loss_D_A: 0.0046, Loss_D_B: 0.0032\n",
            "Epoch 40/70, Batch 7/25, Image: rainy_2513.jpg, Loss_G: 7.6817, Loss_D_A: 0.0095, Loss_D_B: 0.0092\n",
            "Epoch 40/70, Batch 8/25, Image: rainy_1434.jpg, Loss_G: 9.9808, Loss_D_A: 0.0110, Loss_D_B: 0.0191\n",
            "Epoch 40/70, Batch 9/25, Image: rainy_332.jpg, Loss_G: 9.4155, Loss_D_A: 0.0093, Loss_D_B: 0.0227\n",
            "Epoch 40/70, Batch 10/25, Image: rainy_3355.jpg, Loss_G: 10.5174, Loss_D_A: 0.0126, Loss_D_B: 0.0189\n",
            "Epoch 40/70, Batch 11/25, Image: rainy_993.jpg, Loss_G: 7.9469, Loss_D_A: 0.0092, Loss_D_B: 0.0059\n",
            "Epoch 40/70, Batch 12/25, Image: rainy_3014.jpg, Loss_G: 10.2263, Loss_D_A: 0.0063, Loss_D_B: 0.0040\n",
            "Epoch 40/70, Batch 13/25, Image: rainy_3710.jpg, Loss_G: 9.5466, Loss_D_A: 0.0079, Loss_D_B: 0.0037\n",
            "Epoch 40/70, Batch 14/25, Image: rainy_1733.jpg, Loss_G: 12.6710, Loss_D_A: 0.0048, Loss_D_B: 0.0066\n",
            "Epoch 40/70, Batch 15/25, Image: rainy_662.jpg, Loss_G: 8.3766, Loss_D_A: 0.0071, Loss_D_B: 0.0098\n",
            "Epoch 40/70, Batch 16/25, Image: rainy_3019.jpg, Loss_G: 8.4293, Loss_D_A: 0.0164, Loss_D_B: 0.0104\n",
            "Epoch 40/70, Batch 17/25, Image: rainy_446.jpg, Loss_G: 11.1850, Loss_D_A: 0.0093, Loss_D_B: 0.0045\n",
            "Epoch 40/70, Batch 18/25, Image: rainy_2195.jpg, Loss_G: 11.1983, Loss_D_A: 0.0032, Loss_D_B: 0.0041\n",
            "Epoch 40/70, Batch 19/25, Image: rainy_923.jpg, Loss_G: 8.7900, Loss_D_A: 0.0135, Loss_D_B: 0.0063\n",
            "Epoch 40/70, Batch 20/25, Image: rainy_2836.jpg, Loss_G: 10.0861, Loss_D_A: 0.0225, Loss_D_B: 0.0032\n",
            "Epoch 40/70, Batch 21/25, Image: rainy_1046.jpg, Loss_G: 10.0429, Loss_D_A: 0.0238, Loss_D_B: 0.0079\n",
            "Epoch 40/70, Batch 22/25, Image: rainy_773.jpg, Loss_G: 8.6325, Loss_D_A: 0.0093, Loss_D_B: 0.0045\n",
            "Epoch 40/70, Batch 23/25, Image: rainy_904.jpg, Loss_G: 12.6255, Loss_D_A: 0.0217, Loss_D_B: 0.0129\n",
            "Epoch 40/70, Batch 24/25, Image: rainy_841.jpg, Loss_G: 14.9245, Loss_D_A: 0.0818, Loss_D_B: 0.0125\n",
            "✅ Checkpoint saved at epoch 40\n",
            "Epoch 41/70, Batch 0/25, Image: rainy_491.jpg, Loss_G: 12.9337, Loss_D_A: 0.1221, Loss_D_B: 0.0078\n",
            "Epoch 41/70, Batch 1/25, Image: rainy_104.jpg, Loss_G: 10.3273, Loss_D_A: 0.0641, Loss_D_B: 0.0039\n",
            "Epoch 41/70, Batch 2/25, Image: rainy_3014.jpg, Loss_G: 11.4106, Loss_D_A: 0.0190, Loss_D_B: 0.0090\n",
            "Epoch 41/70, Batch 3/25, Image: rainy_2198.jpg, Loss_G: 12.4720, Loss_D_A: 0.0075, Loss_D_B: 0.0059\n",
            "Epoch 41/70, Batch 4/25, Image: rainy_536.jpg, Loss_G: 15.9604, Loss_D_A: 0.0059, Loss_D_B: 0.0053\n",
            "Epoch 41/70, Batch 5/25, Image: rainy_1834.jpg, Loss_G: 8.7224, Loss_D_A: 0.0057, Loss_D_B: 0.0096\n",
            "Epoch 41/70, Batch 6/25, Image: rainy_1599.jpg, Loss_G: 11.2522, Loss_D_A: 0.0200, Loss_D_B: 0.0196\n",
            "Epoch 41/70, Batch 7/25, Image: rainy_1555.jpg, Loss_G: 9.3863, Loss_D_A: 0.0381, Loss_D_B: 0.0217\n",
            "Epoch 41/70, Batch 8/25, Image: rainy_1784.jpg, Loss_G: 11.4458, Loss_D_A: 0.0447, Loss_D_B: 0.0104\n",
            "Epoch 41/70, Batch 9/25, Image: rainy_2257.jpg, Loss_G: 9.0894, Loss_D_A: 0.0354, Loss_D_B: 0.0084\n",
            "Epoch 41/70, Batch 10/25, Image: rainy_446.jpg, Loss_G: 8.8440, Loss_D_A: 0.0152, Loss_D_B: 0.0072\n",
            "Epoch 41/70, Batch 11/25, Image: rainy_2836.jpg, Loss_G: 8.5596, Loss_D_A: 0.0052, Loss_D_B: 0.0042\n",
            "Epoch 41/70, Batch 12/25, Image: rainy_2544.jpg, Loss_G: 9.1422, Loss_D_A: 0.0033, Loss_D_B: 0.0020\n",
            "Epoch 41/70, Batch 13/25, Image: rainy_1158.jpg, Loss_G: 9.2354, Loss_D_A: 0.0035, Loss_D_B: 0.0015\n",
            "Epoch 41/70, Batch 14/25, Image: rainy_1690.jpg, Loss_G: 8.5920, Loss_D_A: 0.0025, Loss_D_B: 0.0017\n",
            "Epoch 41/70, Batch 15/25, Image: rainy_2838.jpg, Loss_G: 8.4210, Loss_D_A: 0.0032, Loss_D_B: 0.0026\n",
            "Epoch 41/70, Batch 16/25, Image: rainy_2859.jpg, Loss_G: 9.1667, Loss_D_A: 0.0029, Loss_D_B: 0.0061\n",
            "Epoch 41/70, Batch 17/25, Image: rainy_1381.jpg, Loss_G: 8.7631, Loss_D_A: 0.0034, Loss_D_B: 0.0062\n",
            "Epoch 41/70, Batch 18/25, Image: rainy_2486.jpg, Loss_G: 7.9769, Loss_D_A: 0.0030, Loss_D_B: 0.0036\n",
            "Epoch 41/70, Batch 19/25, Image: rainy_3428.jpg, Loss_G: 10.3984, Loss_D_A: 0.0033, Loss_D_B: 0.0027\n",
            "Epoch 41/70, Batch 20/25, Image: rainy_2955.jpg, Loss_G: 9.7824, Loss_D_A: 0.0031, Loss_D_B: 0.0025\n",
            "Epoch 41/70, Batch 21/25, Image: rainy_270.jpg, Loss_G: 9.6518, Loss_D_A: 0.0039, Loss_D_B: 0.0031\n",
            "Epoch 41/70, Batch 22/25, Image: rainy_335.jpg, Loss_G: 10.6783, Loss_D_A: 0.0075, Loss_D_B: 0.0085\n",
            "Epoch 41/70, Batch 23/25, Image: rainy_298.jpg, Loss_G: 8.5204, Loss_D_A: 0.0030, Loss_D_B: 0.0110\n",
            "Epoch 41/70, Batch 24/25, Image: rainy_3063.jpg, Loss_G: 8.7002, Loss_D_A: 0.0031, Loss_D_B: 0.0103\n",
            "Epoch 42/70, Batch 0/25, Image: rainy_3363.jpg, Loss_G: 9.5927, Loss_D_A: 0.0034, Loss_D_B: 0.0056\n",
            "Epoch 42/70, Batch 1/25, Image: rainy_429.jpg, Loss_G: 9.4217, Loss_D_A: 0.0048, Loss_D_B: 0.0064\n",
            "Epoch 42/70, Batch 2/25, Image: rainy_750.jpg, Loss_G: 8.7064, Loss_D_A: 0.0139, Loss_D_B: 0.0027\n",
            "Epoch 42/70, Batch 3/25, Image: rainy_3769.jpg, Loss_G: 9.4722, Loss_D_A: 0.0181, Loss_D_B: 0.0014\n",
            "Epoch 42/70, Batch 4/25, Image: rainy_1820 (1).jpg, Loss_G: 9.9445, Loss_D_A: 0.0085, Loss_D_B: 0.0024\n",
            "Epoch 42/70, Batch 5/25, Image: rainy_2928.jpg, Loss_G: 10.9916, Loss_D_A: 0.0026, Loss_D_B: 0.0023\n",
            "Epoch 42/70, Batch 6/25, Image: rainy_475.jpg, Loss_G: 10.8541, Loss_D_A: 0.0034, Loss_D_B: 0.0017\n",
            "Epoch 42/70, Batch 7/25, Image: rainy_902.jpg, Loss_G: 9.9622, Loss_D_A: 0.0028, Loss_D_B: 0.0020\n",
            "Epoch 42/70, Batch 8/25, Image: rainy_826.jpg, Loss_G: 9.8643, Loss_D_A: 0.0074, Loss_D_B: 0.0018\n",
            "Epoch 42/70, Batch 9/25, Image: rainy_2838.jpg, Loss_G: 11.8964, Loss_D_A: 0.0094, Loss_D_B: 0.0023\n",
            "Epoch 42/70, Batch 10/25, Image: rainy_2259.jpg, Loss_G: 8.7547, Loss_D_A: 0.0098, Loss_D_B: 0.0041\n",
            "Epoch 42/70, Batch 11/25, Image: rainy_3020.jpg, Loss_G: 9.7483, Loss_D_A: 0.0052, Loss_D_B: 0.0026\n",
            "Epoch 42/70, Batch 12/25, Image: rainy_79.jpg, Loss_G: 13.1021, Loss_D_A: 0.0024, Loss_D_B: 0.0027\n",
            "Epoch 42/70, Batch 13/25, Image: rainy_1876.jpg, Loss_G: 8.3217, Loss_D_A: 0.0057, Loss_D_B: 0.0028\n",
            "Epoch 42/70, Batch 14/25, Image: rainy_2492.jpg, Loss_G: 9.6780, Loss_D_A: 0.0140, Loss_D_B: 0.0070\n",
            "Epoch 42/70, Batch 15/25, Image: rainy_1426.jpg, Loss_G: 11.3521, Loss_D_A: 0.0083, Loss_D_B: 0.0074\n",
            "Epoch 42/70, Batch 16/25, Image: rainy_413.jpg, Loss_G: 10.3531, Loss_D_A: 0.0028, Loss_D_B: 0.0078\n",
            "Epoch 42/70, Batch 17/25, Image: rainy_1286.jpg, Loss_G: 12.1299, Loss_D_A: 0.0094, Loss_D_B: 0.0038\n",
            "Epoch 42/70, Batch 18/25, Image: rainy_3385.jpg, Loss_G: 9.2694, Loss_D_A: 0.0125, Loss_D_B: 0.0028\n",
            "Epoch 42/70, Batch 19/25, Image: rainy_752.jpg, Loss_G: 8.4459, Loss_D_A: 0.0082, Loss_D_B: 0.0020\n",
            "Epoch 42/70, Batch 20/25, Image: rainy_382.jpg, Loss_G: 8.9598, Loss_D_A: 0.0038, Loss_D_B: 0.0026\n",
            "Epoch 42/70, Batch 21/25, Image: rainy_3529.jpg, Loss_G: 9.0830, Loss_D_A: 0.0034, Loss_D_B: 0.0018\n",
            "Epoch 42/70, Batch 22/25, Image: rainy_2198.jpg, Loss_G: 8.5457, Loss_D_A: 0.0031, Loss_D_B: 0.0024\n",
            "Epoch 42/70, Batch 23/25, Image: rainy_3398.jpg, Loss_G: 11.7678, Loss_D_A: 0.0051, Loss_D_B: 0.0047\n",
            "Epoch 42/70, Batch 24/25, Image: rainy_3060.jpg, Loss_G: 9.5584, Loss_D_A: 0.0035, Loss_D_B: 0.0083\n",
            "Epoch 43/70, Batch 0/25, Image: rainy_1690.jpg, Loss_G: 9.6511, Loss_D_A: 0.0034, Loss_D_B: 0.0098\n",
            "Epoch 43/70, Batch 1/25, Image: rainy_1083.jpg, Loss_G: 10.2952, Loss_D_A: 0.0039, Loss_D_B: 0.0078\n",
            "Epoch 43/70, Batch 2/25, Image: rainy_3371.jpg, Loss_G: 8.9368, Loss_D_A: 0.0044, Loss_D_B: 0.0037\n",
            "Epoch 43/70, Batch 3/25, Image: rainy_2859.jpg, Loss_G: 8.8194, Loss_D_A: 0.0049, Loss_D_B: 0.0024\n",
            "Epoch 43/70, Batch 4/25, Image: rainy_3019.jpg, Loss_G: 10.2660, Loss_D_A: 0.0039, Loss_D_B: 0.0050\n",
            "Epoch 43/70, Batch 5/25, Image: rainy_2724.jpg, Loss_G: 8.4206, Loss_D_A: 0.0023, Loss_D_B: 0.0082\n",
            "Epoch 43/70, Batch 6/25, Image: rainy_912.jpg, Loss_G: 10.6022, Loss_D_A: 0.0028, Loss_D_B: 0.0071\n",
            "Epoch 43/70, Batch 7/25, Image: rainy_558.jpg, Loss_G: 7.8409, Loss_D_A: 0.0027, Loss_D_B: 0.0047\n",
            "Epoch 43/70, Batch 8/25, Image: rainy_2060.jpg, Loss_G: 8.1790, Loss_D_A: 0.0018, Loss_D_B: 0.0049\n",
            "Epoch 43/70, Batch 9/25, Image: rainy_1820 (1).jpg, Loss_G: 10.4575, Loss_D_A: 0.0023, Loss_D_B: 0.0029\n",
            "Epoch 43/70, Batch 10/25, Image: rainy_166.jpg, Loss_G: 8.2059, Loss_D_A: 0.0038, Loss_D_B: 0.0015\n",
            "Epoch 43/70, Batch 11/25, Image: rainy_3710.jpg, Loss_G: 10.0064, Loss_D_A: 0.0040, Loss_D_B: 0.0065\n",
            "Epoch 43/70, Batch 12/25, Image: rainy_3355.jpg, Loss_G: 9.0149, Loss_D_A: 0.0045, Loss_D_B: 0.0058\n",
            "Epoch 43/70, Batch 13/25, Image: rainy_2004.jpg, Loss_G: 8.9027, Loss_D_A: 0.0048, Loss_D_B: 0.0101\n",
            "Epoch 43/70, Batch 14/25, Image: rainy_773.jpg, Loss_G: 8.9365, Loss_D_A: 0.0047, Loss_D_B: 0.0076\n",
            "Epoch 43/70, Batch 15/25, Image: rainy_2275.jpg, Loss_G: 9.1291, Loss_D_A: 0.0031, Loss_D_B: 0.0048\n",
            "Epoch 43/70, Batch 16/25, Image: rainy_1426.jpg, Loss_G: 8.7278, Loss_D_A: 0.0037, Loss_D_B: 0.0031\n",
            "Epoch 43/70, Batch 17/25, Image: rainy_2195.jpg, Loss_G: 10.1169, Loss_D_A: 0.0030, Loss_D_B: 0.0029\n",
            "Epoch 43/70, Batch 18/25, Image: rainy_475.jpg, Loss_G: 8.9672, Loss_D_A: 0.0031, Loss_D_B: 0.0022\n",
            "Epoch 43/70, Batch 19/25, Image: rainy_1482.jpg, Loss_G: 8.0920, Loss_D_A: 0.0016, Loss_D_B: 0.0058\n",
            "Epoch 43/70, Batch 20/25, Image: rainy_750.jpg, Loss_G: 8.4244, Loss_D_A: 0.0020, Loss_D_B: 0.0060\n",
            "Epoch 43/70, Batch 21/25, Image: rainy_923.jpg, Loss_G: 8.3004, Loss_D_A: 0.0015, Loss_D_B: 0.0029\n",
            "Epoch 43/70, Batch 22/25, Image: rainy_913.jpg, Loss_G: 10.1879, Loss_D_A: 0.0038, Loss_D_B: 0.0138\n",
            "Epoch 43/70, Batch 23/25, Image: rainy_2836.jpg, Loss_G: 10.2304, Loss_D_A: 0.0026, Loss_D_B: 0.0313\n",
            "Epoch 43/70, Batch 24/25, Image: rainy_3010.jpg, Loss_G: 11.6360, Loss_D_A: 0.0020, Loss_D_B: 0.0357\n",
            "Epoch 44/70, Batch 0/25, Image: rainy_1426.jpg, Loss_G: 9.2153, Loss_D_A: 0.0024, Loss_D_B: 0.0358\n",
            "Epoch 44/70, Batch 1/25, Image: rainy_205.jpg, Loss_G: 8.4246, Loss_D_A: 0.0021, Loss_D_B: 0.0351\n",
            "Epoch 44/70, Batch 2/25, Image: rainy_3156.jpg, Loss_G: 8.0064, Loss_D_A: 0.0023, Loss_D_B: 0.0233\n",
            "Epoch 44/70, Batch 3/25, Image: rainy_199.jpg, Loss_G: 10.2904, Loss_D_A: 0.0051, Loss_D_B: 0.0140\n",
            "Epoch 44/70, Batch 4/25, Image: rainy_1591.jpg, Loss_G: 9.2635, Loss_D_A: 0.0066, Loss_D_B: 0.0045\n",
            "Epoch 44/70, Batch 5/25, Image: rainy_166.jpg, Loss_G: 10.2472, Loss_D_A: 0.0030, Loss_D_B: 0.0041\n",
            "Epoch 44/70, Batch 6/25, Image: rainy_79.jpg, Loss_G: 9.6901, Loss_D_A: 0.0035, Loss_D_B: 0.0132\n",
            "Epoch 44/70, Batch 7/25, Image: rainy_429.jpg, Loss_G: 9.6873, Loss_D_A: 0.0051, Loss_D_B: 0.0144\n",
            "Epoch 44/70, Batch 8/25, Image: rainy_3063.jpg, Loss_G: 8.4372, Loss_D_A: 0.0050, Loss_D_B: 0.0033\n",
            "Epoch 44/70, Batch 9/25, Image: rainy_2195.jpg, Loss_G: 10.9391, Loss_D_A: 0.0035, Loss_D_B: 0.0033\n",
            "Epoch 44/70, Batch 10/25, Image: rainy_1733.jpg, Loss_G: 9.6769, Loss_D_A: 0.0048, Loss_D_B: 0.0063\n",
            "Epoch 44/70, Batch 11/25, Image: rainy_446.jpg, Loss_G: 11.7661, Loss_D_A: 0.0036, Loss_D_B: 0.0041\n",
            "Epoch 44/70, Batch 12/25, Image: rainy_447.jpg, Loss_G: 8.8230, Loss_D_A: 0.0033, Loss_D_B: 0.0045\n",
            "Epoch 44/70, Batch 13/25, Image: rainy_2779.jpg, Loss_G: 8.3848, Loss_D_A: 0.0031, Loss_D_B: 0.0101\n",
            "Epoch 44/70, Batch 14/25, Image: rainy_2859.jpg, Loss_G: 8.5533, Loss_D_A: 0.0046, Loss_D_B: 0.0099\n",
            "Epoch 44/70, Batch 15/25, Image: rainy_332.jpg, Loss_G: 11.2356, Loss_D_A: 0.0081, Loss_D_B: 0.0043\n",
            "Epoch 44/70, Batch 16/25, Image: rainy_3336.jpg, Loss_G: 10.8622, Loss_D_A: 0.0038, Loss_D_B: 0.0026\n",
            "Epoch 44/70, Batch 17/25, Image: rainy_3606.jpg, Loss_G: 7.6201, Loss_D_A: 0.0019, Loss_D_B: 0.0085\n",
            "Epoch 44/70, Batch 18/25, Image: rainy_3136.jpg, Loss_G: 9.1186, Loss_D_A: 0.0020, Loss_D_B: 0.0088\n",
            "Epoch 44/70, Batch 19/25, Image: rainy_491.jpg, Loss_G: 11.9921, Loss_D_A: 0.0046, Loss_D_B: 0.0103\n",
            "Epoch 44/70, Batch 20/25, Image: rainy_540.jpg, Loss_G: 9.3125, Loss_D_A: 0.0051, Loss_D_B: 0.0096\n",
            "Epoch 44/70, Batch 21/25, Image: rainy_2724.jpg, Loss_G: 9.4428, Loss_D_A: 0.0026, Loss_D_B: 0.0034\n",
            "Epoch 44/70, Batch 22/25, Image: rainy_1172.jpg, Loss_G: 9.7113, Loss_D_A: 0.0056, Loss_D_B: 0.0020\n",
            "Epoch 44/70, Batch 23/25, Image: rainy_398.jpg, Loss_G: 13.7040, Loss_D_A: 0.0241, Loss_D_B: 0.0044\n",
            "Epoch 44/70, Batch 24/25, Image: rainy_1046.jpg, Loss_G: 8.7503, Loss_D_A: 0.0309, Loss_D_B: 0.0029\n",
            "Epoch 45/70, Batch 0/25, Image: rainy_2628.jpg, Loss_G: 9.6173, Loss_D_A: 0.0099, Loss_D_B: 0.0031\n",
            "Epoch 45/70, Batch 1/25, Image: rainy_1237.jpg, Loss_G: 7.6371, Loss_D_A: 0.0112, Loss_D_B: 0.0024\n",
            "Epoch 45/70, Batch 2/25, Image: rainy_2160.jpg, Loss_G: 8.4937, Loss_D_A: 0.0189, Loss_D_B: 0.0029\n",
            "Epoch 45/70, Batch 3/25, Image: rainy_3371.jpg, Loss_G: 9.1333, Loss_D_A: 0.0093, Loss_D_B: 0.0048\n",
            "Epoch 45/70, Batch 4/25, Image: rainy_1826.jpg, Loss_G: 7.1711, Loss_D_A: 0.0033, Loss_D_B: 0.0058\n",
            "Epoch 45/70, Batch 5/25, Image: rainy_1820 (1).jpg, Loss_G: 8.4779, Loss_D_A: 0.0020, Loss_D_B: 0.0042\n",
            "Epoch 45/70, Batch 6/25, Image: rainy_788.jpg, Loss_G: 8.9896, Loss_D_A: 0.0036, Loss_D_B: 0.0026\n",
            "Epoch 45/70, Batch 7/25, Image: rainy_475.jpg, Loss_G: 9.6881, Loss_D_A: 0.0034, Loss_D_B: 0.0039\n",
            "Epoch 45/70, Batch 8/25, Image: rainy_2724.jpg, Loss_G: 9.7524, Loss_D_A: 0.0018, Loss_D_B: 0.0019\n",
            "Epoch 45/70, Batch 9/25, Image: rainy_298.jpg, Loss_G: 8.9179, Loss_D_A: 0.0049, Loss_D_B: 0.0031\n",
            "Epoch 45/70, Batch 10/25, Image: rainy_1901.jpg, Loss_G: 10.4021, Loss_D_A: 0.0055, Loss_D_B: 0.0079\n",
            "Epoch 45/70, Batch 11/25, Image: rainy_1482.jpg, Loss_G: 10.2903, Loss_D_A: 0.0056, Loss_D_B: 0.0126\n",
            "Epoch 45/70, Batch 12/25, Image: rainy_205.jpg, Loss_G: 8.4870, Loss_D_A: 0.0052, Loss_D_B: 0.0058\n",
            "Epoch 45/70, Batch 13/25, Image: rainy_2859.jpg, Loss_G: 8.5542, Loss_D_A: 0.0144, Loss_D_B: 0.0038\n",
            "Epoch 45/70, Batch 14/25, Image: rainy_1931.jpg, Loss_G: 7.2882, Loss_D_A: 0.0273, Loss_D_B: 0.0078\n",
            "Epoch 45/70, Batch 15/25, Image: rainy_3136.jpg, Loss_G: 9.1108, Loss_D_A: 0.0230, Loss_D_B: 0.0104\n",
            "Epoch 45/70, Batch 16/25, Image: rainy_232.jpg, Loss_G: 8.9967, Loss_D_A: 0.0119, Loss_D_B: 0.0069\n",
            "Epoch 45/70, Batch 17/25, Image: rainy_3511.jpg, Loss_G: 8.6647, Loss_D_A: 0.0096, Loss_D_B: 0.0036\n",
            "Epoch 45/70, Batch 18/25, Image: rainy_3661.jpg, Loss_G: 8.2853, Loss_D_A: 0.0042, Loss_D_B: 0.0026\n",
            "Epoch 45/70, Batch 19/25, Image: rainy_1172.jpg, Loss_G: 8.9926, Loss_D_A: 0.0041, Loss_D_B: 0.0026\n",
            "Epoch 45/70, Batch 20/25, Image: rainy_2492.jpg, Loss_G: 8.2113, Loss_D_A: 0.0096, Loss_D_B: 0.0052\n",
            "Epoch 45/70, Batch 21/25, Image: rainy_1059.jpg, Loss_G: 9.6374, Loss_D_A: 0.0163, Loss_D_B: 0.0117\n",
            "Epoch 45/70, Batch 22/25, Image: rainy_912.jpg, Loss_G: 9.2274, Loss_D_A: 0.0095, Loss_D_B: 0.0142\n",
            "Epoch 45/70, Batch 23/25, Image: rainy_2977.jpg, Loss_G: 8.8246, Loss_D_A: 0.0019, Loss_D_B: 0.0155\n",
            "Epoch 45/70, Batch 24/25, Image: rainy_2955.jpg, Loss_G: 11.4485, Loss_D_A: 0.0060, Loss_D_B: 0.0188\n",
            "✅ Checkpoint saved at epoch 45\n",
            "Epoch 46/70, Batch 0/25, Image: rainy_3769.jpg, Loss_G: 15.7997, Loss_D_A: 0.0160, Loss_D_B: 0.0170\n",
            "Epoch 46/70, Batch 1/25, Image: rainy_3584.jpg, Loss_G: 9.5491, Loss_D_A: 0.0196, Loss_D_B: 0.0077\n",
            "Epoch 46/70, Batch 2/25, Image: rainy_1286.jpg, Loss_G: 11.8537, Loss_D_A: 0.0126, Loss_D_B: 0.0064\n",
            "Epoch 46/70, Batch 3/25, Image: rainy_1591.jpg, Loss_G: 9.9774, Loss_D_A: 0.0037, Loss_D_B: 0.0059\n",
            "Epoch 46/70, Batch 4/25, Image: rainy_2544.jpg, Loss_G: 8.9498, Loss_D_A: 0.0031, Loss_D_B: 0.0025\n",
            "Epoch 46/70, Batch 5/25, Image: rainy_993.jpg, Loss_G: 9.0126, Loss_D_A: 0.0041, Loss_D_B: 0.0043\n",
            "Epoch 46/70, Batch 6/25, Image: rainy_865.jpg, Loss_G: 8.1719, Loss_D_A: 0.0024, Loss_D_B: 0.0084\n",
            "Epoch 46/70, Batch 7/25, Image: rainy_3821.jpg, Loss_G: 8.0683, Loss_D_A: 0.0024, Loss_D_B: 0.0083\n",
            "Epoch 46/70, Batch 8/25, Image: rainy_481.jpg, Loss_G: 8.6993, Loss_D_A: 0.0031, Loss_D_B: 0.0038\n",
            "Epoch 46/70, Batch 9/25, Image: rainy_244.jpg, Loss_G: 8.9846, Loss_D_A: 0.0035, Loss_D_B: 0.0020\n",
            "Epoch 46/70, Batch 10/25, Image: rainy_1046.jpg, Loss_G: 8.4598, Loss_D_A: 0.0021, Loss_D_B: 0.0013\n",
            "Epoch 46/70, Batch 11/25, Image: rainy_3635.jpg, Loss_G: 9.8351, Loss_D_A: 0.0021, Loss_D_B: 0.0034\n",
            "Epoch 46/70, Batch 12/25, Image: rainy_795.jpg, Loss_G: 11.0266, Loss_D_A: 0.0024, Loss_D_B: 0.0048\n",
            "Epoch 46/70, Batch 13/25, Image: rainy_2747.jpg, Loss_G: 8.1479, Loss_D_A: 0.0048, Loss_D_B: 0.0033\n",
            "Epoch 46/70, Batch 14/25, Image: rainy_3951.jpg, Loss_G: 7.8218, Loss_D_A: 0.0036, Loss_D_B: 0.0046\n",
            "Epoch 46/70, Batch 15/25, Image: rainy_2474.jpg, Loss_G: 7.4008, Loss_D_A: 0.0019, Loss_D_B: 0.0086\n",
            "Epoch 46/70, Batch 16/25, Image: rainy_2453.jpg, Loss_G: 7.9834, Loss_D_A: 0.0022, Loss_D_B: 0.0085\n",
            "Epoch 46/70, Batch 17/25, Image: rainy_413.jpg, Loss_G: 9.1568, Loss_D_A: 0.0026, Loss_D_B: 0.0065\n",
            "Epoch 46/70, Batch 18/25, Image: rainy_79.jpg, Loss_G: 7.7720, Loss_D_A: 0.0020, Loss_D_B: 0.0034\n",
            "Epoch 46/70, Batch 19/25, Image: rainy_3090.jpg, Loss_G: 7.6152, Loss_D_A: 0.0048, Loss_D_B: 0.0028\n",
            "Epoch 46/70, Batch 20/25, Image: rainy_1656.jpg, Loss_G: 9.6669, Loss_D_A: 0.0076, Loss_D_B: 0.0040\n",
            "Epoch 46/70, Batch 21/25, Image: rainy_475.jpg, Loss_G: 7.0315, Loss_D_A: 0.0032, Loss_D_B: 0.0021\n",
            "Epoch 46/70, Batch 22/25, Image: rainy_1456.jpg, Loss_G: 10.8583, Loss_D_A: 0.0032, Loss_D_B: 0.0051\n",
            "Epoch 46/70, Batch 23/25, Image: rainy_1674.jpg, Loss_G: 12.2651, Loss_D_A: 0.0077, Loss_D_B: 0.0174\n",
            "Epoch 46/70, Batch 24/25, Image: rainy_3661.jpg, Loss_G: 10.2952, Loss_D_A: 0.0101, Loss_D_B: 0.0344\n",
            "Epoch 47/70, Batch 0/25, Image: rainy_1346.jpg, Loss_G: 11.3231, Loss_D_A: 0.0081, Loss_D_B: 0.0248\n",
            "Epoch 47/70, Batch 1/25, Image: rainy_3951.jpg, Loss_G: 11.3415, Loss_D_A: 0.0058, Loss_D_B: 0.0187\n",
            "Epoch 47/70, Batch 2/25, Image: rainy_104.jpg, Loss_G: 10.8185, Loss_D_A: 0.0044, Loss_D_B: 0.0196\n",
            "Epoch 47/70, Batch 3/25, Image: rainy_2973.jpg, Loss_G: 9.7491, Loss_D_A: 0.0022, Loss_D_B: 0.0139\n",
            "Epoch 47/70, Batch 4/25, Image: rainy_3336.jpg, Loss_G: 10.0728, Loss_D_A: 0.0033, Loss_D_B: 0.0105\n",
            "Epoch 47/70, Batch 5/25, Image: rainy_2004.jpg, Loss_G: 10.6780, Loss_D_A: 0.0070, Loss_D_B: 0.0126\n",
            "Epoch 47/70, Batch 6/25, Image: rainy_1046.jpg, Loss_G: 13.9652, Loss_D_A: 0.0055, Loss_D_B: 0.0219\n",
            "Epoch 47/70, Batch 7/25, Image: rainy_3164.jpg, Loss_G: 8.8815, Loss_D_A: 0.0083, Loss_D_B: 0.0228\n",
            "Epoch 47/70, Batch 8/25, Image: rainy_2968.jpg, Loss_G: 8.1663, Loss_D_A: 0.0107, Loss_D_B: 0.0133\n",
            "Epoch 47/70, Batch 9/25, Image: rainy_3529.jpg, Loss_G: 8.8065, Loss_D_A: 0.0072, Loss_D_B: 0.0063\n",
            "Epoch 47/70, Batch 10/25, Image: rainy_3710.jpg, Loss_G: 10.1980, Loss_D_A: 0.0056, Loss_D_B: 0.0070\n",
            "Epoch 47/70, Batch 11/25, Image: rainy_2620.jpg, Loss_G: 8.9265, Loss_D_A: 0.0050, Loss_D_B: 0.0053\n",
            "Epoch 47/70, Batch 12/25, Image: rainy_1901.jpg, Loss_G: 8.3451, Loss_D_A: 0.0112, Loss_D_B: 0.0047\n",
            "Epoch 47/70, Batch 13/25, Image: rainy_3078.jpg, Loss_G: 8.8454, Loss_D_A: 0.0108, Loss_D_B: 0.0042\n",
            "Epoch 47/70, Batch 14/25, Image: rainy_232.jpg, Loss_G: 10.4198, Loss_D_A: 0.0035, Loss_D_B: 0.0047\n",
            "Epoch 47/70, Batch 15/25, Image: rainy_3090.jpg, Loss_G: 11.0988, Loss_D_A: 0.0048, Loss_D_B: 0.0081\n",
            "Epoch 47/70, Batch 16/25, Image: rainy_2533.jpg, Loss_G: 9.9258, Loss_D_A: 0.0085, Loss_D_B: 0.0086\n",
            "Epoch 47/70, Batch 17/25, Image: rainy_1158.jpg, Loss_G: 7.7772, Loss_D_A: 0.0094, Loss_D_B: 0.0059\n",
            "Epoch 47/70, Batch 18/25, Image: rainy_1286.jpg, Loss_G: 8.6937, Loss_D_A: 0.0094, Loss_D_B: 0.0120\n",
            "Epoch 47/70, Batch 19/25, Image: rainy_3342.jpg, Loss_G: 10.0845, Loss_D_A: 0.0072, Loss_D_B: 0.0156\n",
            "Epoch 47/70, Batch 20/25, Image: rainy_2198.jpg, Loss_G: 8.7233, Loss_D_A: 0.0056, Loss_D_B: 0.0141\n",
            "Epoch 47/70, Batch 21/25, Image: rainy_267.jpg, Loss_G: 8.9742, Loss_D_A: 0.0021, Loss_D_B: 0.0096\n",
            "Epoch 47/70, Batch 22/25, Image: rainy_868.jpg, Loss_G: 8.8491, Loss_D_A: 0.0047, Loss_D_B: 0.0034\n",
            "Epoch 47/70, Batch 23/25, Image: rainy_1674.jpg, Loss_G: 9.1614, Loss_D_A: 0.0122, Loss_D_B: 0.0019\n",
            "Epoch 47/70, Batch 24/25, Image: rainy_2859.jpg, Loss_G: 9.3587, Loss_D_A: 0.0158, Loss_D_B: 0.0041\n",
            "Epoch 48/70, Batch 0/25, Image: rainy_1733.jpg, Loss_G: 9.1773, Loss_D_A: 0.0144, Loss_D_B: 0.0031\n",
            "Epoch 48/70, Batch 1/25, Image: rainy_841.jpg, Loss_G: 9.0320, Loss_D_A: 0.0105, Loss_D_B: 0.0041\n",
            "Epoch 48/70, Batch 2/25, Image: rainy_536.jpg, Loss_G: 10.3511, Loss_D_A: 0.0085, Loss_D_B: 0.0043\n",
            "Epoch 48/70, Batch 3/25, Image: rainy_3010.jpg, Loss_G: 10.5520, Loss_D_A: 0.0100, Loss_D_B: 0.0023\n",
            "Epoch 48/70, Batch 4/25, Image: rainy_1769.jpg, Loss_G: 8.5915, Loss_D_A: 0.0054, Loss_D_B: 0.0019\n",
            "Epoch 48/70, Batch 5/25, Image: rainy_446.jpg, Loss_G: 10.0053, Loss_D_A: 0.0086, Loss_D_B: 0.0036\n",
            "Epoch 48/70, Batch 6/25, Image: rainy_1957.jpg, Loss_G: 9.0596, Loss_D_A: 0.0067, Loss_D_B: 0.0044\n",
            "Epoch 48/70, Batch 7/25, Image: rainy_2004.jpg, Loss_G: 9.1329, Loss_D_A: 0.0045, Loss_D_B: 0.0045\n",
            "Epoch 48/70, Batch 8/25, Image: rainy_1599.jpg, Loss_G: 13.1206, Loss_D_A: 0.0091, Loss_D_B: 0.0054\n",
            "Epoch 48/70, Batch 9/25, Image: rainy_3020.jpg, Loss_G: 8.3052, Loss_D_A: 0.0058, Loss_D_B: 0.0042\n",
            "Epoch 48/70, Batch 10/25, Image: rainy_3156.jpg, Loss_G: 9.2484, Loss_D_A: 0.0026, Loss_D_B: 0.0024\n",
            "Epoch 48/70, Batch 11/25, Image: rainy_849.jpg, Loss_G: 10.7495, Loss_D_A: 0.0018, Loss_D_B: 0.0024\n",
            "Epoch 48/70, Batch 12/25, Image: rainy_267.jpg, Loss_G: 9.2554, Loss_D_A: 0.0024, Loss_D_B: 0.0025\n",
            "Epoch 48/70, Batch 13/25, Image: rainy_104.jpg, Loss_G: 8.6524, Loss_D_A: 0.0033, Loss_D_B: 0.0020\n",
            "Epoch 48/70, Batch 14/25, Image: rainy_1876.jpg, Loss_G: 10.3182, Loss_D_A: 0.0015, Loss_D_B: 0.0028\n",
            "Epoch 48/70, Batch 15/25, Image: rainy_3060.jpg, Loss_G: 8.6565, Loss_D_A: 0.0029, Loss_D_B: 0.0041\n",
            "Epoch 48/70, Batch 16/25, Image: rainy_3795.jpg, Loss_G: 9.9989, Loss_D_A: 0.0048, Loss_D_B: 0.0036\n",
            "Epoch 48/70, Batch 17/25, Image: rainy_3573.jpg, Loss_G: 9.9071, Loss_D_A: 0.0033, Loss_D_B: 0.0022\n",
            "Epoch 48/70, Batch 18/25, Image: rainy_205.jpg, Loss_G: 8.6338, Loss_D_A: 0.0017, Loss_D_B: 0.0012\n",
            "Epoch 48/70, Batch 19/25, Image: rainy_3164.jpg, Loss_G: 7.4932, Loss_D_A: 0.0022, Loss_D_B: 0.0016\n",
            "Epoch 48/70, Batch 20/25, Image: rainy_3635.jpg, Loss_G: 8.8942, Loss_D_A: 0.0022, Loss_D_B: 0.0036\n",
            "Epoch 48/70, Batch 21/25, Image: rainy_558.jpg, Loss_G: 8.6863, Loss_D_A: 0.0021, Loss_D_B: 0.0032\n",
            "Epoch 48/70, Batch 22/25, Image: rainy_2977.jpg, Loss_G: 8.3241, Loss_D_A: 0.0071, Loss_D_B: 0.0023\n",
            "Epoch 48/70, Batch 23/25, Image: rainy_2257.jpg, Loss_G: 8.7400, Loss_D_A: 0.0073, Loss_D_B: 0.0047\n",
            "Epoch 48/70, Batch 24/25, Image: rainy_748.jpg, Loss_G: 7.7730, Loss_D_A: 0.0041, Loss_D_B: 0.0036\n",
            "Epoch 49/70, Batch 0/25, Image: rainy_3813.jpg, Loss_G: 8.6024, Loss_D_A: 0.0042, Loss_D_B: 0.0016\n",
            "Epoch 49/70, Batch 1/25, Image: rainy_859.jpg, Loss_G: 8.1097, Loss_D_A: 0.0113, Loss_D_B: 0.0015\n",
            "Epoch 49/70, Batch 2/25, Image: rainy_298.jpg, Loss_G: 8.1092, Loss_D_A: 0.0153, Loss_D_B: 0.0014\n",
            "Epoch 49/70, Batch 3/25, Image: rainy_3445.jpg, Loss_G: 8.5249, Loss_D_A: 0.0070, Loss_D_B: 0.0014\n",
            "Epoch 49/70, Batch 4/25, Image: rainy_1091.jpg, Loss_G: 7.4754, Loss_D_A: 0.0021, Loss_D_B: 0.0011\n",
            "Epoch 49/70, Batch 5/25, Image: rainy_750.jpg, Loss_G: 8.6041, Loss_D_A: 0.0016, Loss_D_B: 0.0015\n",
            "Epoch 49/70, Batch 6/25, Image: rainy_2513.jpg, Loss_G: 9.5158, Loss_D_A: 0.0036, Loss_D_B: 0.0015\n",
            "Epoch 49/70, Batch 7/25, Image: rainy_491.jpg, Loss_G: 10.6427, Loss_D_A: 0.0077, Loss_D_B: 0.0015\n",
            "Epoch 49/70, Batch 8/25, Image: rainy_1381.jpg, Loss_G: 9.4099, Loss_D_A: 0.0065, Loss_D_B: 0.0012\n",
            "Epoch 49/70, Batch 9/25, Image: rainy_446.jpg, Loss_G: 8.3112, Loss_D_A: 0.0028, Loss_D_B: 0.0014\n",
            "Epoch 49/70, Batch 10/25, Image: rainy_184.jpg, Loss_G: 7.6923, Loss_D_A: 0.0045, Loss_D_B: 0.0020\n",
            "Epoch 49/70, Batch 11/25, Image: rainy_814.jpg, Loss_G: 8.7750, Loss_D_A: 0.0068, Loss_D_B: 0.0012\n",
            "Epoch 49/70, Batch 12/25, Image: rainy_335.jpg, Loss_G: 8.8142, Loss_D_A: 0.0102, Loss_D_B: 0.0023\n",
            "Epoch 49/70, Batch 13/25, Image: rainy_1555.jpg, Loss_G: 9.9264, Loss_D_A: 0.0025, Loss_D_B: 0.0040\n",
            "Epoch 49/70, Batch 14/25, Image: rainy_752.jpg, Loss_G: 10.4020, Loss_D_A: 0.0060, Loss_D_B: 0.0038\n",
            "Epoch 49/70, Batch 15/25, Image: rainy_2259.jpg, Loss_G: 8.5279, Loss_D_A: 0.0193, Loss_D_B: 0.0036\n",
            "Epoch 49/70, Batch 16/25, Image: rainy_2492.jpg, Loss_G: 8.6222, Loss_D_A: 0.0184, Loss_D_B: 0.0057\n",
            "Epoch 49/70, Batch 17/25, Image: rainy_53.jpg, Loss_G: 9.0627, Loss_D_A: 0.0054, Loss_D_B: 0.0048\n",
            "Epoch 49/70, Batch 18/25, Image: rainy_2453.jpg, Loss_G: 8.2656, Loss_D_A: 0.0020, Loss_D_B: 0.0050\n",
            "Epoch 49/70, Batch 19/25, Image: rainy_2570.jpg, Loss_G: 9.3323, Loss_D_A: 0.0029, Loss_D_B: 0.0048\n",
            "Epoch 49/70, Batch 20/25, Image: rainy_413.jpg, Loss_G: 9.0703, Loss_D_A: 0.0044, Loss_D_B: 0.0048\n",
            "Epoch 49/70, Batch 21/25, Image: rainy_913.jpg, Loss_G: 11.0357, Loss_D_A: 0.0059, Loss_D_B: 0.0033\n",
            "Epoch 49/70, Batch 22/25, Image: rainy_2346.jpg, Loss_G: 8.8073, Loss_D_A: 0.0081, Loss_D_B: 0.0038\n",
            "Epoch 49/70, Batch 23/25, Image: rainy_3385.jpg, Loss_G: 8.7528, Loss_D_A: 0.0082, Loss_D_B: 0.0043\n",
            "Epoch 49/70, Batch 24/25, Image: rainy_3193.jpg, Loss_G: 8.7822, Loss_D_A: 0.0040, Loss_D_B: 0.0032\n",
            "Epoch 50/70, Batch 0/25, Image: rainy_2257.jpg, Loss_G: 9.5811, Loss_D_A: 0.0025, Loss_D_B: 0.0018\n",
            "Epoch 50/70, Batch 1/25, Image: rainy_3428.jpg, Loss_G: 10.5834, Loss_D_A: 0.0024, Loss_D_B: 0.0026\n",
            "Epoch 50/70, Batch 2/25, Image: rainy_2195.jpg, Loss_G: 9.2040, Loss_D_A: 0.0114, Loss_D_B: 0.0036\n",
            "Epoch 50/70, Batch 3/25, Image: rainy_3164.jpg, Loss_G: 8.3281, Loss_D_A: 0.0229, Loss_D_B: 0.0074\n",
            "Epoch 50/70, Batch 4/25, Image: rainy_1046.jpg, Loss_G: 8.2404, Loss_D_A: 0.0153, Loss_D_B: 0.0062\n",
            "Epoch 50/70, Batch 5/25, Image: rainy_849.jpg, Loss_G: 8.9981, Loss_D_A: 0.0061, Loss_D_B: 0.0061\n",
            "Epoch 50/70, Batch 6/25, Image: rainy_2620.jpg, Loss_G: 9.8439, Loss_D_A: 0.0057, Loss_D_B: 0.0048\n",
            "Epoch 50/70, Batch 7/25, Image: rainy_199.jpg, Loss_G: 12.1940, Loss_D_A: 0.0074, Loss_D_B: 0.0035\n",
            "Epoch 50/70, Batch 8/25, Image: rainy_2724.jpg, Loss_G: 10.5148, Loss_D_A: 0.0077, Loss_D_B: 0.0024\n",
            "Epoch 50/70, Batch 9/25, Image: rainy_2275.jpg, Loss_G: 9.5072, Loss_D_A: 0.0044, Loss_D_B: 0.0015\n",
            "Epoch 50/70, Batch 10/25, Image: rainy_3756.jpg, Loss_G: 9.5557, Loss_D_A: 0.0018, Loss_D_B: 0.0023\n",
            "Epoch 50/70, Batch 11/25, Image: rainy_2474.jpg, Loss_G: 8.1747, Loss_D_A: 0.0034, Loss_D_B: 0.0040\n",
            "Epoch 50/70, Batch 12/25, Image: rainy_3573.jpg, Loss_G: 10.3481, Loss_D_A: 0.0061, Loss_D_B: 0.0080\n",
            "Epoch 50/70, Batch 13/25, Image: rainy_2973.jpg, Loss_G: 8.7298, Loss_D_A: 0.0032, Loss_D_B: 0.0115\n",
            "Epoch 50/70, Batch 14/25, Image: rainy_2977.jpg, Loss_G: 8.9562, Loss_D_A: 0.0066, Loss_D_B: 0.0084\n",
            "Epoch 50/70, Batch 15/25, Image: rainy_298.jpg, Loss_G: 9.2721, Loss_D_A: 0.0090, Loss_D_B: 0.0029\n",
            "Epoch 50/70, Batch 16/25, Image: rainy_2619.jpg, Loss_G: 7.9139, Loss_D_A: 0.0067, Loss_D_B: 0.0030\n",
            "Epoch 50/70, Batch 17/25, Image: rainy_2060.jpg, Loss_G: 9.1223, Loss_D_A: 0.0044, Loss_D_B: 0.0045\n",
            "Epoch 50/70, Batch 18/25, Image: rainy_104.jpg, Loss_G: 10.8675, Loss_D_A: 0.0055, Loss_D_B: 0.0031\n",
            "Epoch 50/70, Batch 19/25, Image: rainy_2859.jpg, Loss_G: 8.6216, Loss_D_A: 0.0024, Loss_D_B: 0.0028\n",
            "Epoch 50/70, Batch 20/25, Image: rainy_859.jpg, Loss_G: 9.0996, Loss_D_A: 0.0031, Loss_D_B: 0.0025\n",
            "Epoch 50/70, Batch 21/25, Image: rainy_788.jpg, Loss_G: 8.6383, Loss_D_A: 0.0047, Loss_D_B: 0.0023\n",
            "Epoch 50/70, Batch 22/25, Image: rainy_2838.jpg, Loss_G: 9.2113, Loss_D_A: 0.0018, Loss_D_B: 0.0019\n",
            "Epoch 50/70, Batch 23/25, Image: rainy_3398.jpg, Loss_G: 8.4547, Loss_D_A: 0.0068, Loss_D_B: 0.0023\n",
            "Epoch 50/70, Batch 24/25, Image: rainy_3355.jpg, Loss_G: 8.8656, Loss_D_A: 0.0079, Loss_D_B: 0.0085\n",
            "✅ Checkpoint saved at epoch 50\n",
            "Epoch 51/70, Batch 0/25, Image: rainy_3951.jpg, Loss_G: 8.3678, Loss_D_A: 0.0042, Loss_D_B: 0.0087\n",
            "Epoch 51/70, Batch 1/25, Image: rainy_3511.jpg, Loss_G: 8.5190, Loss_D_A: 0.0050, Loss_D_B: 0.0102\n",
            "Epoch 51/70, Batch 2/25, Image: rainy_1083.jpg, Loss_G: 8.6690, Loss_D_A: 0.0033, Loss_D_B: 0.0058\n",
            "Epoch 51/70, Batch 3/25, Image: rainy_2453.jpg, Loss_G: 10.6906, Loss_D_A: 0.0050, Loss_D_B: 0.0065\n",
            "Epoch 51/70, Batch 4/25, Image: rainy_926.jpg, Loss_G: 8.0471, Loss_D_A: 0.0080, Loss_D_B: 0.0111\n",
            "Epoch 51/70, Batch 5/25, Image: rainy_2985.jpg, Loss_G: 8.7575, Loss_D_A: 0.0151, Loss_D_B: 0.0166\n",
            "Epoch 51/70, Batch 6/25, Image: rainy_1080.jpg, Loss_G: 8.7745, Loss_D_A: 0.0214, Loss_D_B: 0.0129\n",
            "Epoch 51/70, Batch 7/25, Image: rainy_3661.jpg, Loss_G: 8.2341, Loss_D_A: 0.0094, Loss_D_B: 0.0028\n",
            "Epoch 51/70, Batch 8/25, Image: rainy_2877.jpg, Loss_G: 8.5588, Loss_D_A: 0.0041, Loss_D_B: 0.0038\n",
            "Epoch 51/70, Batch 9/25, Image: rainy_912.jpg, Loss_G: 9.0220, Loss_D_A: 0.0105, Loss_D_B: 0.0051\n",
            "Epoch 51/70, Batch 10/25, Image: rainy_988.jpg, Loss_G: 10.6704, Loss_D_A: 0.0068, Loss_D_B: 0.0022\n",
            "Epoch 51/70, Batch 11/25, Image: rainy_868.jpg, Loss_G: 9.0005, Loss_D_A: 0.0018, Loss_D_B: 0.0018\n",
            "Epoch 51/70, Batch 12/25, Image: rainy_1769.jpg, Loss_G: 8.9896, Loss_D_A: 0.0054, Loss_D_B: 0.0044\n",
            "Epoch 51/70, Batch 13/25, Image: rainy_3342.jpg, Loss_G: 9.1766, Loss_D_A: 0.0040, Loss_D_B: 0.0077\n",
            "Epoch 51/70, Batch 14/25, Image: rainy_1434.jpg, Loss_G: 9.2893, Loss_D_A: 0.0019, Loss_D_B: 0.0147\n",
            "Epoch 51/70, Batch 15/25, Image: rainy_3014.jpg, Loss_G: 8.3728, Loss_D_A: 0.0039, Loss_D_B: 0.0231\n",
            "Epoch 51/70, Batch 16/25, Image: rainy_232.jpg, Loss_G: 8.0983, Loss_D_A: 0.0030, Loss_D_B: 0.0240\n",
            "Epoch 51/70, Batch 17/25, Image: rainy_1820 (1).jpg, Loss_G: 7.8917, Loss_D_A: 0.0034, Loss_D_B: 0.0130\n",
            "Epoch 51/70, Batch 18/25, Image: rainy_398.jpg, Loss_G: 8.2087, Loss_D_A: 0.0037, Loss_D_B: 0.0068\n",
            "Epoch 51/70, Batch 19/25, Image: rainy_1662.jpg, Loss_G: 9.2620, Loss_D_A: 0.0033, Loss_D_B: 0.0088\n",
            "Epoch 51/70, Batch 20/25, Image: rainy_2779.jpg, Loss_G: 8.3308, Loss_D_A: 0.0018, Loss_D_B: 0.0058\n",
            "Epoch 51/70, Batch 21/25, Image: rainy_53.jpg, Loss_G: 7.4233, Loss_D_A: 0.0021, Loss_D_B: 0.0029\n",
            "Epoch 51/70, Batch 22/25, Image: rainy_1555.jpg, Loss_G: 7.5921, Loss_D_A: 0.0028, Loss_D_B: 0.0037\n",
            "Epoch 51/70, Batch 23/25, Image: rainy_491.jpg, Loss_G: 8.5447, Loss_D_A: 0.0012, Loss_D_B: 0.0028\n",
            "Epoch 51/70, Batch 24/25, Image: rainy_1966.jpg, Loss_G: 8.6623, Loss_D_A: 0.0037, Loss_D_B: 0.0026\n",
            "Epoch 52/70, Batch 0/25, Image: rainy_1599.jpg, Loss_G: 8.1418, Loss_D_A: 0.0045, Loss_D_B: 0.0017\n",
            "Epoch 52/70, Batch 1/25, Image: rainy_3445.jpg, Loss_G: 9.4501, Loss_D_A: 0.0072, Loss_D_B: 0.0025\n",
            "Epoch 52/70, Batch 2/25, Image: rainy_1167.jpg, Loss_G: 8.3967, Loss_D_A: 0.0036, Loss_D_B: 0.0031\n",
            "Epoch 52/70, Batch 3/25, Image: rainy_2968.jpg, Loss_G: 8.2795, Loss_D_A: 0.0021, Loss_D_B: 0.0031\n",
            "Epoch 52/70, Batch 4/25, Image: rainy_447.jpg, Loss_G: 8.2388, Loss_D_A: 0.0029, Loss_D_B: 0.0022\n",
            "Epoch 52/70, Batch 5/25, Image: rainy_2195.jpg, Loss_G: 8.4007, Loss_D_A: 0.0045, Loss_D_B: 0.0039\n",
            "Epoch 52/70, Batch 6/25, Image: rainy_232.jpg, Loss_G: 7.6293, Loss_D_A: 0.0023, Loss_D_B: 0.0050\n",
            "Epoch 52/70, Batch 7/25, Image: rainy_1456.jpg, Loss_G: 8.1706, Loss_D_A: 0.0014, Loss_D_B: 0.0065\n",
            "Epoch 52/70, Batch 8/25, Image: rainy_1769.jpg, Loss_G: 7.5887, Loss_D_A: 0.0022, Loss_D_B: 0.0047\n",
            "Epoch 52/70, Batch 9/25, Image: rainy_1662.jpg, Loss_G: 9.1159, Loss_D_A: 0.0058, Loss_D_B: 0.0016\n",
            "Epoch 52/70, Batch 10/25, Image: rainy_913.jpg, Loss_G: 7.9461, Loss_D_A: 0.0199, Loss_D_B: 0.0031\n",
            "Epoch 52/70, Batch 11/25, Image: rainy_170.jpg, Loss_G: 8.8534, Loss_D_A: 0.0401, Loss_D_B: 0.0029\n",
            "Epoch 52/70, Batch 12/25, Image: rainy_2060.jpg, Loss_G: 7.7208, Loss_D_A: 0.0407, Loss_D_B: 0.0036\n",
            "Epoch 52/70, Batch 13/25, Image: rainy_3529.jpg, Loss_G: 9.1254, Loss_D_A: 0.0207, Loss_D_B: 0.0083\n",
            "Epoch 52/70, Batch 14/25, Image: rainy_3014.jpg, Loss_G: 8.3708, Loss_D_A: 0.0064, Loss_D_B: 0.0131\n",
            "Epoch 52/70, Batch 15/25, Image: rainy_752.jpg, Loss_G: 7.6236, Loss_D_A: 0.0049, Loss_D_B: 0.0178\n",
            "Epoch 52/70, Batch 16/25, Image: rainy_53.jpg, Loss_G: 8.0678, Loss_D_A: 0.0031, Loss_D_B: 0.0188\n",
            "Epoch 52/70, Batch 17/25, Image: rainy_3019.jpg, Loss_G: 7.0629, Loss_D_A: 0.0033, Loss_D_B: 0.0154\n",
            "Epoch 52/70, Batch 18/25, Image: rainy_1434.jpg, Loss_G: 8.4111, Loss_D_A: 0.0042, Loss_D_B: 0.0130\n",
            "Epoch 52/70, Batch 19/25, Image: rainy_2492.jpg, Loss_G: 7.5759, Loss_D_A: 0.0063, Loss_D_B: 0.0122\n",
            "Epoch 52/70, Batch 20/25, Image: rainy_3268.jpg, Loss_G: 8.2735, Loss_D_A: 0.0097, Loss_D_B: 0.0103\n",
            "Epoch 52/70, Batch 21/25, Image: rainy_1083.jpg, Loss_G: 7.8301, Loss_D_A: 0.0140, Loss_D_B: 0.0055\n",
            "Epoch 52/70, Batch 22/25, Image: rainy_2724.jpg, Loss_G: 7.9823, Loss_D_A: 0.0145, Loss_D_B: 0.0017\n",
            "Epoch 52/70, Batch 23/25, Image: rainy_335.jpg, Loss_G: 7.7901, Loss_D_A: 0.0095, Loss_D_B: 0.0033\n",
            "Epoch 52/70, Batch 24/25, Image: rainy_1742.jpg, Loss_G: 9.9297, Loss_D_A: 0.0151, Loss_D_B: 0.0062\n",
            "Epoch 53/70, Batch 0/25, Image: rainy_3635.jpg, Loss_G: 9.3456, Loss_D_A: 0.0371, Loss_D_B: 0.0057\n",
            "Epoch 53/70, Batch 1/25, Image: rainy_3821.jpg, Loss_G: 9.0950, Loss_D_A: 0.0382, Loss_D_B: 0.0057\n",
            "Epoch 53/70, Batch 2/25, Image: rainy_1167.jpg, Loss_G: 9.4564, Loss_D_A: 0.0239, Loss_D_B: 0.0069\n",
            "Epoch 53/70, Batch 3/25, Image: rainy_1769.jpg, Loss_G: 8.1075, Loss_D_A: 0.0094, Loss_D_B: 0.0081\n",
            "Epoch 53/70, Batch 4/25, Image: rainy_2714.jpg, Loss_G: 10.4480, Loss_D_A: 0.0033, Loss_D_B: 0.0073\n",
            "Epoch 53/70, Batch 5/25, Image: rainy_446.jpg, Loss_G: 7.7288, Loss_D_A: 0.0042, Loss_D_B: 0.0063\n",
            "Epoch 53/70, Batch 6/25, Image: rainy_1555.jpg, Loss_G: 9.7642, Loss_D_A: 0.0080, Loss_D_B: 0.0038\n",
            "Epoch 53/70, Batch 7/25, Image: rainy_1346.jpg, Loss_G: 7.6882, Loss_D_A: 0.0112, Loss_D_B: 0.0038\n",
            "Epoch 53/70, Batch 8/25, Image: rainy_3710.jpg, Loss_G: 7.7774, Loss_D_A: 0.0099, Loss_D_B: 0.0054\n",
            "Epoch 53/70, Batch 9/25, Image: rainy_1771.jpg, Loss_G: 8.4278, Loss_D_A: 0.0090, Loss_D_B: 0.0041\n",
            "Epoch 53/70, Batch 10/25, Image: rainy_3020.jpg, Loss_G: 10.2833, Loss_D_A: 0.0051, Loss_D_B: 0.0033\n",
            "Epoch 53/70, Batch 11/25, Image: rainy_2533.jpg, Loss_G: 7.9048, Loss_D_A: 0.0052, Loss_D_B: 0.0019\n",
            "Epoch 53/70, Batch 12/25, Image: rainy_841.jpg, Loss_G: 8.6121, Loss_D_A: 0.0051, Loss_D_B: 0.0017\n",
            "Epoch 53/70, Batch 13/25, Image: rainy_2747.jpg, Loss_G: 7.2189, Loss_D_A: 0.0024, Loss_D_B: 0.0018\n",
            "Epoch 53/70, Batch 14/25, Image: rainy_3756.jpg, Loss_G: 8.2936, Loss_D_A: 0.0017, Loss_D_B: 0.0016\n",
            "Epoch 53/70, Batch 15/25, Image: rainy_2691.jpg, Loss_G: 8.5993, Loss_D_A: 0.0025, Loss_D_B: 0.0032\n",
            "Epoch 53/70, Batch 16/25, Image: rainy_1656.jpg, Loss_G: 8.5730, Loss_D_A: 0.0031, Loss_D_B: 0.0079\n",
            "Epoch 53/70, Batch 17/25, Image: rainy_1690.jpg, Loss_G: 7.0747, Loss_D_A: 0.0015, Loss_D_B: 0.0093\n",
            "Epoch 53/70, Batch 18/25, Image: rainy_119.jpg, Loss_G: 8.8083, Loss_D_A: 0.0039, Loss_D_B: 0.0077\n",
            "Epoch 53/70, Batch 19/25, Image: rainy_1568.jpg, Loss_G: 10.8344, Loss_D_A: 0.0047, Loss_D_B: 0.0028\n",
            "Epoch 53/70, Batch 20/25, Image: rainy_3193.jpg, Loss_G: 7.6539, Loss_D_A: 0.0040, Loss_D_B: 0.0021\n",
            "Epoch 53/70, Batch 21/25, Image: rainy_518.jpg, Loss_G: 8.5939, Loss_D_A: 0.0079, Loss_D_B: 0.0061\n",
            "Epoch 53/70, Batch 22/25, Image: rainy_3371.jpg, Loss_G: 7.6512, Loss_D_A: 0.0068, Loss_D_B: 0.0088\n",
            "Epoch 53/70, Batch 23/25, Image: rainy_3661.jpg, Loss_G: 8.0950, Loss_D_A: 0.0028, Loss_D_B: 0.0072\n",
            "Epoch 53/70, Batch 24/25, Image: rainy_2977.jpg, Loss_G: 10.8452, Loss_D_A: 0.0059, Loss_D_B: 0.0041\n",
            "Epoch 54/70, Batch 0/25, Image: rainy_814.jpg, Loss_G: 7.2858, Loss_D_A: 0.0047, Loss_D_B: 0.0050\n",
            "Epoch 54/70, Batch 1/25, Image: rainy_3337.jpg, Loss_G: 7.7930, Loss_D_A: 0.0027, Loss_D_B: 0.0066\n",
            "Epoch 54/70, Batch 2/25, Image: rainy_1482.jpg, Loss_G: 8.9354, Loss_D_A: 0.0022, Loss_D_B: 0.0051\n",
            "Epoch 54/70, Batch 3/25, Image: rainy_826.jpg, Loss_G: 7.3056, Loss_D_A: 0.0035, Loss_D_B: 0.0030\n",
            "Epoch 54/70, Batch 4/25, Image: rainy_2629.jpg, Loss_G: 8.8054, Loss_D_A: 0.0028, Loss_D_B: 0.0013\n",
            "Epoch 54/70, Batch 5/25, Image: rainy_3511.jpg, Loss_G: 7.4278, Loss_D_A: 0.0012, Loss_D_B: 0.0027\n",
            "Epoch 54/70, Batch 6/25, Image: rainy_773.jpg, Loss_G: 8.7102, Loss_D_A: 0.0033, Loss_D_B: 0.0051\n",
            "Epoch 54/70, Batch 7/25, Image: rainy_2570.jpg, Loss_G: 8.2454, Loss_D_A: 0.0044, Loss_D_B: 0.0057\n",
            "Epoch 54/70, Batch 8/25, Image: rainy_2724.jpg, Loss_G: 9.0852, Loss_D_A: 0.0037, Loss_D_B: 0.0038\n",
            "Epoch 54/70, Batch 9/25, Image: rainy_1434.jpg, Loss_G: 10.3342, Loss_D_A: 0.0037, Loss_D_B: 0.0024\n",
            "Epoch 54/70, Batch 10/25, Image: rainy_3078.jpg, Loss_G: 10.0468, Loss_D_A: 0.0065, Loss_D_B: 0.0078\n",
            "Epoch 54/70, Batch 11/25, Image: rainy_3661.jpg, Loss_G: 7.9290, Loss_D_A: 0.0051, Loss_D_B: 0.0075\n",
            "Epoch 54/70, Batch 12/25, Image: rainy_1769.jpg, Loss_G: 9.1558, Loss_D_A: 0.0028, Loss_D_B: 0.0082\n",
            "Epoch 54/70, Batch 13/25, Image: rainy_2838.jpg, Loss_G: 8.9029, Loss_D_A: 0.0051, Loss_D_B: 0.0084\n",
            "Epoch 54/70, Batch 14/25, Image: rainy_2533.jpg, Loss_G: 9.6082, Loss_D_A: 0.0083, Loss_D_B: 0.0054\n",
            "Epoch 54/70, Batch 15/25, Image: rainy_3635.jpg, Loss_G: 13.3760, Loss_D_A: 0.0036, Loss_D_B: 0.0021\n",
            "Epoch 54/70, Batch 16/25, Image: rainy_382.jpg, Loss_G: 9.1226, Loss_D_A: 0.0025, Loss_D_B: 0.0023\n",
            "Epoch 54/70, Batch 17/25, Image: rainy_923.jpg, Loss_G: 8.4115, Loss_D_A: 0.0038, Loss_D_B: 0.0047\n",
            "Epoch 54/70, Batch 18/25, Image: rainy_518.jpg, Loss_G: 8.4676, Loss_D_A: 0.0029, Loss_D_B: 0.0034\n",
            "Epoch 54/70, Batch 19/25, Image: rainy_2060.jpg, Loss_G: 7.7587, Loss_D_A: 0.0043, Loss_D_B: 0.0021\n",
            "Epoch 54/70, Batch 20/25, Image: rainy_1237.jpg, Loss_G: 8.0409, Loss_D_A: 0.0036, Loss_D_B: 0.0018\n",
            "Epoch 54/70, Batch 21/25, Image: rainy_1899.jpg, Loss_G: 8.0939, Loss_D_A: 0.0017, Loss_D_B: 0.0026\n",
            "Epoch 54/70, Batch 22/25, Image: rainy_79.jpg, Loss_G: 8.0876, Loss_D_A: 0.0038, Loss_D_B: 0.0034\n",
            "Epoch 54/70, Batch 23/25, Image: rainy_1059.jpg, Loss_G: 9.4680, Loss_D_A: 0.0054, Loss_D_B: 0.0038\n",
            "Epoch 54/70, Batch 24/25, Image: rainy_429.jpg, Loss_G: 8.0739, Loss_D_A: 0.0066, Loss_D_B: 0.0026\n",
            "Epoch 55/70, Batch 0/25, Image: rainy_3078.jpg, Loss_G: 9.0883, Loss_D_A: 0.0049, Loss_D_B: 0.0019\n",
            "Epoch 55/70, Batch 1/25, Image: rainy_1966.jpg, Loss_G: 10.9310, Loss_D_A: 0.0019, Loss_D_B: 0.0019\n",
            "Epoch 55/70, Batch 2/25, Image: rainy_3193.jpg, Loss_G: 9.5388, Loss_D_A: 0.0040, Loss_D_B: 0.0032\n",
            "Epoch 55/70, Batch 3/25, Image: rainy_1508.jpg, Loss_G: 9.1828, Loss_D_A: 0.0085, Loss_D_B: 0.0130\n",
            "Epoch 55/70, Batch 4/25, Image: rainy_537.jpg, Loss_G: 9.1592, Loss_D_A: 0.0125, Loss_D_B: 0.0265\n",
            "Epoch 55/70, Batch 5/25, Image: rainy_1185.jpg, Loss_G: 10.3069, Loss_D_A: 0.0072, Loss_D_B: 0.0387\n",
            "Epoch 55/70, Batch 6/25, Image: rainy_2787.jpg, Loss_G: 7.8731, Loss_D_A: 0.0049, Loss_D_B: 0.0303\n",
            "Epoch 55/70, Batch 7/25, Image: rainy_3090.jpg, Loss_G: 13.3541, Loss_D_A: 0.0039, Loss_D_B: 0.0146\n",
            "Epoch 55/70, Batch 8/25, Image: rainy_1269.jpg, Loss_G: 10.3261, Loss_D_A: 0.0055, Loss_D_B: 0.0099\n",
            "Epoch 55/70, Batch 9/25, Image: rainy_1286.jpg, Loss_G: 11.5010, Loss_D_A: 0.0118, Loss_D_B: 0.0051\n",
            "Epoch 55/70, Batch 10/25, Image: rainy_2570.jpg, Loss_G: 10.5448, Loss_D_A: 0.0155, Loss_D_B: 0.0053\n",
            "Epoch 55/70, Batch 11/25, Image: rainy_2859.jpg, Loss_G: 8.5037, Loss_D_A: 0.0078, Loss_D_B: 0.0110\n",
            "Epoch 55/70, Batch 12/25, Image: rainy_1662.jpg, Loss_G: 8.9794, Loss_D_A: 0.0055, Loss_D_B: 0.0092\n",
            "Epoch 55/70, Batch 13/25, Image: rainy_3164.jpg, Loss_G: 7.4254, Loss_D_A: 0.0109, Loss_D_B: 0.0044\n",
            "Epoch 55/70, Batch 14/25, Image: rainy_170.jpg, Loss_G: 8.6433, Loss_D_A: 0.0057, Loss_D_B: 0.0049\n",
            "Epoch 55/70, Batch 15/25, Image: rainy_1482.jpg, Loss_G: 10.3094, Loss_D_A: 0.0094, Loss_D_B: 0.0168\n",
            "Epoch 55/70, Batch 16/25, Image: rainy_1568.jpg, Loss_G: 8.4762, Loss_D_A: 0.0292, Loss_D_B: 0.0242\n",
            "Epoch 55/70, Batch 17/25, Image: rainy_1690.jpg, Loss_G: 11.0935, Loss_D_A: 0.0172, Loss_D_B: 0.0172\n",
            "Epoch 55/70, Batch 18/25, Image: rainy_1957.jpg, Loss_G: 9.4751, Loss_D_A: 0.0039, Loss_D_B: 0.0024\n",
            "Epoch 55/70, Batch 19/25, Image: rainy_2759.jpg, Loss_G: 7.4936, Loss_D_A: 0.0145, Loss_D_B: 0.0052\n",
            "Epoch 55/70, Batch 20/25, Image: rainy_795.jpg, Loss_G: 7.4486, Loss_D_A: 0.0349, Loss_D_B: 0.0103\n",
            "Epoch 55/70, Batch 21/25, Image: rainy_3136.jpg, Loss_G: 8.1150, Loss_D_A: 0.0641, Loss_D_B: 0.0101\n",
            "Epoch 55/70, Batch 22/25, Image: rainy_2275.jpg, Loss_G: 9.6095, Loss_D_A: 0.0448, Loss_D_B: 0.0032\n",
            "Epoch 55/70, Batch 23/25, Image: rainy_748.jpg, Loss_G: 8.2479, Loss_D_A: 0.0201, Loss_D_B: 0.0024\n",
            "Epoch 55/70, Batch 24/25, Image: rainy_2544.jpg, Loss_G: 7.8374, Loss_D_A: 0.0096, Loss_D_B: 0.0033\n",
            "✅ Checkpoint saved at epoch 55\n",
            "Epoch 56/70, Batch 0/25, Image: rainy_923.jpg, Loss_G: 8.7897, Loss_D_A: 0.0102, Loss_D_B: 0.0023\n",
            "Epoch 56/70, Batch 1/25, Image: rainy_2492.jpg, Loss_G: 7.9491, Loss_D_A: 0.0103, Loss_D_B: 0.0025\n",
            "Epoch 56/70, Batch 2/25, Image: rainy_1185.jpg, Loss_G: 8.3572, Loss_D_A: 0.0073, Loss_D_B: 0.0031\n",
            "Epoch 56/70, Batch 3/25, Image: rainy_2619.jpg, Loss_G: 9.6719, Loss_D_A: 0.0079, Loss_D_B: 0.0096\n",
            "Epoch 56/70, Batch 4/25, Image: rainy_267.jpg, Loss_G: 8.8918, Loss_D_A: 0.0065, Loss_D_B: 0.0056\n",
            "Epoch 56/70, Batch 5/25, Image: rainy_270.jpg, Loss_G: 8.5247, Loss_D_A: 0.0049, Loss_D_B: 0.0041\n",
            "Epoch 56/70, Batch 6/25, Image: rainy_2431.jpg, Loss_G: 11.2668, Loss_D_A: 0.0052, Loss_D_B: 0.0058\n",
            "Epoch 56/70, Batch 7/25, Image: rainy_2836.jpg, Loss_G: 8.7093, Loss_D_A: 0.0029, Loss_D_B: 0.0073\n",
            "Epoch 56/70, Batch 8/25, Image: rainy_540.jpg, Loss_G: 9.9972, Loss_D_A: 0.0032, Loss_D_B: 0.0154\n",
            "Epoch 56/70, Batch 9/25, Image: rainy_3529.jpg, Loss_G: 9.4846, Loss_D_A: 0.0149, Loss_D_B: 0.0210\n",
            "Epoch 56/70, Batch 10/25, Image: rainy_3268.jpg, Loss_G: 8.6956, Loss_D_A: 0.0222, Loss_D_B: 0.0314\n",
            "Epoch 56/70, Batch 11/25, Image: rainy_2474.jpg, Loss_G: 11.3868, Loss_D_A: 0.0126, Loss_D_B: 0.0544\n",
            "Epoch 56/70, Batch 12/25, Image: rainy_849.jpg, Loss_G: 7.1275, Loss_D_A: 0.0070, Loss_D_B: 0.0456\n",
            "Epoch 56/70, Batch 13/25, Image: rainy_1434.jpg, Loss_G: 7.6728, Loss_D_A: 0.0107, Loss_D_B: 0.0232\n",
            "Epoch 56/70, Batch 14/25, Image: rainy_1591.jpg, Loss_G: 9.2480, Loss_D_A: 0.0099, Loss_D_B: 0.0054\n",
            "Epoch 56/70, Batch 15/25, Image: rainy_904.jpg, Loss_G: 8.7375, Loss_D_A: 0.0094, Loss_D_B: 0.0020\n",
            "Epoch 56/70, Batch 16/25, Image: rainy_3020.jpg, Loss_G: 7.6087, Loss_D_A: 0.0046, Loss_D_B: 0.0049\n",
            "Epoch 56/70, Batch 17/25, Image: rainy_2714.jpg, Loss_G: 8.5011, Loss_D_A: 0.0021, Loss_D_B: 0.0045\n",
            "Epoch 56/70, Batch 18/25, Image: rainy_1059.jpg, Loss_G: 10.6607, Loss_D_A: 0.0038, Loss_D_B: 0.0034\n",
            "Epoch 56/70, Batch 19/25, Image: rainy_841.jpg, Loss_G: 8.5873, Loss_D_A: 0.0088, Loss_D_B: 0.0032\n",
            "Epoch 56/70, Batch 20/25, Image: rainy_2114.jpg, Loss_G: 8.9449, Loss_D_A: 0.0079, Loss_D_B: 0.0044\n",
            "Epoch 56/70, Batch 21/25, Image: rainy_2838.jpg, Loss_G: 8.5253, Loss_D_A: 0.0022, Loss_D_B: 0.0067\n",
            "Epoch 56/70, Batch 22/25, Image: rainy_170.jpg, Loss_G: 7.9594, Loss_D_A: 0.0023, Loss_D_B: 0.0054\n",
            "Epoch 56/70, Batch 23/25, Image: rainy_3090.jpg, Loss_G: 7.6480, Loss_D_A: 0.0029, Loss_D_B: 0.0025\n",
            "Epoch 56/70, Batch 24/25, Image: rainy_3164.jpg, Loss_G: 8.0209, Loss_D_A: 0.0025, Loss_D_B: 0.0018\n",
            "Epoch 57/70, Batch 0/25, Image: rainy_2620.jpg, Loss_G: 7.7670, Loss_D_A: 0.0033, Loss_D_B: 0.0012\n",
            "Epoch 57/70, Batch 1/25, Image: rainy_2197.jpg, Loss_G: 12.1489, Loss_D_A: 0.0064, Loss_D_B: 0.0029\n",
            "Epoch 57/70, Batch 2/25, Image: rainy_2570.jpg, Loss_G: 8.9040, Loss_D_A: 0.0090, Loss_D_B: 0.0031\n",
            "Epoch 57/70, Batch 3/25, Image: rainy_2460.jpg, Loss_G: 10.5509, Loss_D_A: 0.0139, Loss_D_B: 0.0038\n",
            "Epoch 57/70, Batch 4/25, Image: rainy_335.jpg, Loss_G: 7.3337, Loss_D_A: 0.0133, Loss_D_B: 0.0062\n",
            "Epoch 57/70, Batch 5/25, Image: rainy_923.jpg, Loss_G: 6.9900, Loss_D_A: 0.0069, Loss_D_B: 0.0042\n",
            "Epoch 57/70, Batch 6/25, Image: rainy_2985.jpg, Loss_G: 9.9262, Loss_D_A: 0.0027, Loss_D_B: 0.0025\n",
            "Epoch 57/70, Batch 7/25, Image: rainy_3509.jpg, Loss_G: 10.3793, Loss_D_A: 0.0062, Loss_D_B: 0.0037\n",
            "Epoch 57/70, Batch 8/25, Image: rainy_3020.jpg, Loss_G: 9.9545, Loss_D_A: 0.0163, Loss_D_B: 0.0070\n",
            "Epoch 57/70, Batch 9/25, Image: rainy_1568.jpg, Loss_G: 9.9586, Loss_D_A: 0.0268, Loss_D_B: 0.0030\n",
            "Epoch 57/70, Batch 10/25, Image: rainy_244.jpg, Loss_G: 8.3982, Loss_D_A: 0.0204, Loss_D_B: 0.0013\n",
            "Epoch 57/70, Batch 11/25, Image: rainy_3385.jpg, Loss_G: 7.8620, Loss_D_A: 0.0065, Loss_D_B: 0.0032\n",
            "Epoch 57/70, Batch 12/25, Image: rainy_2779.jpg, Loss_G: 7.0682, Loss_D_A: 0.0052, Loss_D_B: 0.0044\n",
            "Epoch 57/70, Batch 13/25, Image: rainy_2346.jpg, Loss_G: 7.2974, Loss_D_A: 0.0130, Loss_D_B: 0.0089\n",
            "Epoch 57/70, Batch 14/25, Image: rainy_558.jpg, Loss_G: 8.6125, Loss_D_A: 0.0091, Loss_D_B: 0.0108\n",
            "Epoch 57/70, Batch 15/25, Image: rainy_926.jpg, Loss_G: 11.2166, Loss_D_A: 0.0030, Loss_D_B: 0.0089\n",
            "Epoch 57/70, Batch 16/25, Image: rainy_3060.jpg, Loss_G: 10.2617, Loss_D_A: 0.0276, Loss_D_B: 0.0100\n",
            "Epoch 57/70, Batch 17/25, Image: rainy_1662.jpg, Loss_G: 10.2214, Loss_D_A: 0.0570, Loss_D_B: 0.0209\n",
            "Epoch 57/70, Batch 18/25, Image: rainy_841.jpg, Loss_G: 8.1375, Loss_D_A: 0.0190, Loss_D_B: 0.0088\n",
            "Epoch 57/70, Batch 19/25, Image: rainy_2973.jpg, Loss_G: 7.7677, Loss_D_A: 0.0054, Loss_D_B: 0.0040\n",
            "Epoch 57/70, Batch 20/25, Image: rainy_2928.jpg, Loss_G: 7.1296, Loss_D_A: 0.0050, Loss_D_B: 0.0021\n",
            "Epoch 57/70, Batch 21/25, Image: rainy_267.jpg, Loss_G: 7.8073, Loss_D_A: 0.0047, Loss_D_B: 0.0023\n",
            "Epoch 57/70, Batch 22/25, Image: rainy_3063.jpg, Loss_G: 9.3168, Loss_D_A: 0.0109, Loss_D_B: 0.0073\n",
            "Epoch 57/70, Batch 23/25, Image: rainy_119.jpg, Loss_G: 8.0254, Loss_D_A: 0.0163, Loss_D_B: 0.0150\n",
            "Epoch 57/70, Batch 24/25, Image: rainy_2619.jpg, Loss_G: 8.3261, Loss_D_A: 0.0098, Loss_D_B: 0.0122\n",
            "Epoch 58/70, Batch 0/25, Image: rainy_2431.jpg, Loss_G: 8.0874, Loss_D_A: 0.0107, Loss_D_B: 0.0056\n",
            "Epoch 58/70, Batch 1/25, Image: rainy_232.jpg, Loss_G: 9.7480, Loss_D_A: 0.0149, Loss_D_B: 0.0045\n",
            "Epoch 58/70, Batch 2/25, Image: rainy_537.jpg, Loss_G: 7.7255, Loss_D_A: 0.0141, Loss_D_B: 0.0028\n",
            "Epoch 58/70, Batch 3/25, Image: rainy_3156.jpg, Loss_G: 10.6506, Loss_D_A: 0.0030, Loss_D_B: 0.0027\n",
            "Epoch 58/70, Batch 4/25, Image: rainy_1091.jpg, Loss_G: 7.3714, Loss_D_A: 0.0058, Loss_D_B: 0.0027\n",
            "Epoch 58/70, Batch 5/25, Image: rainy_3529.jpg, Loss_G: 8.2698, Loss_D_A: 0.0109, Loss_D_B: 0.0031\n",
            "Epoch 58/70, Batch 6/25, Image: rainy_2453.jpg, Loss_G: 9.7012, Loss_D_A: 0.0110, Loss_D_B: 0.0022\n",
            "Epoch 58/70, Batch 7/25, Image: rainy_3703.jpg, Loss_G: 8.4558, Loss_D_A: 0.0081, Loss_D_B: 0.0038\n",
            "Epoch 58/70, Batch 8/25, Image: rainy_1167.jpg, Loss_G: 8.4214, Loss_D_A: 0.0062, Loss_D_B: 0.0057\n",
            "Epoch 58/70, Batch 9/25, Image: rainy_2198.jpg, Loss_G: 6.5183, Loss_D_A: 0.0067, Loss_D_B: 0.0056\n",
            "Epoch 58/70, Batch 10/25, Image: rainy_166.jpg, Loss_G: 10.1048, Loss_D_A: 0.0049, Loss_D_B: 0.0104\n",
            "Epoch 58/70, Batch 11/25, Image: rainy_382.jpg, Loss_G: 9.8068, Loss_D_A: 0.0020, Loss_D_B: 0.0070\n",
            "Epoch 58/70, Batch 12/25, Image: rainy_298.jpg, Loss_G: 8.4802, Loss_D_A: 0.0034, Loss_D_B: 0.0039\n",
            "Epoch 58/70, Batch 13/25, Image: rainy_267.jpg, Loss_G: 8.0911, Loss_D_A: 0.0075, Loss_D_B: 0.0018\n",
            "Epoch 58/70, Batch 14/25, Image: rainy_1555.jpg, Loss_G: 10.0892, Loss_D_A: 0.0060, Loss_D_B: 0.0013\n",
            "Epoch 58/70, Batch 15/25, Image: rainy_3398.jpg, Loss_G: 9.0934, Loss_D_A: 0.0018, Loss_D_B: 0.0020\n",
            "Epoch 58/70, Batch 16/25, Image: rainy_904.jpg, Loss_G: 8.1433, Loss_D_A: 0.0101, Loss_D_B: 0.0025\n",
            "Epoch 58/70, Batch 17/25, Image: rainy_788.jpg, Loss_G: 7.4902, Loss_D_A: 0.0185, Loss_D_B: 0.0019\n",
            "Epoch 58/70, Batch 18/25, Image: rainy_3090.jpg, Loss_G: 9.5213, Loss_D_A: 0.0145, Loss_D_B: 0.0043\n",
            "Epoch 58/70, Batch 19/25, Image: rainy_1771.jpg, Loss_G: 8.8875, Loss_D_A: 0.0049, Loss_D_B: 0.0034\n",
            "Epoch 58/70, Batch 20/25, Image: rainy_1820 (1).jpg, Loss_G: 8.7118, Loss_D_A: 0.0028, Loss_D_B: 0.0042\n",
            "Epoch 58/70, Batch 21/25, Image: rainy_1456.jpg, Loss_G: 7.9232, Loss_D_A: 0.0052, Loss_D_B: 0.0024\n",
            "Epoch 58/70, Batch 22/25, Image: rainy_859.jpg, Loss_G: 7.5419, Loss_D_A: 0.0096, Loss_D_B: 0.0018\n",
            "Epoch 58/70, Batch 23/25, Image: rainy_2474.jpg, Loss_G: 7.8652, Loss_D_A: 0.0055, Loss_D_B: 0.0037\n",
            "Epoch 58/70, Batch 24/25, Image: rainy_475.jpg, Loss_G: 7.7967, Loss_D_A: 0.0026, Loss_D_B: 0.0044\n",
            "Epoch 59/70, Batch 0/25, Image: rainy_2928.jpg, Loss_G: 8.9736, Loss_D_A: 0.0034, Loss_D_B: 0.0025\n",
            "Epoch 59/70, Batch 1/25, Image: rainy_826.jpg, Loss_G: 6.9735, Loss_D_A: 0.0022, Loss_D_B: 0.0021\n",
            "Epoch 59/70, Batch 2/25, Image: rainy_3769.jpg, Loss_G: 7.8019, Loss_D_A: 0.0018, Loss_D_B: 0.0035\n",
            "Epoch 59/70, Batch 3/25, Image: rainy_3710.jpg, Loss_G: 8.8178, Loss_D_A: 0.0022, Loss_D_B: 0.0056\n",
            "Epoch 59/70, Batch 4/25, Image: rainy_1656.jpg, Loss_G: 7.9721, Loss_D_A: 0.0027, Loss_D_B: 0.0080\n",
            "Epoch 59/70, Batch 5/25, Image: rainy_2968.jpg, Loss_G: 7.4482, Loss_D_A: 0.0030, Loss_D_B: 0.0117\n",
            "Epoch 59/70, Batch 6/25, Image: rainy_491.jpg, Loss_G: 9.6882, Loss_D_A: 0.0041, Loss_D_B: 0.0166\n",
            "Epoch 59/70, Batch 7/25, Image: rainy_3821.jpg, Loss_G: 8.0594, Loss_D_A: 0.0037, Loss_D_B: 0.0198\n",
            "Epoch 59/70, Batch 8/25, Image: rainy_2747.jpg, Loss_G: 12.6958, Loss_D_A: 0.0030, Loss_D_B: 0.0224\n",
            "Epoch 59/70, Batch 9/25, Image: rainy_328.jpg, Loss_G: 10.7976, Loss_D_A: 0.0022, Loss_D_B: 0.0153\n",
            "Epoch 59/70, Batch 10/25, Image: rainy_1530.jpg, Loss_G: 9.4296, Loss_D_A: 0.0040, Loss_D_B: 0.0095\n",
            "Epoch 59/70, Batch 11/25, Image: rainy_2544.jpg, Loss_G: 10.1422, Loss_D_A: 0.0049, Loss_D_B: 0.0060\n",
            "Epoch 59/70, Batch 12/25, Image: rainy_1591.jpg, Loss_G: 11.7044, Loss_D_A: 0.0066, Loss_D_B: 0.0073\n",
            "Epoch 59/70, Batch 13/25, Image: rainy_3398.jpg, Loss_G: 8.5824, Loss_D_A: 0.0078, Loss_D_B: 0.0086\n",
            "Epoch 59/70, Batch 14/25, Image: rainy_3355.jpg, Loss_G: 9.3825, Loss_D_A: 0.0062, Loss_D_B: 0.0082\n",
            "Epoch 59/70, Batch 15/25, Image: rainy_558.jpg, Loss_G: 9.0259, Loss_D_A: 0.0037, Loss_D_B: 0.0108\n",
            "Epoch 59/70, Batch 16/25, Image: rainy_332.jpg, Loss_G: 8.4909, Loss_D_A: 0.0020, Loss_D_B: 0.0101\n",
            "Epoch 59/70, Batch 17/25, Image: rainy_988.jpg, Loss_G: 9.6613, Loss_D_A: 0.0033, Loss_D_B: 0.0078\n",
            "Epoch 59/70, Batch 18/25, Image: rainy_232.jpg, Loss_G: 7.7965, Loss_D_A: 0.0040, Loss_D_B: 0.0038\n",
            "Epoch 59/70, Batch 19/25, Image: rainy_3010.jpg, Loss_G: 7.8509, Loss_D_A: 0.0045, Loss_D_B: 0.0026\n",
            "Epoch 59/70, Batch 20/25, Image: rainy_3363.jpg, Loss_G: 6.9185, Loss_D_A: 0.0026, Loss_D_B: 0.0027\n",
            "Epoch 59/70, Batch 21/25, Image: rainy_1471.jpg, Loss_G: 7.4540, Loss_D_A: 0.0044, Loss_D_B: 0.0043\n",
            "Epoch 59/70, Batch 22/25, Image: rainy_540.jpg, Loss_G: 13.3421, Loss_D_A: 0.0062, Loss_D_B: 0.0068\n",
            "Epoch 59/70, Batch 23/25, Image: rainy_1639.jpg, Loss_G: 8.9680, Loss_D_A: 0.0093, Loss_D_B: 0.0074\n",
            "Epoch 59/70, Batch 24/25, Image: rainy_3063.jpg, Loss_G: 9.7546, Loss_D_A: 0.0032, Loss_D_B: 0.0028\n",
            "Epoch 60/70, Batch 0/25, Image: rainy_3213.jpg, Loss_G: 8.9196, Loss_D_A: 0.0030, Loss_D_B: 0.0066\n",
            "Epoch 60/70, Batch 1/25, Image: rainy_1091.jpg, Loss_G: 7.8351, Loss_D_A: 0.0052, Loss_D_B: 0.0127\n",
            "Epoch 60/70, Batch 2/25, Image: rainy_298.jpg, Loss_G: 8.4505, Loss_D_A: 0.0062, Loss_D_B: 0.0168\n",
            "Epoch 60/70, Batch 3/25, Image: rainy_2928.jpg, Loss_G: 6.4951, Loss_D_A: 0.0073, Loss_D_B: 0.0159\n",
            "Epoch 60/70, Batch 4/25, Image: rainy_2977.jpg, Loss_G: 7.7842, Loss_D_A: 0.0055, Loss_D_B: 0.0108\n",
            "Epoch 60/70, Batch 5/25, Image: rainy_3813.jpg, Loss_G: 7.3628, Loss_D_A: 0.0036, Loss_D_B: 0.0049\n",
            "Epoch 60/70, Batch 6/25, Image: rainy_1346.jpg, Loss_G: 9.2060, Loss_D_A: 0.0037, Loss_D_B: 0.0020\n",
            "Epoch 60/70, Batch 7/25, Image: rainy_270.jpg, Loss_G: 8.8683, Loss_D_A: 0.0055, Loss_D_B: 0.0020\n",
            "Epoch 60/70, Batch 8/25, Image: rainy_2453.jpg, Loss_G: 7.1063, Loss_D_A: 0.0044, Loss_D_B: 0.0019\n",
            "Epoch 60/70, Batch 9/25, Image: rainy_2275.jpg, Loss_G: 10.2736, Loss_D_A: 0.0038, Loss_D_B: 0.0037\n",
            "Epoch 60/70, Batch 10/25, Image: rainy_1957.jpg, Loss_G: 8.7542, Loss_D_A: 0.0024, Loss_D_B: 0.0090\n",
            "Epoch 60/70, Batch 11/25, Image: rainy_1662.jpg, Loss_G: 7.1580, Loss_D_A: 0.0021, Loss_D_B: 0.0108\n",
            "Epoch 60/70, Batch 12/25, Image: rainy_3371.jpg, Loss_G: 8.7024, Loss_D_A: 0.0026, Loss_D_B: 0.0073\n",
            "Epoch 60/70, Batch 13/25, Image: rainy_2132.jpg, Loss_G: 8.6063, Loss_D_A: 0.0019, Loss_D_B: 0.0038\n",
            "Epoch 60/70, Batch 14/25, Image: rainy_1456.jpg, Loss_G: 7.8472, Loss_D_A: 0.0017, Loss_D_B: 0.0022\n",
            "Epoch 60/70, Batch 15/25, Image: rainy_518.jpg, Loss_G: 6.9751, Loss_D_A: 0.0021, Loss_D_B: 0.0018\n",
            "Epoch 60/70, Batch 16/25, Image: rainy_865.jpg, Loss_G: 10.0010, Loss_D_A: 0.0046, Loss_D_B: 0.0080\n",
            "Epoch 60/70, Batch 17/25, Image: rainy_53.jpg, Loss_G: 8.1973, Loss_D_A: 0.0030, Loss_D_B: 0.0052\n",
            "Epoch 60/70, Batch 18/25, Image: rainy_3428.jpg, Loss_G: 8.7106, Loss_D_A: 0.0021, Loss_D_B: 0.0102\n",
            "Epoch 60/70, Batch 19/25, Image: rainy_912.jpg, Loss_G: 9.0043, Loss_D_A: 0.0022, Loss_D_B: 0.0096\n",
            "Epoch 60/70, Batch 20/25, Image: rainy_868.jpg, Loss_G: 7.3999, Loss_D_A: 0.0023, Loss_D_B: 0.0066\n",
            "Epoch 60/70, Batch 21/25, Image: rainy_2346.jpg, Loss_G: 9.5600, Loss_D_A: 0.0028, Loss_D_B: 0.0056\n",
            "Epoch 60/70, Batch 22/25, Image: rainy_3136.jpg, Loss_G: 9.1005, Loss_D_A: 0.0027, Loss_D_B: 0.0022\n",
            "Epoch 60/70, Batch 23/25, Image: rainy_3756.jpg, Loss_G: 7.6038, Loss_D_A: 0.0042, Loss_D_B: 0.0040\n",
            "Epoch 60/70, Batch 24/25, Image: rainy_2259.jpg, Loss_G: 10.1997, Loss_D_A: 0.0061, Loss_D_B: 0.0067\n",
            "✅ Checkpoint saved at epoch 60\n",
            "Epoch 61/70, Batch 0/25, Image: rainy_913.jpg, Loss_G: 8.8874, Loss_D_A: 0.0046, Loss_D_B: 0.0051\n",
            "Epoch 61/70, Batch 1/25, Image: rainy_2838.jpg, Loss_G: 6.9209, Loss_D_A: 0.0017, Loss_D_B: 0.0022\n",
            "Epoch 61/70, Batch 2/25, Image: rainy_2943.jpg, Loss_G: 7.0351, Loss_D_A: 0.0035, Loss_D_B: 0.0024\n",
            "Epoch 61/70, Batch 3/25, Image: rainy_912.jpg, Loss_G: 7.5233, Loss_D_A: 0.0052, Loss_D_B: 0.0031\n",
            "Epoch 61/70, Batch 4/25, Image: rainy_902.jpg, Loss_G: 8.1246, Loss_D_A: 0.0038, Loss_D_B: 0.0031\n",
            "Epoch 61/70, Batch 5/25, Image: rainy_2985.jpg, Loss_G: 9.8882, Loss_D_A: 0.0016, Loss_D_B: 0.0021\n",
            "Epoch 61/70, Batch 6/25, Image: rainy_540.jpg, Loss_G: 9.1873, Loss_D_A: 0.0018, Loss_D_B: 0.0024\n",
            "Epoch 61/70, Batch 7/25, Image: rainy_2404.jpg, Loss_G: 8.3528, Loss_D_A: 0.0030, Loss_D_B: 0.0018\n",
            "Epoch 61/70, Batch 8/25, Image: rainy_1530.jpg, Loss_G: 10.2403, Loss_D_A: 0.0048, Loss_D_B: 0.0012\n",
            "Epoch 61/70, Batch 9/25, Image: rainy_1690.jpg, Loss_G: 10.7006, Loss_D_A: 0.0055, Loss_D_B: 0.0024\n",
            "Epoch 61/70, Batch 10/25, Image: rainy_1269.jpg, Loss_G: 9.0463, Loss_D_A: 0.0068, Loss_D_B: 0.0024\n",
            "Epoch 61/70, Batch 11/25, Image: rainy_2275.jpg, Loss_G: 10.1225, Loss_D_A: 0.0022, Loss_D_B: 0.0037\n",
            "Epoch 61/70, Batch 12/25, Image: rainy_232.jpg, Loss_G: 8.4404, Loss_D_A: 0.0083, Loss_D_B: 0.0106\n",
            "Epoch 61/70, Batch 13/25, Image: rainy_3355.jpg, Loss_G: 9.4425, Loss_D_A: 0.0243, Loss_D_B: 0.0069\n",
            "Epoch 61/70, Batch 14/25, Image: rainy_2724.jpg, Loss_G: 7.6772, Loss_D_A: 0.0346, Loss_D_B: 0.0030\n",
            "Epoch 61/70, Batch 15/25, Image: rainy_3606.jpg, Loss_G: 7.8118, Loss_D_A: 0.0293, Loss_D_B: 0.0075\n",
            "Epoch 61/70, Batch 16/25, Image: rainy_3063.jpg, Loss_G: 6.7007, Loss_D_A: 0.0149, Loss_D_B: 0.0111\n",
            "Epoch 61/70, Batch 17/25, Image: rainy_2492.jpg, Loss_G: 6.7531, Loss_D_A: 0.0034, Loss_D_B: 0.0092\n",
            "Epoch 61/70, Batch 18/25, Image: rainy_2259.jpg, Loss_G: 7.5991, Loss_D_A: 0.0028, Loss_D_B: 0.0026\n",
            "Epoch 61/70, Batch 19/25, Image: rainy_1771.jpg, Loss_G: 7.4697, Loss_D_A: 0.0060, Loss_D_B: 0.0022\n",
            "Epoch 61/70, Batch 20/25, Image: rainy_3078.jpg, Loss_G: 8.3798, Loss_D_A: 0.0073, Loss_D_B: 0.0053\n",
            "Epoch 61/70, Batch 21/25, Image: rainy_3710.jpg, Loss_G: 11.1571, Loss_D_A: 0.0051, Loss_D_B: 0.0083\n",
            "Epoch 61/70, Batch 22/25, Image: rainy_2132.jpg, Loss_G: 9.6889, Loss_D_A: 0.0036, Loss_D_B: 0.0087\n",
            "Epoch 61/70, Batch 23/25, Image: rainy_1591.jpg, Loss_G: 8.2539, Loss_D_A: 0.0024, Loss_D_B: 0.0048\n",
            "Epoch 61/70, Batch 24/25, Image: rainy_2060.jpg, Loss_G: 8.4338, Loss_D_A: 0.0023, Loss_D_B: 0.0022\n",
            "Epoch 62/70, Batch 0/25, Image: rainy_1784.jpg, Loss_G: 8.3339, Loss_D_A: 0.0026, Loss_D_B: 0.0051\n",
            "Epoch 62/70, Batch 1/25, Image: rainy_1286.jpg, Loss_G: 7.4991, Loss_D_A: 0.0015, Loss_D_B: 0.0059\n",
            "Epoch 62/70, Batch 2/25, Image: rainy_1237.jpg, Loss_G: 9.3262, Loss_D_A: 0.0016, Loss_D_B: 0.0043\n",
            "Epoch 62/70, Batch 3/25, Image: rainy_865.jpg, Loss_G: 8.9647, Loss_D_A: 0.0017, Loss_D_B: 0.0040\n",
            "Epoch 62/70, Batch 4/25, Image: rainy_481.jpg, Loss_G: 8.0694, Loss_D_A: 0.0017, Loss_D_B: 0.0053\n",
            "Epoch 62/70, Batch 5/25, Image: rainy_3606.jpg, Loss_G: 9.5871, Loss_D_A: 0.0023, Loss_D_B: 0.0059\n",
            "Epoch 62/70, Batch 6/25, Image: rainy_3951.jpg, Loss_G: 8.2451, Loss_D_A: 0.0056, Loss_D_B: 0.0037\n",
            "Epoch 62/70, Batch 7/25, Image: rainy_1899.jpg, Loss_G: 8.7525, Loss_D_A: 0.0080, Loss_D_B: 0.0011\n",
            "Epoch 62/70, Batch 8/25, Image: rainy_1901.jpg, Loss_G: 10.3464, Loss_D_A: 0.0054, Loss_D_B: 0.0027\n",
            "Epoch 62/70, Batch 9/25, Image: rainy_3584.jpg, Loss_G: 8.4757, Loss_D_A: 0.0022, Loss_D_B: 0.0035\n",
            "Epoch 62/70, Batch 10/25, Image: rainy_2973.jpg, Loss_G: 10.7650, Loss_D_A: 0.0015, Loss_D_B: 0.0028\n",
            "Epoch 62/70, Batch 11/25, Image: rainy_2453.jpg, Loss_G: 7.8598, Loss_D_A: 0.0017, Loss_D_B: 0.0038\n",
            "Epoch 62/70, Batch 12/25, Image: rainy_3703.jpg, Loss_G: 6.9193, Loss_D_A: 0.0020, Loss_D_B: 0.0109\n",
            "Epoch 62/70, Batch 13/25, Image: rainy_1957.jpg, Loss_G: 9.7493, Loss_D_A: 0.0024, Loss_D_B: 0.0186\n",
            "Epoch 62/70, Batch 14/25, Image: rainy_3769.jpg, Loss_G: 9.5524, Loss_D_A: 0.0026, Loss_D_B: 0.0153\n",
            "Epoch 62/70, Batch 15/25, Image: rainy_398.jpg, Loss_G: 8.5799, Loss_D_A: 0.0020, Loss_D_B: 0.0101\n",
            "Epoch 62/70, Batch 16/25, Image: rainy_3337.jpg, Loss_G: 11.1248, Loss_D_A: 0.0024, Loss_D_B: 0.0078\n",
            "Epoch 62/70, Batch 17/25, Image: rainy_2619.jpg, Loss_G: 9.9826, Loss_D_A: 0.0018, Loss_D_B: 0.0050\n",
            "Epoch 62/70, Batch 18/25, Image: rainy_2629.jpg, Loss_G: 8.9033, Loss_D_A: 0.0023, Loss_D_B: 0.0031\n",
            "Epoch 62/70, Batch 19/25, Image: rainy_184.jpg, Loss_G: 8.5502, Loss_D_A: 0.0062, Loss_D_B: 0.0053\n",
            "Epoch 62/70, Batch 20/25, Image: rainy_1508.jpg, Loss_G: 9.5264, Loss_D_A: 0.0067, Loss_D_B: 0.0042\n",
            "Epoch 62/70, Batch 21/25, Image: rainy_1083.jpg, Loss_G: 8.3567, Loss_D_A: 0.0036, Loss_D_B: 0.0018\n",
            "Epoch 62/70, Batch 22/25, Image: rainy_2814.jpg, Loss_G: 8.8173, Loss_D_A: 0.0032, Loss_D_B: 0.0023\n",
            "Epoch 62/70, Batch 23/25, Image: rainy_2197.jpg, Loss_G: 8.2010, Loss_D_A: 0.0043, Loss_D_B: 0.0045\n",
            "Epoch 62/70, Batch 24/25, Image: rainy_3445.jpg, Loss_G: 7.9187, Loss_D_A: 0.0108, Loss_D_B: 0.0047\n",
            "Epoch 63/70, Batch 0/25, Image: rainy_923.jpg, Loss_G: 7.2727, Loss_D_A: 0.0171, Loss_D_B: 0.0051\n",
            "Epoch 63/70, Batch 1/25, Image: rainy_1901.jpg, Loss_G: 7.4019, Loss_D_A: 0.0120, Loss_D_B: 0.0048\n",
            "Epoch 63/70, Batch 2/25, Image: rainy_2836.jpg, Loss_G: 7.7124, Loss_D_A: 0.0041, Loss_D_B: 0.0032\n",
            "Epoch 63/70, Batch 3/25, Image: rainy_328.jpg, Loss_G: 7.3932, Loss_D_A: 0.0031, Loss_D_B: 0.0024\n",
            "Epoch 63/70, Batch 4/25, Image: rainy_2968.jpg, Loss_G: 7.2476, Loss_D_A: 0.0020, Loss_D_B: 0.0025\n",
            "Epoch 63/70, Batch 5/25, Image: rainy_865.jpg, Loss_G: 8.0568, Loss_D_A: 0.0013, Loss_D_B: 0.0029\n",
            "Epoch 63/70, Batch 6/25, Image: rainy_2814.jpg, Loss_G: 7.8687, Loss_D_A: 0.0032, Loss_D_B: 0.0028\n",
            "Epoch 63/70, Batch 7/25, Image: rainy_332.jpg, Loss_G: 8.3999, Loss_D_A: 0.0085, Loss_D_B: 0.0011\n",
            "Epoch 63/70, Batch 8/25, Image: rainy_3710.jpg, Loss_G: 9.1742, Loss_D_A: 0.0115, Loss_D_B: 0.0059\n",
            "Epoch 63/70, Batch 9/25, Image: rainy_3584.jpg, Loss_G: 7.2228, Loss_D_A: 0.0074, Loss_D_B: 0.0057\n",
            "Epoch 63/70, Batch 10/25, Image: rainy_3001.jpg, Loss_G: 7.3803, Loss_D_A: 0.0081, Loss_D_B: 0.0095\n",
            "Epoch 63/70, Batch 11/25, Image: rainy_1381.jpg, Loss_G: 8.4963, Loss_D_A: 0.0018, Loss_D_B: 0.0050\n",
            "Epoch 63/70, Batch 12/25, Image: rainy_3371.jpg, Loss_G: 8.0720, Loss_D_A: 0.0042, Loss_D_B: 0.0079\n",
            "Epoch 63/70, Batch 13/25, Image: rainy_1861.jpg, Loss_G: 7.7173, Loss_D_A: 0.0067, Loss_D_B: 0.0060\n",
            "Epoch 63/70, Batch 14/25, Image: rainy_2275.jpg, Loss_G: 8.8185, Loss_D_A: 0.0047, Loss_D_B: 0.0032\n",
            "Epoch 63/70, Batch 15/25, Image: rainy_1931.jpg, Loss_G: 8.0174, Loss_D_A: 0.0140, Loss_D_B: 0.0067\n",
            "Epoch 63/70, Batch 16/25, Image: rainy_926.jpg, Loss_G: 7.1852, Loss_D_A: 0.0325, Loss_D_B: 0.0147\n",
            "Epoch 63/70, Batch 17/25, Image: rainy_1091.jpg, Loss_G: 7.6431, Loss_D_A: 0.0564, Loss_D_B: 0.0191\n",
            "Epoch 63/70, Batch 18/25, Image: rainy_2952.jpg, Loss_G: 8.2875, Loss_D_A: 0.0761, Loss_D_B: 0.0162\n",
            "Epoch 63/70, Batch 19/25, Image: rainy_1876.jpg, Loss_G: 7.6419, Loss_D_A: 0.0491, Loss_D_B: 0.0073\n",
            "Epoch 63/70, Batch 20/25, Image: rainy_1083.jpg, Loss_G: 6.9602, Loss_D_A: 0.0173, Loss_D_B: 0.0023\n",
            "Epoch 63/70, Batch 21/25, Image: rainy_3635.jpg, Loss_G: 8.2885, Loss_D_A: 0.0058, Loss_D_B: 0.0046\n",
            "Epoch 63/70, Batch 22/25, Image: rainy_1966.jpg, Loss_G: 7.3457, Loss_D_A: 0.0102, Loss_D_B: 0.0095\n",
            "Epoch 63/70, Batch 23/25, Image: rainy_1591.jpg, Loss_G: 7.9095, Loss_D_A: 0.0086, Loss_D_B: 0.0158\n",
            "Epoch 63/70, Batch 24/25, Image: rainy_3355.jpg, Loss_G: 8.9750, Loss_D_A: 0.0053, Loss_D_B: 0.0152\n",
            "Epoch 64/70, Batch 0/25, Image: rainy_3371.jpg, Loss_G: 11.4612, Loss_D_A: 0.0082, Loss_D_B: 0.0057\n",
            "Epoch 64/70, Batch 1/25, Image: rainy_2492.jpg, Loss_G: 7.5328, Loss_D_A: 0.0187, Loss_D_B: 0.0031\n",
            "Epoch 64/70, Batch 2/25, Image: rainy_3213.jpg, Loss_G: 8.9851, Loss_D_A: 0.0293, Loss_D_B: 0.0079\n",
            "Epoch 64/70, Batch 3/25, Image: rainy_1456.jpg, Loss_G: 8.8814, Loss_D_A: 0.0326, Loss_D_B: 0.0077\n",
            "Epoch 64/70, Batch 4/25, Image: rainy_2759.jpg, Loss_G: 8.8116, Loss_D_A: 0.0504, Loss_D_B: 0.0116\n",
            "Epoch 64/70, Batch 5/25, Image: rainy_2747.jpg, Loss_G: 8.6856, Loss_D_A: 0.0426, Loss_D_B: 0.0091\n",
            "Epoch 64/70, Batch 6/25, Image: rainy_814.jpg, Loss_G: 11.9116, Loss_D_A: 0.0278, Loss_D_B: 0.0035\n",
            "Epoch 64/70, Batch 7/25, Image: rainy_988.jpg, Loss_G: 7.5282, Loss_D_A: 0.0079, Loss_D_B: 0.0099\n",
            "Epoch 64/70, Batch 8/25, Image: rainy_3509.jpg, Loss_G: 9.5654, Loss_D_A: 0.0061, Loss_D_B: 0.0196\n",
            "Epoch 64/70, Batch 9/25, Image: rainy_748.jpg, Loss_G: 9.2309, Loss_D_A: 0.0177, Loss_D_B: 0.0184\n",
            "Epoch 64/70, Batch 10/25, Image: rainy_752.jpg, Loss_G: 8.2209, Loss_D_A: 0.0154, Loss_D_B: 0.0045\n",
            "Epoch 64/70, Batch 11/25, Image: rainy_3019.jpg, Loss_G: 8.4460, Loss_D_A: 0.0050, Loss_D_B: 0.0040\n",
            "Epoch 64/70, Batch 12/25, Image: rainy_1508.jpg, Loss_G: 8.9120, Loss_D_A: 0.0046, Loss_D_B: 0.0135\n",
            "Epoch 64/70, Batch 13/25, Image: rainy_2544.jpg, Loss_G: 8.2094, Loss_D_A: 0.0060, Loss_D_B: 0.0206\n",
            "Epoch 64/70, Batch 14/25, Image: rainy_1172.jpg, Loss_G: 7.7510, Loss_D_A: 0.0019, Loss_D_B: 0.0118\n",
            "Epoch 64/70, Batch 15/25, Image: rainy_2968.jpg, Loss_G: 8.5641, Loss_D_A: 0.0043, Loss_D_B: 0.0031\n",
            "Epoch 64/70, Batch 16/25, Image: rainy_1482.jpg, Loss_G: 8.4840, Loss_D_A: 0.0083, Loss_D_B: 0.0012\n",
            "Epoch 64/70, Batch 17/25, Image: rainy_1237.jpg, Loss_G: 8.7970, Loss_D_A: 0.0048, Loss_D_B: 0.0041\n",
            "Epoch 64/70, Batch 18/25, Image: rainy_2955.jpg, Loss_G: 7.0735, Loss_D_A: 0.0017, Loss_D_B: 0.0057\n",
            "Epoch 64/70, Batch 19/25, Image: rainy_3001.jpg, Loss_G: 7.6182, Loss_D_A: 0.0025, Loss_D_B: 0.0033\n",
            "Epoch 64/70, Batch 20/25, Image: rainy_270.jpg, Loss_G: 7.8127, Loss_D_A: 0.0051, Loss_D_B: 0.0040\n",
            "Epoch 64/70, Batch 21/25, Image: rainy_3010.jpg, Loss_G: 8.8587, Loss_D_A: 0.0125, Loss_D_B: 0.0159\n",
            "Epoch 64/70, Batch 22/25, Image: rainy_3606.jpg, Loss_G: 8.8812, Loss_D_A: 0.0256, Loss_D_B: 0.0283\n",
            "Epoch 64/70, Batch 23/25, Image: rainy_1091.jpg, Loss_G: 8.2106, Loss_D_A: 0.0181, Loss_D_B: 0.0300\n",
            "Epoch 64/70, Batch 24/25, Image: rainy_2928.jpg, Loss_G: 8.5848, Loss_D_A: 0.0063, Loss_D_B: 0.0150\n",
            "Epoch 65/70, Batch 0/25, Image: rainy_3136.jpg, Loss_G: 7.1127, Loss_D_A: 0.0107, Loss_D_B: 0.0079\n",
            "Epoch 65/70, Batch 1/25, Image: rainy_1456.jpg, Loss_G: 7.9058, Loss_D_A: 0.0058, Loss_D_B: 0.0030\n",
            "Epoch 65/70, Batch 2/25, Image: rainy_3164.jpg, Loss_G: 8.0901, Loss_D_A: 0.0070, Loss_D_B: 0.0021\n",
            "Epoch 65/70, Batch 3/25, Image: rainy_2691.jpg, Loss_G: 6.7321, Loss_D_A: 0.0198, Loss_D_B: 0.0039\n",
            "Epoch 65/70, Batch 4/25, Image: rainy_3951.jpg, Loss_G: 7.7194, Loss_D_A: 0.0239, Loss_D_B: 0.0111\n",
            "Epoch 65/70, Batch 5/25, Image: rainy_1901.jpg, Loss_G: 7.2080, Loss_D_A: 0.0193, Loss_D_B: 0.0165\n",
            "Epoch 65/70, Batch 6/25, Image: rainy_260.jpg, Loss_G: 7.9827, Loss_D_A: 0.0125, Loss_D_B: 0.0146\n",
            "Epoch 65/70, Batch 7/25, Image: rainy_335.jpg, Loss_G: 7.5010, Loss_D_A: 0.0026, Loss_D_B: 0.0048\n",
            "Epoch 65/70, Batch 8/25, Image: rainy_788.jpg, Loss_G: 8.0578, Loss_D_A: 0.0034, Loss_D_B: 0.0025\n",
            "Epoch 65/70, Batch 9/25, Image: rainy_2431.jpg, Loss_G: 8.3788, Loss_D_A: 0.0045, Loss_D_B: 0.0049\n",
            "Epoch 65/70, Batch 10/25, Image: rainy_2474.jpg, Loss_G: 7.0895, Loss_D_A: 0.0011, Loss_D_B: 0.0054\n",
            "Epoch 65/70, Batch 11/25, Image: rainy_3063.jpg, Loss_G: 9.0043, Loss_D_A: 0.0023, Loss_D_B: 0.0043\n",
            "Epoch 65/70, Batch 12/25, Image: rainy_3193.jpg, Loss_G: 8.0416, Loss_D_A: 0.0022, Loss_D_B: 0.0036\n",
            "Epoch 65/70, Batch 13/25, Image: rainy_1482.jpg, Loss_G: 9.0657, Loss_D_A: 0.0020, Loss_D_B: 0.0032\n",
            "Epoch 65/70, Batch 14/25, Image: rainy_2570.jpg, Loss_G: 8.0270, Loss_D_A: 0.0029, Loss_D_B: 0.0055\n",
            "Epoch 65/70, Batch 15/25, Image: rainy_2968.jpg, Loss_G: 7.8676, Loss_D_A: 0.0025, Loss_D_B: 0.0038\n",
            "Epoch 65/70, Batch 16/25, Image: rainy_773.jpg, Loss_G: 8.0632, Loss_D_A: 0.0014, Loss_D_B: 0.0020\n",
            "Epoch 65/70, Batch 17/25, Image: rainy_3078.jpg, Loss_G: 6.6053, Loss_D_A: 0.0034, Loss_D_B: 0.0013\n",
            "Epoch 65/70, Batch 18/25, Image: rainy_2257.jpg, Loss_G: 7.6178, Loss_D_A: 0.0020, Loss_D_B: 0.0020\n",
            "Epoch 65/70, Batch 19/25, Image: rainy_166.jpg, Loss_G: 7.4780, Loss_D_A: 0.0016, Loss_D_B: 0.0070\n",
            "Epoch 65/70, Batch 20/25, Image: rainy_199.jpg, Loss_G: 8.1536, Loss_D_A: 0.0026, Loss_D_B: 0.0195\n",
            "Epoch 65/70, Batch 21/25, Image: rainy_2492.jpg, Loss_G: 7.2679, Loss_D_A: 0.0026, Loss_D_B: 0.0164\n",
            "Epoch 65/70, Batch 22/25, Image: rainy_859.jpg, Loss_G: 8.9283, Loss_D_A: 0.0061, Loss_D_B: 0.0067\n",
            "Epoch 65/70, Batch 23/25, Image: rainy_1784.jpg, Loss_G: 10.7151, Loss_D_A: 0.0147, Loss_D_B: 0.0036\n",
            "Epoch 65/70, Batch 24/25, Image: rainy_826.jpg, Loss_G: 10.3688, Loss_D_A: 0.0161, Loss_D_B: 0.0070\n",
            "✅ Checkpoint saved at epoch 65\n",
            "Epoch 66/70, Batch 0/25, Image: rainy_3428.jpg, Loss_G: 8.3800, Loss_D_A: 0.0113, Loss_D_B: 0.0049\n",
            "Epoch 66/70, Batch 1/25, Image: rainy_540.jpg, Loss_G: 9.8067, Loss_D_A: 0.0062, Loss_D_B: 0.0046\n",
            "Epoch 66/70, Batch 2/25, Image: rainy_1434.jpg, Loss_G: 8.0935, Loss_D_A: 0.0022, Loss_D_B: 0.0023\n",
            "Epoch 66/70, Batch 3/25, Image: rainy_3363.jpg, Loss_G: 8.1209, Loss_D_A: 0.0034, Loss_D_B: 0.0022\n",
            "Epoch 66/70, Batch 4/25, Image: rainy_3063.jpg, Loss_G: 7.1502, Loss_D_A: 0.0022, Loss_D_B: 0.0015\n",
            "Epoch 66/70, Batch 5/25, Image: rainy_814.jpg, Loss_G: 6.6958, Loss_D_A: 0.0034, Loss_D_B: 0.0018\n",
            "Epoch 66/70, Batch 6/25, Image: rainy_2724.jpg, Loss_G: 8.2190, Loss_D_A: 0.0055, Loss_D_B: 0.0013\n",
            "Epoch 66/70, Batch 7/25, Image: rainy_2857.jpg, Loss_G: 6.9620, Loss_D_A: 0.0027, Loss_D_B: 0.0014\n",
            "Epoch 66/70, Batch 8/25, Image: rainy_912.jpg, Loss_G: 8.7754, Loss_D_A: 0.0019, Loss_D_B: 0.0013\n",
            "Epoch 66/70, Batch 9/25, Image: rainy_1059.jpg, Loss_G: 8.6472, Loss_D_A: 0.0033, Loss_D_B: 0.0020\n",
            "Epoch 66/70, Batch 10/25, Image: rainy_104.jpg, Loss_G: 9.2094, Loss_D_A: 0.0074, Loss_D_B: 0.0098\n",
            "Epoch 66/70, Batch 11/25, Image: rainy_1742.jpg, Loss_G: 7.9299, Loss_D_A: 0.0058, Loss_D_B: 0.0118\n",
            "Epoch 66/70, Batch 12/25, Image: rainy_205.jpg, Loss_G: 8.5186, Loss_D_A: 0.0036, Loss_D_B: 0.0117\n",
            "Epoch 66/70, Batch 13/25, Image: rainy_3010.jpg, Loss_G: 9.5462, Loss_D_A: 0.0037, Loss_D_B: 0.0045\n",
            "Epoch 66/70, Batch 14/25, Image: rainy_2859.jpg, Loss_G: 7.4073, Loss_D_A: 0.0065, Loss_D_B: 0.0023\n",
            "Epoch 66/70, Batch 15/25, Image: rainy_413.jpg, Loss_G: 8.1396, Loss_D_A: 0.0053, Loss_D_B: 0.0076\n",
            "Epoch 66/70, Batch 16/25, Image: rainy_3014.jpg, Loss_G: 8.1749, Loss_D_A: 0.0038, Loss_D_B: 0.0072\n",
            "Epoch 66/70, Batch 17/25, Image: rainy_2431.jpg, Loss_G: 10.8856, Loss_D_A: 0.0044, Loss_D_B: 0.0065\n",
            "Epoch 66/70, Batch 18/25, Image: rainy_1784.jpg, Loss_G: 8.2450, Loss_D_A: 0.0045, Loss_D_B: 0.0032\n",
            "Epoch 66/70, Batch 19/25, Image: rainy_1508.jpg, Loss_G: 7.2640, Loss_D_A: 0.0041, Loss_D_B: 0.0038\n",
            "Epoch 66/70, Batch 20/25, Image: rainy_2197.jpg, Loss_G: 8.6580, Loss_D_A: 0.0033, Loss_D_B: 0.0043\n",
            "Epoch 66/70, Batch 21/25, Image: rainy_1432.jpg, Loss_G: 9.3284, Loss_D_A: 0.0043, Loss_D_B: 0.0017\n",
            "Epoch 66/70, Batch 22/25, Image: rainy_3635.jpg, Loss_G: 10.4184, Loss_D_A: 0.0056, Loss_D_B: 0.0053\n",
            "Epoch 66/70, Batch 23/25, Image: rainy_2838.jpg, Loss_G: 8.0680, Loss_D_A: 0.0035, Loss_D_B: 0.0082\n",
            "Epoch 66/70, Batch 24/25, Image: rainy_1931.jpg, Loss_G: 10.8740, Loss_D_A: 0.0105, Loss_D_B: 0.0084\n",
            "Epoch 67/70, Batch 0/25, Image: rainy_232.jpg, Loss_G: 9.3272, Loss_D_A: 0.0106, Loss_D_B: 0.0125\n",
            "Epoch 67/70, Batch 1/25, Image: rainy_1690.jpg, Loss_G: 10.5064, Loss_D_A: 0.0039, Loss_D_B: 0.0201\n",
            "Epoch 67/70, Batch 2/25, Image: rainy_3756.jpg, Loss_G: 7.8654, Loss_D_A: 0.0011, Loss_D_B: 0.0238\n",
            "Epoch 67/70, Batch 3/25, Image: rainy_3529.jpg, Loss_G: 7.9984, Loss_D_A: 0.0019, Loss_D_B: 0.0136\n",
            "Epoch 67/70, Batch 4/25, Image: rainy_1059.jpg, Loss_G: 9.9463, Loss_D_A: 0.0078, Loss_D_B: 0.0057\n",
            "Epoch 67/70, Batch 5/25, Image: rainy_3213.jpg, Loss_G: 8.0481, Loss_D_A: 0.0088, Loss_D_B: 0.0025\n",
            "Epoch 67/70, Batch 6/25, Image: rainy_79.jpg, Loss_G: 8.0861, Loss_D_A: 0.0053, Loss_D_B: 0.0020\n",
            "Epoch 67/70, Batch 7/25, Image: rainy_3795.jpg, Loss_G: 6.6201, Loss_D_A: 0.0013, Loss_D_B: 0.0032\n",
            "Epoch 67/70, Batch 8/25, Image: rainy_1269.jpg, Loss_G: 7.8594, Loss_D_A: 0.0016, Loss_D_B: 0.0043\n",
            "Epoch 67/70, Batch 9/25, Image: rainy_2838.jpg, Loss_G: 7.9952, Loss_D_A: 0.0041, Loss_D_B: 0.0029\n",
            "Epoch 67/70, Batch 10/25, Image: rainy_3342.jpg, Loss_G: 8.4707, Loss_D_A: 0.0068, Loss_D_B: 0.0017\n",
            "Epoch 67/70, Batch 11/25, Image: rainy_2779.jpg, Loss_G: 8.4467, Loss_D_A: 0.0056, Loss_D_B: 0.0025\n",
            "Epoch 67/70, Batch 12/25, Image: rainy_814.jpg, Loss_G: 7.8257, Loss_D_A: 0.0099, Loss_D_B: 0.0032\n",
            "Epoch 67/70, Batch 13/25, Image: rainy_2544.jpg, Loss_G: 7.9023, Loss_D_A: 0.0175, Loss_D_B: 0.0045\n",
            "Epoch 67/70, Batch 14/25, Image: rainy_2570.jpg, Loss_G: 6.4702, Loss_D_A: 0.0128, Loss_D_B: 0.0025\n",
            "Epoch 67/70, Batch 15/25, Image: rainy_1861.jpg, Loss_G: 8.2111, Loss_D_A: 0.0126, Loss_D_B: 0.0029\n",
            "Epoch 67/70, Batch 16/25, Image: rainy_446.jpg, Loss_G: 8.5523, Loss_D_A: 0.0051, Loss_D_B: 0.0044\n",
            "Epoch 67/70, Batch 17/25, Image: rainy_2257.jpg, Loss_G: 8.5427, Loss_D_A: 0.0018, Loss_D_B: 0.0090\n",
            "Epoch 67/70, Batch 18/25, Image: rainy_3020.jpg, Loss_G: 7.5348, Loss_D_A: 0.0020, Loss_D_B: 0.0090\n",
            "Epoch 67/70, Batch 19/25, Image: rainy_904.jpg, Loss_G: 9.6976, Loss_D_A: 0.0016, Loss_D_B: 0.0060\n",
            "Epoch 67/70, Batch 20/25, Image: rainy_2747.jpg, Loss_G: 7.1906, Loss_D_A: 0.0040, Loss_D_B: 0.0038\n",
            "Epoch 67/70, Batch 21/25, Image: rainy_475.jpg, Loss_G: 8.8174, Loss_D_A: 0.0041, Loss_D_B: 0.0054\n",
            "Epoch 67/70, Batch 22/25, Image: rainy_2955.jpg, Loss_G: 8.2351, Loss_D_A: 0.0035, Loss_D_B: 0.0087\n",
            "Epoch 67/70, Batch 23/25, Image: rainy_1656.jpg, Loss_G: 7.6428, Loss_D_A: 0.0043, Loss_D_B: 0.0085\n",
            "Epoch 67/70, Batch 24/25, Image: rainy_2431.jpg, Loss_G: 7.9972, Loss_D_A: 0.0041, Loss_D_B: 0.0053\n",
            "Epoch 68/70, Batch 0/25, Image: rainy_963.jpg, Loss_G: 7.9549, Loss_D_A: 0.0017, Loss_D_B: 0.0019\n",
            "Epoch 68/70, Batch 1/25, Image: rainy_2977.jpg, Loss_G: 8.2316, Loss_D_A: 0.0023, Loss_D_B: 0.0014\n",
            "Epoch 68/70, Batch 2/25, Image: rainy_1591.jpg, Loss_G: 6.6840, Loss_D_A: 0.0073, Loss_D_B: 0.0010\n",
            "Epoch 68/70, Batch 3/25, Image: rainy_2943.jpg, Loss_G: 10.4018, Loss_D_A: 0.0104, Loss_D_B: 0.0024\n",
            "Epoch 68/70, Batch 4/25, Image: rainy_3014.jpg, Loss_G: 9.2373, Loss_D_A: 0.0057, Loss_D_B: 0.0018\n",
            "Epoch 68/70, Batch 5/25, Image: rainy_447.jpg, Loss_G: 7.6945, Loss_D_A: 0.0031, Loss_D_B: 0.0033\n",
            "Epoch 68/70, Batch 6/25, Image: rainy_79.jpg, Loss_G: 8.5645, Loss_D_A: 0.0100, Loss_D_B: 0.0045\n",
            "Epoch 68/70, Batch 7/25, Image: rainy_2628.jpg, Loss_G: 7.9536, Loss_D_A: 0.0153, Loss_D_B: 0.0066\n",
            "Epoch 68/70, Batch 8/25, Image: rainy_540.jpg, Loss_G: 8.2811, Loss_D_A: 0.0211, Loss_D_B: 0.0062\n",
            "Epoch 68/70, Batch 9/25, Image: rainy_1674.jpg, Loss_G: 8.0201, Loss_D_A: 0.0122, Loss_D_B: 0.0051\n",
            "Epoch 68/70, Batch 10/25, Image: rainy_382.jpg, Loss_G: 7.5575, Loss_D_A: 0.0042, Loss_D_B: 0.0040\n",
            "Epoch 68/70, Batch 11/25, Image: rainy_3337.jpg, Loss_G: 6.9454, Loss_D_A: 0.0032, Loss_D_B: 0.0012\n",
            "Epoch 68/70, Batch 12/25, Image: rainy_1432.jpg, Loss_G: 7.1567, Loss_D_A: 0.0161, Loss_D_B: 0.0021\n",
            "Epoch 68/70, Batch 13/25, Image: rainy_773.jpg, Loss_G: 13.1462, Loss_D_A: 0.0365, Loss_D_B: 0.0048\n",
            "Epoch 68/70, Batch 14/25, Image: rainy_205.jpg, Loss_G: 7.8544, Loss_D_A: 0.0298, Loss_D_B: 0.0034\n",
            "Epoch 68/70, Batch 15/25, Image: rainy_1771.jpg, Loss_G: 8.2861, Loss_D_A: 0.0130, Loss_D_B: 0.0014\n",
            "Epoch 68/70, Batch 16/25, Image: rainy_1836.jpg, Loss_G: 7.5326, Loss_D_A: 0.0078, Loss_D_B: 0.0019\n",
            "Epoch 68/70, Batch 17/25, Image: rainy_2877.jpg, Loss_G: 8.7325, Loss_D_A: 0.0050, Loss_D_B: 0.0020\n",
            "Epoch 68/70, Batch 18/25, Image: rainy_3193.jpg, Loss_G: 8.4871, Loss_D_A: 0.0081, Loss_D_B: 0.0023\n",
            "Epoch 68/70, Batch 19/25, Image: rainy_1901.jpg, Loss_G: 8.1075, Loss_D_A: 0.0236, Loss_D_B: 0.0037\n",
            "Epoch 68/70, Batch 20/25, Image: rainy_1508.jpg, Loss_G: 7.7006, Loss_D_A: 0.0268, Loss_D_B: 0.0031\n",
            "Epoch 68/70, Batch 21/25, Image: rainy_2787.jpg, Loss_G: 7.3640, Loss_D_A: 0.0154, Loss_D_B: 0.0023\n",
            "Epoch 68/70, Batch 22/25, Image: rainy_537.jpg, Loss_G: 7.2834, Loss_D_A: 0.0097, Loss_D_B: 0.0065\n",
            "Epoch 68/70, Batch 23/25, Image: rainy_3156.jpg, Loss_G: 7.1996, Loss_D_A: 0.0034, Loss_D_B: 0.0115\n",
            "Epoch 68/70, Batch 24/25, Image: rainy_332.jpg, Loss_G: 7.9253, Loss_D_A: 0.0133, Loss_D_B: 0.0088\n",
            "Epoch 69/70, Batch 0/25, Image: rainy_3951.jpg, Loss_G: 8.4066, Loss_D_A: 0.0304, Loss_D_B: 0.0042\n",
            "Epoch 69/70, Batch 1/25, Image: rainy_1434.jpg, Loss_G: 8.5296, Loss_D_A: 0.0220, Loss_D_B: 0.0016\n",
            "Epoch 69/70, Batch 2/25, Image: rainy_841.jpg, Loss_G: 8.2006, Loss_D_A: 0.0054, Loss_D_B: 0.0018\n",
            "Epoch 69/70, Batch 3/25, Image: rainy_826.jpg, Loss_G: 8.3445, Loss_D_A: 0.0107, Loss_D_B: 0.0021\n",
            "Epoch 69/70, Batch 4/25, Image: rainy_1876.jpg, Loss_G: 9.1569, Loss_D_A: 0.0144, Loss_D_B: 0.0016\n",
            "Epoch 69/70, Batch 5/25, Image: rainy_1826.jpg, Loss_G: 8.3496, Loss_D_A: 0.0155, Loss_D_B: 0.0013\n",
            "Epoch 69/70, Batch 6/25, Image: rainy_2620.jpg, Loss_G: 8.8703, Loss_D_A: 0.0083, Loss_D_B: 0.0027\n",
            "Epoch 69/70, Batch 7/25, Image: rainy_2492.jpg, Loss_G: 9.3124, Loss_D_A: 0.0021, Loss_D_B: 0.0097\n",
            "Epoch 69/70, Batch 8/25, Image: rainy_2968.jpg, Loss_G: 8.8473, Loss_D_A: 0.0022, Loss_D_B: 0.0092\n",
            "Epoch 69/70, Batch 9/25, Image: rainy_2198.jpg, Loss_G: 7.6679, Loss_D_A: 0.0022, Loss_D_B: 0.0094\n",
            "Epoch 69/70, Batch 10/25, Image: rainy_1568.jpg, Loss_G: 8.6556, Loss_D_A: 0.0013, Loss_D_B: 0.0061\n",
            "Epoch 69/70, Batch 11/25, Image: rainy_3573.jpg, Loss_G: 7.3967, Loss_D_A: 0.0012, Loss_D_B: 0.0029\n",
            "Epoch 69/70, Batch 12/25, Image: rainy_382.jpg, Loss_G: 7.5501, Loss_D_A: 0.0012, Loss_D_B: 0.0014\n",
            "Epoch 69/70, Batch 13/25, Image: rainy_3511.jpg, Loss_G: 7.7054, Loss_D_A: 0.0017, Loss_D_B: 0.0013\n",
            "Epoch 69/70, Batch 14/25, Image: rainy_3213.jpg, Loss_G: 8.7821, Loss_D_A: 0.0046, Loss_D_B: 0.0018\n",
            "Epoch 69/70, Batch 15/25, Image: rainy_963.jpg, Loss_G: 7.6653, Loss_D_A: 0.0060, Loss_D_B: 0.0009\n",
            "Epoch 69/70, Batch 16/25, Image: rainy_3014.jpg, Loss_G: 8.1093, Loss_D_A: 0.0058, Loss_D_B: 0.0016\n",
            "Epoch 69/70, Batch 17/25, Image: rainy_3859.jpg, Loss_G: 8.1811, Loss_D_A: 0.0063, Loss_D_B: 0.0019\n",
            "Epoch 69/70, Batch 18/25, Image: rainy_244.jpg, Loss_G: 7.3794, Loss_D_A: 0.0034, Loss_D_B: 0.0025\n",
            "Epoch 69/70, Batch 19/25, Image: rainy_3019.jpg, Loss_G: 6.7333, Loss_D_A: 0.0031, Loss_D_B: 0.0023\n",
            "Epoch 69/70, Batch 20/25, Image: rainy_1508.jpg, Loss_G: 6.7228, Loss_D_A: 0.0059, Loss_D_B: 0.0020\n",
            "Epoch 69/70, Batch 21/25, Image: rainy_1172.jpg, Loss_G: 8.1426, Loss_D_A: 0.0021, Loss_D_B: 0.0026\n",
            "Epoch 69/70, Batch 22/25, Image: rainy_773.jpg, Loss_G: 9.3344, Loss_D_A: 0.0026, Loss_D_B: 0.0025\n",
            "Epoch 69/70, Batch 23/25, Image: rainy_3635.jpg, Loss_G: 7.0095, Loss_D_A: 0.0073, Loss_D_B: 0.0045\n",
            "Epoch 69/70, Batch 24/25, Image: rainy_3010.jpg, Loss_G: 8.1964, Loss_D_A: 0.0117, Loss_D_B: 0.0081\n",
            "✅ Checkpoint saved at epoch 69\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1083.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_267.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1237.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3606.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3584.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1861.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1059.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1771.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1820 (1).jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1185.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3019.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1957.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2492.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1766.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_298.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_244.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3136.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3769.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2544.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1931.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_491.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_232.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3509.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3164.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2198.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1834.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2060.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2973.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2275.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3078.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_769.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1555.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_902.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3911.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2160.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2759.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2977.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3756.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_335.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2985.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_413.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_748.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_558.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2486.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1769.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_270.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1742.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_166.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3014.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_868.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3010.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1346.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3573.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2779.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3363.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1599.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2747.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3385.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3428.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_923.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_382.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2714.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2968.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2691.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_795.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1826.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_988.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2346.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3821.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3661.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3063.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2259.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_752.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1432.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3529.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_398.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2619.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_926.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2570.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3355.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3371.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1269.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2513.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1669.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_518.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2460.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2955.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_913.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_963.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1761.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_119.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2404.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_993.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_750.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1568.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2814.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3398.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3813.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1899.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_53.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_199.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1434.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_662.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1071.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_260.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2952.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3342.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2474.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3156.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3060.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2629.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2943.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3090.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2859.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1836.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2132.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2453.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3213.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1172.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1901.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3635.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_841.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_475.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1662.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_773.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2197.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1690.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1784.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1158.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1080.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_481.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2533.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3703.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3445.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1639.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3710.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2114.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2787.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3795.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3859.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1530.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3020.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_865.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2004.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3268.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_859.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2620.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_536.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_328.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_826.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3193.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1482.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1456.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3511.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1591.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3951.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_79.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1046.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2836.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1508.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1426.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_912.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2877.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2838.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_170.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1966.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2257.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2431.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_849.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_447.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3001.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2628.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1167.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_429.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_904.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3336.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1228.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2195.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1471.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2857.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_540.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1091.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_814.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_537.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1381.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_3337.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_104.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1733.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1656.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_184.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1876.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_788.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_332.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2724.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1286.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2263.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_2928.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_1674.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_205.jpg\n",
            "✅ Saved: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/DID-MDN-Heavy_epoch_69_de_rained_rainy_446.jpg\n",
            "🚀 Training on all datasets completed successfully! ✅\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.cuda.amp as amp  # Mixed Precision Training\n",
        "from torchvision.transforms.functional import to_pil_image  # For correct image saving\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from models.networks import ResnetGenerator, NLayerDiscriminator\n",
        "\n",
        "# Define dataset paths and batch sizes\n",
        "datasets = {\n",
        "    # \"Rain100L\": {\n",
        "    #     \"input\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain100L/input\",\n",
        "    #     \"target\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain100L/target\",\n",
        "    #     \"output\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain100L/results_8/\",\n",
        "    #     \"batch_size\": 8,  # Custom batch size per dataset\n",
        "    #     \"sample_size\": 100  # Take only 100 samples\n",
        "    # },\n",
        "    \"DID-MDN-Heavy\": {\n",
        "        \"input\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Heavy/rainy\",\n",
        "        \"target\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Heavy/non_rainy\",\n",
        "        \"output\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/\",\n",
        "        \"batch_size\": 8,\n",
        "        \"sample_size\": 200  # Take 200 samples\n",
        "    }\n",
        "    # \"DID-MDN-Medium\": {\n",
        "    # \"input\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Medium/rainy\",\n",
        "    # \"target\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Medium/non_rainy\",\n",
        "    # \"output\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Medium-rain/results_1/\",\n",
        "    # \"batch_size\": 8,\n",
        "    # \"sample_size\": 200  # Take 200 samples\n",
        "    # }\n",
        "    # \"DID-MDN-Medium\": {\n",
        "    # \"input\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Light/rainy\",\n",
        "    # \"target\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Light/non_rainy\",\n",
        "    # \"output\": \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Light-rain/results_1/\",\n",
        "    # \"batch_size\": 6,\n",
        "    # \"sample_size\": 200  # Take 200 samples\n",
        "    # }\n",
        "}\n",
        "\n",
        "\n",
        "# ✅ Image transformations with fixed normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.02, contrast=0.02, saturation=0.02),  # ✅ Subtle augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # ✅ Normalization for training\n",
        "])\n",
        "\n",
        "def denormalize(tensor):\n",
        "    mean = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1).to(tensor.device)\n",
        "    std = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1).to(tensor.device)\n",
        "    tensor = tensor * std + mean\n",
        "    return torch.clamp(tensor, 0.05, 0.95)  # ✅ Avoid clipping too aggressively\n",
        "  # ✅ Ensures valid pixel values\n",
        "\n",
        "# ✅ Initialize Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ✅ Initialize Model\n",
        "model = DeRainCycleGANSSL(input_nc=3, output_nc=3, ngf=128, ndf=256, device=device)\n",
        "\n",
        "# ✅ Learning Rate Schedulers\n",
        "scheduler_G = torch.optim.lr_scheduler.StepLR(model.optimizer_G, step_size=30, gamma=0.5)\n",
        "scheduler_D = torch.optim.lr_scheduler.StepLR(model.optimizer_D, step_size=30, gamma=0.5)\n",
        "\n",
        "# ✅ Training Configuration\n",
        "num_epochs = 70\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint_1/\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)  # ✅ Ensure checkpoint folder exists\n",
        "\n",
        "\n",
        "# ✅ Mixed Precision Training\n",
        "scaler = torch.amp.GradScaler(\"cuda\")\n",
        "# start_epoch = load_latest_checkpoint(model, model.optimizer_G, model.optimizer_D, scheduler_G, scheduler_D, scaler, checkpoint_dir, device)\n",
        "start_epoch = 0\n",
        "print(f\"🚀 Training will start from epoch {start_epoch}\")\n",
        "\n",
        "# ✅ Loop Through Each Dataset and Train\n",
        "for dataset_name, paths in datasets.items():\n",
        "    print(f\"\\n🔹 Training on {dataset_name} dataset...\")\n",
        "\n",
        "    input_dir = paths[\"input\"]\n",
        "    target_dir = paths[\"target\"]\n",
        "    output_dir = paths[\"output\"]\n",
        "    batch_size = paths[\"batch_size\"]\n",
        "    sample_size = paths[\"sample_size\"]\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # ✅ Load dataset\n",
        "    train_loader = DataLoader(\n",
        "        RainDatasetSSL(\n",
        "            dataset_name=dataset_name,\n",
        "            input_dir=input_dir,\n",
        "            target_dir=target_dir,\n",
        "            transform=transform,\n",
        "            sample_size=sample_size,\n",
        "            output_dir=output_dir,\n",
        "            save_masked=True\n",
        "        ),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        for i, (masked_A, real_A, real_B, img_name) in enumerate(train_loader):\n",
        "            masked_A, real_A, real_B = masked_A.to(device), real_A.to(device), real_B.to(device)\n",
        "\n",
        "            # ✅ Optimize model and check loss\n",
        "            loss_G, loss_D_A, loss_D_B = model.optimize_parameters(masked_A, real_B, scaler)\n",
        "\n",
        "            # ✅ Ensure all loss values are valid tensors\n",
        "            if not isinstance(loss_G, torch.Tensor) or not isinstance(loss_D_A, torch.Tensor) or not isinstance(loss_D_B, torch.Tensor):\n",
        "                print(f\"⚠️ Error: Loss values must be tensors! Received: loss_G={loss_G}, loss_D_A={loss_D_A}, loss_D_B={loss_D_B}\")\n",
        "                continue\n",
        "\n",
        "            # ✅ Check for NaN values in loss\n",
        "            if torch.isnan(loss_G).any() or torch.isnan(loss_D_A).any() or torch.isnan(loss_D_B).any():\n",
        "                print(\"⚠️ NaN detected in loss! Skipping update\")\n",
        "                continue\n",
        "\n",
        "            print(f\"Epoch {epoch}/{num_epochs}, Batch {i}/{len(train_loader)}, Image: {img_name[0]}, \"\n",
        "                  f\"Loss_G: {loss_G.item():.4f}, Loss_D_A: {loss_D_A.item():.4f}, Loss_D_B: {loss_D_B.item():.4f}\")\n",
        "\n",
        "        scheduler_G.step(loss_G)\n",
        "        scheduler_D.step((loss_D_A + loss_D_B) * 0.8)\n",
        "\n",
        "        torch.cuda.empty_cache()  # ✅ Prevent OOM errors\n",
        "\n",
        "        # ✅ Save checkpoint every 5 epochs\n",
        "        if epoch % 5 == 0 or epoch == num_epochs - 1:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_G_A_state_dict': model.netG_A.state_dict(),\n",
        "                'model_G_B_state_dict': model.netG_B.state_dict(),\n",
        "                'model_D_A_state_dict': model.netD_A.state_dict(),\n",
        "                'model_D_B_state_dict': model.netD_B.state_dict(),\n",
        "                'optimizer_G_state_dict': model.optimizer_G.state_dict(),\n",
        "                'optimizer_D_state_dict': model.optimizer_D.state_dict(),\n",
        "                'scheduler_G_state_dict': scheduler_G.state_dict(),\n",
        "                'scheduler_D_state_dict': scheduler_D.state_dict(),\n",
        "                'scaler_state_dict': scaler.state_dict()\n",
        "            }, os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\"))\n",
        "            print(f\"✅ Checkpoint saved at epoch {epoch}\")\n",
        "\n",
        "    # ✅ Save final generated images with correct colors\n",
        "    if epoch == num_epochs - 1:\n",
        "        model.netG_A.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (_, real_A, _, img_names) in enumerate(train_loader):\n",
        "                real_A = real_A.to(device)\n",
        "                fake_B = model.netG_A(real_A)\n",
        "\n",
        "                # ✅ Apply Denormalization Properly\n",
        "                fake_B = denormalize(fake_B)\n",
        "                fake_B = torch.clamp(fake_B, 0.05, 0.95)  # ✅ Ensure correct color range\n",
        "\n",
        "                for j in range(real_A.size(0)):\n",
        "                    img_name = img_names[j]\n",
        "                    save_path = os.path.join(output_dir, f\"{dataset_name}_epoch_{epoch}_de_rained_{img_name}\")\n",
        "\n",
        "                    # ✅ Convert to PIL image correctly\n",
        "                    pil_img = to_pil_image(fake_B[j].detach().cpu())\n",
        "                    pil_img.save(save_path)\n",
        "\n",
        "                    print(f\"✅ Saved: {save_path}\")\n",
        "\n",
        "print(\"🚀 Training on all datasets completed successfully! ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFfSsa8gN-Hq",
        "outputId": "f3af39ea-29f2-42a6-82ce-753011deb196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Final trained model saved at: /content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint_1/final_trained_model.pth\n"
          ]
        }
      ],
      "source": [
        "final_checkpoint_path = os.path.join(checkpoint_dir, \"final_trained_model.pth\")\n",
        "\n",
        "torch.save({\n",
        "    'epoch': num_epochs,\n",
        "    'model_G_A_state_dict': model.netG_A.state_dict(),\n",
        "    'model_G_B_state_dict': model.netG_B.state_dict(),\n",
        "    'model_D_A_state_dict': model.netD_A.state_dict(),\n",
        "    'model_D_B_state_dict': model.netD_B.state_dict(),\n",
        "    'optimizer_G_state_dict': model.optimizer_G.state_dict(),\n",
        "    'optimizer_D_state_dict': model.optimizer_D.state_dict(),\n",
        "    'scheduler_G_state_dict': scheduler_G.state_dict(),\n",
        "    'scheduler_D_state_dict': scheduler_D.state_dict(),\n",
        "    'scaler_state_dict': scaler.state_dict()\n",
        "}, final_checkpoint_path)\n",
        "\n",
        "print(f\"✅ Final trained model saved at: {final_checkpoint_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lR3465mOJ8u",
        "outputId": "d8e7d024-6b57-4e24-f677-633a203e23cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-096fa9f893d0>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"/content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint_1/final_trained_model.pth\", map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:03<00:00, 144MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded from: /content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint_1/final_trained_model.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Load the model\n",
        "# ✅ Define the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint_1/final_trained_model.pth\", map_location=device)\n",
        "model = DeRainCycleGANSSL(input_nc=3, output_nc=3, ngf=128, ndf=256, device=device)\n",
        "scaler = torch.amp.GradScaler(\"cuda\")\n",
        "# ✅ Learning Rate Schedulers\n",
        "scheduler_G = torch.optim.lr_scheduler.StepLR(model.optimizer_G, step_size=30, gamma=0.5)\n",
        "scheduler_D = torch.optim.lr_scheduler.StepLR(model.optimizer_D, step_size=30, gamma=0.5)\n",
        "\n",
        "model.netG_A.load_state_dict(checkpoint['model_G_A_state_dict'])\n",
        "model.netG_B.load_state_dict(checkpoint['model_G_B_state_dict'])\n",
        "model.netD_A.load_state_dict(checkpoint['model_D_A_state_dict'])\n",
        "model.netD_B.load_state_dict(checkpoint['model_D_B_state_dict'])\n",
        "\n",
        "# Load optimizers & scaler (if resuming training)\n",
        "model.optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
        "model.optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n",
        "scheduler_G.load_state_dict(checkpoint['scheduler_G_state_dict'])\n",
        "scheduler_D.load_state_dict(checkpoint['scheduler_D_state_dict'])\n",
        "scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
        "\n",
        "print(f\"✅ Model loaded from: /content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint_1/final_trained_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXDqNhm0PLNR",
        "outputId": "624b9bf3-66ee-43c6-9a8e-2b85224780e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-26-4012adf4af5a>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"/content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint_1/final_trained_model.pth\", map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Inference complete! De-rained image saved.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from models.networks import ResnetGenerator\n",
        "\n",
        "# ✅ Load trained model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_G_A = ResnetGenerator(input_nc=3, output_nc=3, ngf=128, norm_layer=torch.nn.InstanceNorm2d, n_blocks=9).to(device)\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint_1/final_trained_model.pth\", map_location=device)\n",
        "model_G_A.load_state_dict(checkpoint['model_G_A_state_dict'])\n",
        "model_G_A.eval()\n",
        "\n",
        "# ✅ Define image transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    # transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# ✅ Load new rainy image\n",
        "img_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Light/rainy/rainy_88.jpg\"\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "img_tensor = transform(img).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "# ✅ Perform inference\n",
        "with torch.no_grad():\n",
        "    de_rained_tensor = model_G_A(img_tensor)\n",
        "\n",
        "# ✅ Convert back to an image\n",
        "mean = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1).to(device)\n",
        "std = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1).to(device)\n",
        "de_rained_tensor = de_rained_tensor * std + mean  # Denormalization\n",
        "de_rained_tensor = torch.clamp(de_rained_tensor, 0.05, 0.95)\n",
        "\n",
        "# ✅ Save the de-rained image\n",
        "de_rained_image = to_pil_image(de_rained_tensor.squeeze(0).cpu())\n",
        "de_rained_image.save(\"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain_Light_rainy_rainy_88.jpg\")\n",
        "\n",
        "print(\"✅ Inference complete! De-rained image saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf-kbxXzIEu_",
        "outputId": "248754b6-176f-4e1b-af0c-b2290fd48f2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Inference complete! De-rained image saved.\n",
            "📌 PSNR: 19.1212, SSIM: 0.5683\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import numpy as np\n",
        "from models.networks import ResnetGenerator\n",
        "\n",
        "# ✅ Load trained model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_G_A = ResnetGenerator(input_nc=3, output_nc=3, ngf=128, norm_layer=torch.nn.InstanceNorm2d, n_blocks=9).to(device)\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint_1/final_trained_model.pth\", map_location=device, weights_only=True)\n",
        "model_G_A.load_state_dict(checkpoint['model_G_A_state_dict'])\n",
        "model_G_A.eval()\n",
        "\n",
        "# ✅ Define image transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# ✅ Load new rainy image\n",
        "img_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Light/rainy/rainy_88.jpg\"\n",
        "gt_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Rain_Light/non_rainy/non_rainy_88.jpg\"  # Ground truth\n",
        "\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "gt = Image.open(gt_path).convert(\"RGB\")\n",
        "\n",
        "img_tensor = transform(img).unsqueeze(0).to(device)  # Add batch dimension\n",
        "gt_tensor = transform(gt).unsqueeze(0).to(device)\n",
        "\n",
        "# ✅ Perform inference\n",
        "with torch.no_grad():\n",
        "    de_rained_tensor = model_G_A(img_tensor)\n",
        "\n",
        "# ✅ Convert back to an image\n",
        "mean = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1).to(device)\n",
        "std = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1).to(device)\n",
        "de_rained_tensor = de_rained_tensor * std + mean  # Denormalization\n",
        "de_rained_tensor = torch.clamp(de_rained_tensor, 0.05, 0.95)\n",
        "\n",
        "gt_np = np.array(img.resize((256, 256)), dtype=np.float32) / 255.0  # Normalize GT to 0-1\n",
        "de_rained_np = np.array(to_pil_image(de_rained_tensor.squeeze(0).cpu()), dtype=np.float32) / 255.0  # Normalize output\n",
        "\n",
        "# ✅ Compute PSNR & SSIM properly\n",
        "psnr_value = psnr(gt_np, de_rained_np, data_range=1.0)  # Use 1.0 as max range\n",
        "ssim_value = ssim(gt_np, de_rained_np, data_range=1.0, channel_axis=-1, win_size=3)\n",
        "\n",
        "# ✅ Save the de-rained image\n",
        "de_rained_image = to_pil_image(de_rained_tensor.squeeze(0).cpu())\n",
        "de_rained_image.save(\"/content/drive/MyDrive/Khabeer - IRP/Dataset/Rain_Light_rainy_rainy_882.jpg\")\n",
        "\n",
        "print(f\"✅ Inference complete! De-rained image saved.\")\n",
        "print(f\"📌 PSNR: {psnr_value:.4f}, SSIM: {ssim_value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBrxB4WEt1Hs",
        "outputId": "b7443b7f-5966-4ad4-a5d3-bae6839fff29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Awhy-w32nUQ3",
        "outputId": "df865509-923c-4619-e618-643af52b3c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from lpips) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (0.20.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.11/dist-packages (from lpips) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (1.14.1)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.2.1->lpips) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.2)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n"
          ]
        }
      ],
      "source": [
        "pip install lpips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scQ0JZwrm3fy",
        "outputId": "40ffb1a4-d366-40d0-e069-dfbe8ec2bfef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "Epoch [1/60], PSNR: 11.4478, SSIM: 0.0555, LPIPS: 0.9069\n",
            "Epoch [2/60], PSNR: 13.0224, SSIM: 0.1164, LPIPS: 0.8189\n",
            "Epoch [3/60], PSNR: 13.2814, SSIM: 0.1369, LPIPS: 0.7188\n",
            "Epoch [4/60], PSNR: 13.4929, SSIM: 0.1616, LPIPS: 0.6192\n",
            "Epoch [5/60], PSNR: 13.6207, SSIM: 0.1911, LPIPS: 0.5724\n",
            "Epoch [6/60], PSNR: 13.7125, SSIM: 0.2222, LPIPS: 0.5395\n",
            "Epoch [7/60], PSNR: 13.7478, SSIM: 0.2415, LPIPS: 0.5159\n",
            "Epoch [8/60], PSNR: 13.7969, SSIM: 0.2568, LPIPS: 0.4991\n",
            "Epoch [9/60], PSNR: 13.8208, SSIM: 0.2677, LPIPS: 0.4864\n",
            "Epoch [10/60], PSNR: 13.8356, SSIM: 0.2757, LPIPS: 0.4755\n",
            "Epoch [11/60], PSNR: 13.8224, SSIM: 0.2825, LPIPS: 0.4659\n",
            "Epoch [12/60], PSNR: 13.8367, SSIM: 0.2883, LPIPS: 0.4562\n",
            "Epoch [13/60], PSNR: 13.8550, SSIM: 0.2933, LPIPS: 0.4459\n",
            "Epoch [14/60], PSNR: 13.8780, SSIM: 0.2980, LPIPS: 0.4387\n",
            "Epoch [15/60], PSNR: 13.8803, SSIM: 0.3014, LPIPS: 0.4325\n",
            "Epoch [16/60], PSNR: 13.8836, SSIM: 0.3047, LPIPS: 0.4268\n",
            "Epoch [17/60], PSNR: 13.8970, SSIM: 0.3084, LPIPS: 0.4229\n",
            "Epoch [18/60], PSNR: 13.8947, SSIM: 0.3108, LPIPS: 0.4174\n",
            "Epoch [19/60], PSNR: 13.9204, SSIM: 0.3130, LPIPS: 0.4148\n",
            "Epoch [20/60], PSNR: 13.9387, SSIM: 0.3149, LPIPS: 0.4113\n",
            "Epoch [21/60], PSNR: 13.9323, SSIM: 0.3166, LPIPS: 0.4085\n",
            "Epoch [22/60], PSNR: 13.9166, SSIM: 0.3180, LPIPS: 0.4056\n",
            "Epoch [23/60], PSNR: 13.9300, SSIM: 0.3193, LPIPS: 0.4039\n",
            "Epoch [24/60], PSNR: 13.9134, SSIM: 0.3200, LPIPS: 0.4011\n",
            "Epoch [25/60], PSNR: 13.9181, SSIM: 0.3215, LPIPS: 0.3978\n",
            "Epoch [26/60], PSNR: 13.9101, SSIM: 0.3221, LPIPS: 0.3956\n",
            "Epoch [27/60], PSNR: 13.9146, SSIM: 0.3232, LPIPS: 0.3931\n",
            "Epoch [28/60], PSNR: 13.9126, SSIM: 0.3241, LPIPS: 0.3915\n",
            "Epoch [29/60], PSNR: 13.9090, SSIM: 0.3248, LPIPS: 0.3889\n",
            "Epoch [30/60], PSNR: 13.9452, SSIM: 0.3254, LPIPS: 0.3876\n",
            "Epoch [31/60], PSNR: 13.9393, SSIM: 0.3262, LPIPS: 0.3855\n",
            "Epoch [32/60], PSNR: 13.9250, SSIM: 0.3268, LPIPS: 0.3833\n",
            "Epoch [33/60], PSNR: 13.9361, SSIM: 0.3274, LPIPS: 0.3828\n",
            "Epoch [34/60], PSNR: 13.9272, SSIM: 0.3273, LPIPS: 0.3804\n",
            "Epoch [35/60], PSNR: 13.9114, SSIM: 0.3281, LPIPS: 0.3796\n",
            "Epoch [36/60], PSNR: 13.9373, SSIM: 0.3287, LPIPS: 0.3783\n",
            "Epoch [37/60], PSNR: 13.9148, SSIM: 0.3292, LPIPS: 0.3761\n",
            "Epoch [38/60], PSNR: 13.9506, SSIM: 0.3297, LPIPS: 0.3751\n",
            "Epoch [39/60], PSNR: 13.9287, SSIM: 0.3299, LPIPS: 0.3734\n",
            "Epoch [40/60], PSNR: 13.9219, SSIM: 0.3305, LPIPS: 0.3729\n",
            "Epoch [41/60], PSNR: 13.9348, SSIM: 0.3306, LPIPS: 0.3712\n",
            "Epoch [42/60], PSNR: 13.9303, SSIM: 0.3309, LPIPS: 0.3706\n",
            "Epoch [43/60], PSNR: 13.9600, SSIM: 0.3311, LPIPS: 0.3694\n",
            "Epoch [44/60], PSNR: 13.9089, SSIM: 0.3320, LPIPS: 0.3679\n",
            "Epoch [45/60], PSNR: 13.9469, SSIM: 0.3319, LPIPS: 0.3663\n",
            "Epoch [46/60], PSNR: 13.9463, SSIM: 0.3322, LPIPS: 0.3655\n",
            "Epoch [47/60], PSNR: 13.9798, SSIM: 0.3325, LPIPS: 0.3645\n",
            "Epoch [48/60], PSNR: 13.9317, SSIM: 0.3324, LPIPS: 0.3642\n",
            "Epoch [49/60], PSNR: 13.9308, SSIM: 0.3330, LPIPS: 0.3630\n",
            "Epoch [50/60], PSNR: 13.9349, SSIM: 0.3332, LPIPS: 0.3619\n",
            "Epoch [51/60], PSNR: 13.9161, SSIM: 0.3336, LPIPS: 0.3607\n",
            "Epoch [52/60], PSNR: 13.9486, SSIM: 0.3337, LPIPS: 0.3601\n",
            "Epoch [53/60], PSNR: 13.9417, SSIM: 0.3337, LPIPS: 0.3587\n",
            "Epoch [54/60], PSNR: 13.9383, SSIM: 0.3343, LPIPS: 0.3574\n",
            "Epoch [55/60], PSNR: 13.9071, SSIM: 0.3345, LPIPS: 0.3564\n",
            "Epoch [56/60], PSNR: 13.9487, SSIM: 0.3345, LPIPS: 0.3553\n",
            "Epoch [57/60], PSNR: 13.9286, SSIM: 0.3349, LPIPS: 0.3549\n",
            "Epoch [58/60], PSNR: 13.9591, SSIM: 0.3347, LPIPS: 0.3544\n",
            "Epoch [59/60], PSNR: 13.9847, SSIM: 0.3346, LPIPS: 0.3538\n",
            "Epoch [60/60], PSNR: 13.9463, SSIM: 0.3347, LPIPS: 0.3524\n",
            "\n",
            "🎯 Autoencoder Training & Evaluation Completed! ✅\n",
            "✅ Final reconstructed images saved to: /content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/final_reconstructed_images_12_7/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import lpips  # LPIPS Perceptual Loss\n",
        "from torchvision.utils import save_image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import math\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Dataset Handling\n",
        "# ------------------------------\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.image_filenames = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, self.image_filenames[idx]\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Image Transformations (Ensuring Proper Normalization)\n",
        "# ------------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1,1] for LPIPS\n",
        "])\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Improved Autoencoder\n",
        "# ------------------------------\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # 🔹 Encoder\n",
        "        self.encoder1 = nn.Sequential(nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.encoder2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.encoder3 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.encoder4 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "\n",
        "        # 🔹 Bottleneck\n",
        "        self.bottleneck = nn.Sequential(nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "\n",
        "        # 🔹 Decoder\n",
        "        self.decoder1 = nn.Sequential(nn.ConvTranspose2d(512, 512, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder2 = nn.Sequential(nn.ConvTranspose2d(512 + 512, 256, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder3 = nn.Sequential(nn.ConvTranspose2d(256 + 256, 128, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder4 = nn.Sequential(nn.ConvTranspose2d(128 + 128, 64, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder5 = nn.Sequential(nn.ConvTranspose2d(64 + 64, input_nc, kernel_size=4, stride=2, padding=1),nn.Sigmoid())  # ✅ Changed to Tanh for [-1,1] range\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        e4 = self.encoder4(e3)\n",
        "        b = self.bottleneck(e4)\n",
        "        d1 = self.decoder1(b)\n",
        "        d2 = self.decoder2(torch.cat([d1, e4], dim=1))\n",
        "        d3 = self.decoder3(torch.cat([d2, e3], dim=1))\n",
        "        d4 = self.decoder4(torch.cat([d3, e2], dim=1))\n",
        "        d5 = self.decoder5(torch.cat([d4, e1], dim=1))\n",
        "        return d5\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Perceptual Loss (LPIPS) + SSIM Loss\n",
        "# ------------------------------\n",
        "class SSIMLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SSIMLoss, self).__init__()\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        return 1 - ssim(img1.cpu().detach().numpy().transpose(1, 2, 0), img2.cpu().detach().numpy().transpose(1, 2, 0), data_range=2.0, channel_axis=2)\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Training Configuration\n",
        "# ------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "autoencoder = Autoencoder(input_nc=3).to(device)\n",
        "mse_loss = nn.MSELoss()\n",
        "ssim_loss = SSIMLoss()\n",
        "lpips_loss_fn = lpips.LPIPS(net='alex').to(device)  # ✅ LPIPS Perceptual Loss\n",
        "\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0002)\n",
        "\n",
        "# ✅ Load dataset\n",
        "dataset_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/\"\n",
        "train_dataset = ImageDataset(dataset_path, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Training Loop\n",
        "# ------------------------------\n",
        "output_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/final_reconstructed_images_12_7/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "# Convert output from [-1,1] to [0,1]\n",
        "def denormalize_image(tensor):\n",
        "    return (tensor + 1) / 2  # ✅ Convert from [-1,1] → [0,1]\n",
        "\n",
        "epochs = 60\n",
        "for epoch in range(epochs):\n",
        "    total_psnr, total_ssim, total_lpips, num_images = 0, 0, 0, 0\n",
        "\n",
        "    for images, filenames in train_loader:\n",
        "        images = images.to(device)\n",
        "        reconstructed = autoencoder(images)\n",
        "\n",
        "        mse_loss_value = mse_loss(reconstructed, images)\n",
        "        ssim_loss_value = torch.tensor([\n",
        "            ssim(\n",
        "                reconstructed[i].cpu().detach().numpy().transpose(1, 2, 0),\n",
        "                images[i].cpu().detach().numpy().transpose(1, 2, 0),\n",
        "                data_range=2.0,  # 🔹 FIX: Explicit data_range for SSIM\n",
        "                channel_axis=2\n",
        "            ) for i in range(images.size(0))\n",
        "        ]).mean()\n",
        "        lpips_loss_value = lpips_loss_fn(images, reconstructed).mean()\n",
        "\n",
        "        #  Loss\n",
        "        # ✅ Reduce LPIPS loss contribution to avoid dark artifacts\n",
        "        total_loss = 0.8 * mse_loss_value + 0.2 * ssim_loss_value + 0.02 * lpips_loss_value\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(autoencoder.parameters(), max_norm=5)  # ✅ Gradient Clipping\n",
        "        optimizer.step()\n",
        "\n",
        "        total_psnr += psnr(images.cpu().detach().numpy(), reconstructed.cpu().detach().numpy(), data_range=2.0)\n",
        "        total_ssim += ssim_loss_value.item()\n",
        "        total_lpips += lpips_loss_value.item()\n",
        "        num_images += 1\n",
        "\n",
        "         # ✅ Save Images in the Final Epoch\n",
        "        if epoch == epochs - 1:\n",
        "            for i in range(images.size(0)):\n",
        "                save_path = os.path.join(output_dir, f\"reconstructed_{filenames[i]}\")\n",
        "                # Denormalize output before saving\n",
        "                reconstructed = denormalize_image(reconstructed)\n",
        "                save_image(reconstructed[i], save_path)\n",
        "\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], PSNR: {total_psnr/num_images:.4f}, SSIM: {total_ssim/num_images:.4f}, LPIPS: {total_lpips/num_images:.4f}\")\n",
        "\n",
        "print(\"\\n🎯 Autoencoder Training & Evaluation Completed! ✅\")\n",
        "print(f\"✅ Final reconstructed images saved to: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import lpips  # LPIPS Perceptual Loss\n",
        "from torchvision.utils import save_image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Dataset Handling\n",
        "# ------------------------------\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.image_filenames = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, self.image_filenames[idx]\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Image Transformations (Ensuring Proper Normalization)\n",
        "# ------------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Improved Autoencoder (Larger Bottleneck)\n",
        "# ------------------------------\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # 🔹 Encoder\n",
        "        self.encoder1 = nn.Sequential(nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.encoder2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.encoder3 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.encoder4 = nn.Sequential(nn.Conv2d(256, 1024, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))  # 🔹 Larger bottleneck\n",
        "\n",
        "        # 🔹 Bottleneck (Expanded)\n",
        "        self.bottleneck = nn.Sequential(nn.Conv2d(1024, 1024, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "\n",
        "        # 🔹 Decoder\n",
        "        self.decoder1 = nn.Sequential(nn.ConvTranspose2d(1024, 1024, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder2 = nn.Sequential(nn.ConvTranspose2d(1024 + 1024, 256, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder3 = nn.Sequential(nn.ConvTranspose2d(256 + 256, 128, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder4 = nn.Sequential(nn.ConvTranspose2d(128 + 128, 64, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder5 = nn.Sequential(nn.ConvTranspose2d(64 + 64, input_nc, kernel_size=4, stride=2, padding=1), nn.Sigmoid())  # 🔹 Sigmoid for [0,1] range\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        e4 = self.encoder4(e3)\n",
        "        b = self.bottleneck(e4)\n",
        "        d1 = self.decoder1(b)\n",
        "        d2 = self.decoder2(torch.cat([d1, e4], dim=1))\n",
        "        d3 = self.decoder3(torch.cat([d2, e3], dim=1))\n",
        "        d4 = self.decoder4(torch.cat([d3, e2], dim=1))\n",
        "        d5 = self.decoder5(torch.cat([d4, e1], dim=1))\n",
        "        return d5\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Training Configuration\n",
        "# ------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "autoencoder = Autoencoder(input_nc=3).to(device)\n",
        "mse_loss = nn.MSELoss()\n",
        "lpips_loss_fn = lpips.LPIPS(net='alex').to(device)  # ✅ LPIPS Perceptual Loss\n",
        "\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0002)\n",
        "\n",
        "# ✅ Load dataset\n",
        "dataset_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/results_12/\"\n",
        "train_dataset = ImageDataset(dataset_path, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# ✅ Output Directory\n",
        "output_dir = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/DID-MDN-datasets/DID-MDN-training-split/Heavy-rain/final_reconstructed_images_12_10/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ------------------------------\n",
        "# 🔹 Training Loop\n",
        "# ------------------------------\n",
        "def compute_ssim(img1, img2):\n",
        "    return ssim(img1.cpu().detach().numpy().transpose(1, 2, 0), img2.cpu().detach().numpy().transpose(1, 2, 0), data_range=1.0, channel_axis=2)\n",
        "\n",
        "epochs = 80  # 🔹 More epochs for stability\n",
        "for epoch in range(epochs):\n",
        "    total_psnr, total_ssim, total_lpips, num_images = 0, 0, 0, 0\n",
        "\n",
        "    for images, filenames in train_loader:\n",
        "        images = images.to(device)\n",
        "        reconstructed = autoencoder(images)\n",
        "\n",
        "        mse_loss_value = mse_loss(reconstructed, images)\n",
        "        ssim_loss_value = torch.tensor([compute_ssim(reconstructed[i], images[i]) for i in range(images.size(0))]).mean()\n",
        "        lpips_loss_value = lpips_loss_fn(images, reconstructed).mean()\n",
        "\n",
        "        # ✅ Adjusted Loss Function Weights (Better SSIM)\n",
        "        total_loss = 0.5 * mse_loss_value + 0.4 * (1 - ssim_loss_value) + 0.05 * lpips_loss_value  # 🔹 Higher SSIM weight\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_psnr += psnr(images.cpu().detach().numpy(), reconstructed.cpu().detach().numpy(), data_range=1.0)\n",
        "        total_ssim += ssim_loss_value.item()\n",
        "        total_lpips += lpips_loss_value.item()\n",
        "        num_images += 1\n",
        "\n",
        "        # ✅ Save Images in the Final Epoch\n",
        "        if epoch == epochs - 1:\n",
        "            for i in range(images.size(0)):\n",
        "                save_path = os.path.join(output_dir, f\"reconstructed_{filenames[i]}\")\n",
        "                save_image(reconstructed[i], save_path)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], PSNR: {total_psnr/num_images:.4f}, SSIM: {total_ssim/num_images:.4f}, LPIPS: {total_lpips/num_images:.4f}\")\n",
        "\n",
        "# ✅ Save the trained model\n",
        "torch.save(autoencoder.state_dict(), \"/content/drive/MyDrive/Khabeer - IRP/Dataset/autoencoder_trained.pth\")\n",
        "\n",
        "print(\"\\n✅ Model saved as autoencoder_trained.pth ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJgSZ7ml63c1",
        "outputId": "996ce37e-86c0-4e54-dc43-f1e162958a07"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "Epoch [1/80], PSNR: 11.7606, SSIM: 0.0962, LPIPS: 0.5727\n",
            "Epoch [2/80], PSNR: 15.8081, SSIM: 0.1876, LPIPS: 0.4248\n",
            "Epoch [3/80], PSNR: 19.0521, SSIM: 0.3352, LPIPS: 0.3540\n",
            "Epoch [4/80], PSNR: 20.8190, SSIM: 0.4239, LPIPS: 0.2853\n",
            "Epoch [5/80], PSNR: 22.0705, SSIM: 0.5070, LPIPS: 0.2332\n",
            "Epoch [6/80], PSNR: 22.9662, SSIM: 0.5808, LPIPS: 0.1988\n",
            "Epoch [7/80], PSNR: 23.7724, SSIM: 0.6382, LPIPS: 0.1692\n",
            "Epoch [8/80], PSNR: 24.5388, SSIM: 0.6883, LPIPS: 0.1414\n",
            "Epoch [9/80], PSNR: 25.1847, SSIM: 0.7231, LPIPS: 0.1153\n",
            "Epoch [10/80], PSNR: 25.9672, SSIM: 0.7516, LPIPS: 0.0939\n",
            "Epoch [11/80], PSNR: 26.3819, SSIM: 0.7735, LPIPS: 0.0814\n",
            "Epoch [12/80], PSNR: 26.9687, SSIM: 0.7907, LPIPS: 0.0727\n",
            "Epoch [13/80], PSNR: 27.1899, SSIM: 0.8042, LPIPS: 0.0678\n",
            "Epoch [14/80], PSNR: 27.5502, SSIM: 0.8142, LPIPS: 0.0637\n",
            "Epoch [15/80], PSNR: 27.8129, SSIM: 0.8269, LPIPS: 0.0576\n",
            "Epoch [16/80], PSNR: 28.1998, SSIM: 0.8369, LPIPS: 0.0534\n",
            "Epoch [17/80], PSNR: 28.5106, SSIM: 0.8447, LPIPS: 0.0501\n",
            "Epoch [18/80], PSNR: 28.7314, SSIM: 0.8483, LPIPS: 0.0486\n",
            "Epoch [19/80], PSNR: 28.9852, SSIM: 0.8556, LPIPS: 0.0449\n",
            "Epoch [20/80], PSNR: 29.2409, SSIM: 0.8623, LPIPS: 0.0428\n",
            "Epoch [21/80], PSNR: 29.2645, SSIM: 0.8671, LPIPS: 0.0404\n",
            "Epoch [22/80], PSNR: 29.5478, SSIM: 0.8718, LPIPS: 0.0385\n",
            "Epoch [23/80], PSNR: 29.6890, SSIM: 0.8757, LPIPS: 0.0368\n",
            "Epoch [24/80], PSNR: 29.6252, SSIM: 0.8779, LPIPS: 0.0360\n",
            "Epoch [25/80], PSNR: 30.1218, SSIM: 0.8820, LPIPS: 0.0336\n",
            "Epoch [26/80], PSNR: 30.1494, SSIM: 0.8849, LPIPS: 0.0330\n",
            "Epoch [27/80], PSNR: 30.3880, SSIM: 0.8882, LPIPS: 0.0311\n",
            "Epoch [28/80], PSNR: 30.4210, SSIM: 0.8915, LPIPS: 0.0298\n",
            "Epoch [29/80], PSNR: 30.4447, SSIM: 0.8936, LPIPS: 0.0289\n",
            "Epoch [30/80], PSNR: 30.7488, SSIM: 0.8969, LPIPS: 0.0273\n",
            "Epoch [31/80], PSNR: 30.8629, SSIM: 0.8984, LPIPS: 0.0263\n",
            "Epoch [32/80], PSNR: 30.8644, SSIM: 0.9011, LPIPS: 0.0252\n",
            "Epoch [33/80], PSNR: 31.1353, SSIM: 0.9028, LPIPS: 0.0242\n",
            "Epoch [34/80], PSNR: 31.2760, SSIM: 0.9056, LPIPS: 0.0232\n",
            "Epoch [35/80], PSNR: 31.3153, SSIM: 0.9074, LPIPS: 0.0224\n",
            "Epoch [36/80], PSNR: 31.4276, SSIM: 0.9078, LPIPS: 0.0219\n",
            "Epoch [37/80], PSNR: 31.5628, SSIM: 0.9109, LPIPS: 0.0207\n",
            "Epoch [38/80], PSNR: 31.5520, SSIM: 0.9112, LPIPS: 0.0204\n",
            "Epoch [39/80], PSNR: 31.6232, SSIM: 0.9132, LPIPS: 0.0200\n",
            "Epoch [40/80], PSNR: 31.8778, SSIM: 0.9159, LPIPS: 0.0184\n",
            "Epoch [41/80], PSNR: 31.9128, SSIM: 0.9167, LPIPS: 0.0178\n",
            "Epoch [42/80], PSNR: 32.0538, SSIM: 0.9184, LPIPS: 0.0169\n",
            "Epoch [43/80], PSNR: 32.1459, SSIM: 0.9198, LPIPS: 0.0163\n",
            "Epoch [44/80], PSNR: 32.2723, SSIM: 0.9213, LPIPS: 0.0155\n",
            "Epoch [45/80], PSNR: 32.1756, SSIM: 0.9226, LPIPS: 0.0149\n",
            "Epoch [46/80], PSNR: 32.2605, SSIM: 0.9228, LPIPS: 0.0151\n",
            "Epoch [47/80], PSNR: 32.4374, SSIM: 0.9237, LPIPS: 0.0142\n",
            "Epoch [48/80], PSNR: 32.5058, SSIM: 0.9266, LPIPS: 0.0133\n",
            "Epoch [49/80], PSNR: 32.6114, SSIM: 0.9274, LPIPS: 0.0126\n",
            "Epoch [50/80], PSNR: 32.6234, SSIM: 0.9286, LPIPS: 0.0123\n",
            "Epoch [51/80], PSNR: 32.7283, SSIM: 0.9295, LPIPS: 0.0116\n",
            "Epoch [52/80], PSNR: 32.8745, SSIM: 0.9303, LPIPS: 0.0114\n",
            "Epoch [53/80], PSNR: 32.9650, SSIM: 0.9318, LPIPS: 0.0106\n",
            "Epoch [54/80], PSNR: 33.0374, SSIM: 0.9329, LPIPS: 0.0102\n",
            "Epoch [55/80], PSNR: 33.0341, SSIM: 0.9339, LPIPS: 0.0099\n",
            "Epoch [56/80], PSNR: 33.0911, SSIM: 0.9347, LPIPS: 0.0096\n",
            "Epoch [57/80], PSNR: 33.2213, SSIM: 0.9355, LPIPS: 0.0093\n",
            "Epoch [58/80], PSNR: 33.3345, SSIM: 0.9367, LPIPS: 0.0087\n",
            "Epoch [59/80], PSNR: 33.3617, SSIM: 0.9377, LPIPS: 0.0084\n",
            "Epoch [60/80], PSNR: 33.3469, SSIM: 0.9383, LPIPS: 0.0081\n",
            "Epoch [61/80], PSNR: 33.0789, SSIM: 0.9391, LPIPS: 0.0080\n",
            "Epoch [62/80], PSNR: 33.4447, SSIM: 0.9400, LPIPS: 0.0077\n",
            "Epoch [63/80], PSNR: 33.5993, SSIM: 0.9404, LPIPS: 0.0075\n",
            "Epoch [64/80], PSNR: 33.1839, SSIM: 0.9410, LPIPS: 0.0074\n",
            "Epoch [65/80], PSNR: 33.5534, SSIM: 0.9417, LPIPS: 0.0075\n",
            "Epoch [66/80], PSNR: 33.6948, SSIM: 0.9427, LPIPS: 0.0069\n",
            "Epoch [67/80], PSNR: 33.8081, SSIM: 0.9436, LPIPS: 0.0065\n",
            "Epoch [68/80], PSNR: 33.9450, SSIM: 0.9442, LPIPS: 0.0062\n",
            "Epoch [69/80], PSNR: 34.0459, SSIM: 0.9452, LPIPS: 0.0059\n",
            "Epoch [70/80], PSNR: 34.0628, SSIM: 0.9456, LPIPS: 0.0057\n",
            "Epoch [71/80], PSNR: 34.1162, SSIM: 0.9463, LPIPS: 0.0055\n",
            "Epoch [72/80], PSNR: 34.1944, SSIM: 0.9471, LPIPS: 0.0052\n",
            "Epoch [73/80], PSNR: 33.9971, SSIM: 0.9477, LPIPS: 0.0052\n",
            "Epoch [74/80], PSNR: 32.9122, SSIM: 0.9469, LPIPS: 0.0062\n",
            "Epoch [75/80], PSNR: 33.9164, SSIM: 0.9481, LPIPS: 0.0056\n",
            "Epoch [76/80], PSNR: 34.0307, SSIM: 0.9489, LPIPS: 0.0051\n",
            "Epoch [77/80], PSNR: 34.3519, SSIM: 0.9497, LPIPS: 0.0047\n",
            "Epoch [78/80], PSNR: 34.4746, SSIM: 0.9505, LPIPS: 0.0045\n",
            "Epoch [79/80], PSNR: 34.4614, SSIM: 0.9510, LPIPS: 0.0043\n",
            "Epoch [80/80], PSNR: 34.5925, SSIM: 0.9515, LPIPS: 0.0042\n",
            "\n",
            "✅ Model saved as autoencoder_trained.pth ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Define a path to save the model\n",
        "autoencoder_save_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/autoencoder_model.pth\"\n",
        "\n",
        "# ✅ Save function after training completes\n",
        "torch.save({\n",
        "    'epoch': epochs,\n",
        "    'model_state_dict': autoencoder.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "}, autoencoder_save_path)\n",
        "\n",
        "print(f\"✅ Autoencoder model saved at: {autoencoder_save_path}\")\n"
      ],
      "metadata": {
        "id": "tocehTBNxq8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Load function\n",
        "checkpoint = torch.load(autoencoder_save_path, map_location=device)\n",
        "\n",
        "# ✅ Load model and optimizer states\n",
        "autoencoder.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "start_epoch = checkpoint['epoch']\n",
        "\n",
        "# ✅ Set model to evaluation mode for inference\n",
        "autoencoder.eval()\n",
        "print(f\"✅ Autoencoder model loaded from epoch {start_epoch}\")\n"
      ],
      "metadata": {
        "id": "2c07p-RQxuHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import lpips  # LPIPS Perceptual Loss\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from models.networks import ResnetGenerator  # ✅ GAN Model\n",
        "\n",
        "# ✅ Define image transformations (ensure consistency across models)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1,1]\n",
        "])\n",
        "\n",
        "# ✅ Function to denormalize and convert tensor to image\n",
        "def tensor_to_pil(image_tensor):\n",
        "    image_tensor = image_tensor * 0.5 + 0.5  # Denormalize\n",
        "    image_tensor = torch.clamp(image_tensor, 0, 1)  # Clip values\n",
        "    image_np = image_tensor.squeeze(0).cpu().numpy().transpose(1, 2, 0)  # Convert to NumPy\n",
        "    return Image.fromarray((image_np * 255).astype(np.uint8))\n",
        "\n",
        "# ✅ Load GAN Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_G_A = ResnetGenerator(input_nc=3, output_nc=3, ngf=128, norm_layer=torch.nn.InstanceNorm2d, n_blocks=9).to(device)\n",
        "\n",
        "# ✅ Load GAN Weights\n",
        "gan_checkpoint_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/checkpoint_1/final_trained_model.pth\"\n",
        "checkpoint = torch.load(gan_checkpoint_path, map_location=device)\n",
        "model_G_A.load_state_dict(checkpoint['model_G_A_state_dict'])\n",
        "model_G_A.eval()\n",
        "print(\"✅ GAN Model Loaded!\")\n",
        "\n",
        "# ✅ Define Autoencoder Model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder1 = nn.Sequential(nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.encoder2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.encoder3 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.encoder4 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.bottleneck = nn.Sequential(nn.Conv2d(512, 512, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True))\n",
        "        self.decoder1 = nn.Sequential(nn.ConvTranspose2d(512, 512, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder2 = nn.Sequential(nn.ConvTranspose2d(512 + 512, 256, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder3 = nn.Sequential(nn.ConvTranspose2d(256 + 256, 128, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder4 = nn.Sequential(nn.ConvTranspose2d(128 + 128, 64, kernel_size=4, stride=2, padding=1), nn.ReLU(True))\n",
        "        self.decoder5 = nn.Sequential(nn.ConvTranspose2d(64 + 64, input_nc, kernel_size=4, stride=2, padding=1),nn.Sigmoid())  # ✅ Changed to Tanh for [-1,1] range\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        e4 = self.encoder4(e3)\n",
        "        b = self.bottleneck(e4)\n",
        "        d1 = self.decoder1(b)\n",
        "        d2 = self.decoder2(torch.cat([d1, e4], dim=1))\n",
        "        d3 = self.decoder3(torch.cat([d2, e3], dim=1))\n",
        "        d4 = self.decoder4(torch.cat([d3, e2], dim=1))\n",
        "        d5 = self.decoder5(torch.cat([d4, e1], dim=1))\n",
        "        return d5\n",
        "\n",
        "# ✅ Load Autoencoder Model\n",
        "autoencoder = Autoencoder(input_nc=3).to(device)\n",
        "autoencoder_checkpoint_path = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/autoencoder_model.pth\"\n",
        "checkpoint = torch.load(autoencoder_checkpoint_path, map_location=device)\n",
        "autoencoder.load_state_dict(checkpoint['model_state_dict'])\n",
        "autoencoder.eval()\n",
        "print(\"✅ Autoencoder Model Loaded!\")\n",
        "\n",
        "# ✅ Initialize Loss Functions\n",
        "lpips_loss_fn = lpips.LPIPS(net='alex').to(device)  # Perceptual Loss\n",
        "\n",
        "# ✅ Compute Loss Metrics\n",
        "def compute_metrics(gt, output):\n",
        "    gt_np = gt.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "    output_np = output.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "\n",
        "    psnr_value = psnr(gt_np, output_np, data_range=1.0)\n",
        "    ssim_value = ssim(gt_np, output_np, data_range=1.0, channel_axis=2)\n",
        "    lpips_value = lpips_loss_fn(gt, output).mean().item()\n",
        "\n",
        "    return psnr_value, ssim_value, lpips_value\n",
        "\n",
        "def derain_pipeline(image_path, output_path):\n",
        "    # ✅ Load and preprocess image\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    # ✅ GAN Model Inference\n",
        "    with torch.no_grad():\n",
        "        gan_output = model_G_A(img_tensor)\n",
        "\n",
        "    # ✅ Autoencoder Inference\n",
        "    with torch.no_grad():\n",
        "        refined_output = autoencoder(gan_output)\n",
        "\n",
        "    # ✅ Convert to PIL Image\n",
        "    refined_pil = tensor_to_pil(refined_output)\n",
        "\n",
        "    # ✅ Save Image\n",
        "    refined_pil.save(output_path)\n",
        "\n",
        "    # ✅ Compute Loss Scores\n",
        "    psnr_value, ssim_value, lpips_value = compute_metrics(img_tensor, refined_output)\n",
        "\n",
        "    print(f\"✅ Inference Complete!\")\n",
        "    print(f\"📌 PSNR: {psnr_value:.4f}, SSIM: {ssim_value:.4f}, LPIPS: {lpips_value:.4f}\")\n",
        "\n",
        "    return refined_pil, psnr_value, ssim_value, lpips_value\n",
        "\n"
      ],
      "metadata": {
        "id": "c29ynfNJxu7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/test_rainy.jpg\"\n",
        "output_image = \"/content/drive/MyDrive/Khabeer - IRP/Dataset/de-rained_test.jpg\"\n",
        "\n",
        "final_image, psnr_score, ssim_score, lpips_score = derain_pipeline(input_image, output_image)\n"
      ],
      "metadata": {
        "id": "mrmcHi4W0t35"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}